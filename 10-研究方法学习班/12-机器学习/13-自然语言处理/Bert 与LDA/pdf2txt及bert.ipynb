{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF转TXT的Python实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "摘自https://blog.csdn.net/shao824714565/article/details/84792089"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### package "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- python2中是pdfminer ，python3中是pdfminer3k\n",
    "- PDF更像一张图片,像是在一张纸的各个准确的位置上把内容都摆放出来。大部分情况下，没有逻辑结构，比如句子或段落，并且不能自适应页面大小的调整。PDFMiner尝试通过猜测它们的布局来重建它们的结构，但是不保证一定能工作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解析pdf文件用到的类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **PDFParser**：从文件中获取数据\n",
    "- **PDFDocument**：存储文档数据结构到内存中，保存获取的数据，和PDFParser是相互关联的\n",
    "- PDFPageInterpreter：解析页面内容\n",
    "- PDFDevice：把解析到的内容翻译为你需要的格式\n",
    "- PDFResourceManager：存储共享资源，例如字体或图片\n",
    "\n",
    "![relation](.\\Desktop\\relation.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 布局分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "布局分析返回PDF文档中的每个页面LTPage对象。这个对象和页内包含的子对象，形成一个树结构。\n",
    "- LTPage：表示整个页。可能会含有LTTextBox，LTFigure，LTImage，LTRect，LTCurve和LTLine子对象。\n",
    "- LTTextBox：表示一组文本块可能包含在一个矩形区域。注意此box是由几何分析中创建，并且不一定表示该文本的一个逻辑边界。它包含LTTextLine对象的列表。使用 get_text（）方法返回的文本内容。\n",
    "- LTTextLine：包含表示单个文本行LTChar对象的列表。字符对齐要么水平或垂直，取决于文本的写入模式。\n",
    "- LTChar：单个文本对象。\n",
    "- LTAnno：在文本中实际的字母表示为Unicode字符串（？）。需要注意的是，虽然一个LTChar对象具有实际边界，LTAnno对象没有，因为这些是“虚拟”的字符，根据两个字符间的关系（例如，一个空格）由布局分析后插入。\n",
    "- LTImage：表示一个图像对象。嵌入式图像可以是JPEG或其它格式，但是目前PDFMiner没有放置太多精力在图形对象。\n",
    "- LTLine：代表一条直线。可用于分离文本或附图。\n",
    "- LTRect：表示矩形。可用于框架的另一图片或数字。\n",
    "- LTCurve：表示一个通用的Bezier曲线。\n",
    "![LTPAGE](.\\Desktop\\LTPAGE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解析pdf文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PDF](.\\Desktop\\PDF-1.png)\n",
    "![PDF](.\\Desktop\\PDF-2.png)\n",
    "![PDF](.\\Desktop\\PDF-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Text & Images from PDF Files\n",
      "\n",
      "August 04, 2010\n",
      "\n",
      "Update: January 29, 2012\n",
      "I've corrected this code to work with the current version of pdfminer and it's now available as a github repo:\n",
      "https://github.com/dpapathanasiou/pdfminer-layout-scanner\n",
      "\n",
      "PDFMiner is a pdf parsing library written in Python by Yusuke Shinyama.\n",
      "\n",
      "In addition to the pdf2txt.py and dumppdf.py command line tools, there is a way of analyzing the content tree of each page.\n",
      "\n",
      "Since that's exactly the kind of programmatic parsing I wanted to use PDFMiner for, this is a more complete example, which continues\n",
      "where the default documentation stops.\n",
      "\n",
      "This example is still a work-in-progress, with room for improvement.\n",
      "\n",
      "In the next few sections, I describe how I built up each function, resolving problems I encountered along the way. The impatient can just get\n",
      "the code here instead.\n",
      "\n",
      "Basic Framework\n",
      "Here are the python imports we need for PDFMiner:\n",
      "\n",
      "from pdfminer.pdfparser import PDFParser, PDFDocument, PDFNoOutlines\n",
      "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
      "from pdfminer.converter import PDFPageAggregator\n",
      "from pdfminer.layout import LAParams, LTTextBox, LTTextLine, LTFigure, LTImage\n",
      "\n",
      "Since PDFMiner requires a series of initializations for each pdf file, I've started with this wrapper (Lisp macro style ) function to take care of\n",
      "the basic preliminary actions (file IO, PDFMminer object creation and connection, etc.).\n",
      "\n",
      "def with_pdf (pdf_doc, pdf_pwd, fn, *args):\n",
      "    \"\"\"Open the pdf document, and apply the function, returning the results\"\"\"\n",
      "    result = None\n",
      "    try:\n",
      "        # open the pdf file\n",
      "        fp = open(pdf_doc, 'rb')\n",
      "        # create a parser object associated with the file object\n",
      "        parser = PDFParser(fp)\n",
      "        # create a PDFDocument object that stores the document structure\n",
      "        doc = PDFDocument()\n",
      "        # connect the parser and document objects\n",
      "        parser.set_document(doc)\n",
      "        doc.set_parser(parser)\n",
      "        # supply the password for initialization\n",
      "        doc.initialize(pdf_pwd)\n",
      "\n",
      "        if doc.is_extractable:\n",
      "            # apply the function and return the result\n",
      "            result = fn(doc, *args)\n",
      "\n",
      "        # close the pdf file\n",
      "        fp.close()\n",
      "    except IOError:\n",
      "        # the file doesn't exist or similar problem\n",
      "        pass\n",
      "    return result\n",
      "\n",
      "The first two parameters are the name of the pdf file, and its password. The third parameter, fn, is a higher-order function which takes the\n",
      "instance of the pdfminer.pdfparser.PDFDocument created, and applies whatever action we want (get the table of contents, walk through the\n",
      "pdf page by page, etc.)\n",
      "\n",
      "The last part of the signature, *args, is an optional list of parameters that can be passed to the high-order function as needed (I could have\n",
      "gone with keyword arguments here instead, but a simple list is enough for these examples).\n",
      "\n",
      "As a warm-up, here's an example of how to use the with_pdf() function to fetch the table of contents from a pdf file:\n",
      "\n",
      "def _parse_toc (doc):\n",
      "    \"\"\"With an open PDFDocument object, get the table of contents (toc) data\n",
      "    [this is a higher-order function to be passed to with_pdf()]\"\"\"\n",
      "    toc = []\n",
      "    try:\n",
      "        outlines = doc.get_outlines()\n",
      "        for (level,title,dest,a,se) in outlines:\n",
      "            toc.append( (level, title) )\n",
      "    except PDFNoOutlines:\n",
      "        pass\n",
      "    return toc\n",
      "\n",
      "The _parse_toc() function is the higher-order function which gets passed to with_pdf() as the fn parameter. It expects a single parameter,\n",
      "doc, which is the the instance of the pdfminer.pdfparser.PDFDocument created within with_pdf() itself (note that if with_pdf() couldn't find\n",
      "the file, then _parse_toc() doesn't get called).\n",
      "\n",
      "With all the PDFMiner overhead and initialization done by with_pdf(), _parse_toc() can just focus on collecting the table of content data and\n",
      "returning them as a list. The get_outlines() can raise a \"PDFNoOutlines\" error, so I catch it as an exception, and simply return an empty list\n",
      "in that case.\n",
      "\n",
      "All that's left to do is define the function that invokes _parse_toc() for a specific pdf file; this is also the function that any external users of\n",
      "this module would use to get the table of contents list. Note that the pdf password defaults to an empty string (which is what PDFMiner will\n",
      "use for documents that aren't password-protected), but that can be overriden as needed.\n",
      "\n",
      "def get_toc (pdf_doc, pdf_pwd=''):\n",
      "    \"\"\"Return the table of contents (toc), if any, for this pdf file\"\"\"\n",
      "    return with_pdf(pdf_doc, pdf_pwd, _parse_toc)\n",
      "\n",
      "Page Parsing\n",
      "Next, onto layout analysis. Using the with_pdf() wrapper, we can reproduce the example in the documentation with this higher-order\n",
      "function:\n",
      "\n",
      "def _parse_pages (doc):\n",
      "    \"\"\"With an open PDFDocument object, get the pages and parse each one\n",
      "    [this is a higher-order function to be passed to with_pdf()]\"\"\"\n",
      "    rsrcmgr = PDFResourceManager()\n",
      "    laparams = LAParams()\n",
      "    device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
      "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
      "\n",
      "    for page in doc.get_pages():\n",
      "        interpreter.process_page(page)\n",
      "        # receive the LTPage object for this page\n",
      "        layout = device.get_result()\n",
      "        # layout is an LTPage object which may contain child objects like LTTextBox, LTFigure, LTImage, etc.\n",
      "\n",
      "And this external function, which defines the specific pdf file to analyze:\n",
      "\n",
      "def get_pages (pdf_doc, pdf_pwd=''):\n",
      "    \"\"\"Process each of the pages in this pdf file\"\"\"\n",
      "    with_pdf(pdf_doc, pdf_pwd, _parse_pages)\n",
      "\n",
      "So far, this code doesn't do anything exciting: it just loads each page into a pdfminer.layout.LTPage object, closes the pdf file, and exits.\n",
      "\n",
      "Within each pdfminer.layout.LTPage instance, though, is an objs attribute, which defines the tree of pdfminer.layout.LT* child objects as in\n",
      "the documentation:\n",
      "\n",
      "In this example, I'm going to collect all the text from each page in a top-down, left-to-right sequence, merging any multiple columns into a\n",
      "single stream of consecutive text.\n",
      "\n",
      "The results are not always perfect, but I'm using a fuzzy logic based on physical position and column width, which is very good in most\n",
      "cases.\n",
      "\n",
      "I'm also going to save any images found to a separate folder, and mark their position in the text with <img /> tags.\n",
      "\n",
      "Right now, I'm only able to extract jpeg images, whereas xpdf's pdfimages tool is capable of getting to non-jpeg images and saving them as\n",
      "ppm format.\n",
      "\n",
      "I'm not sure if the problem is within PDFMiner or how I'm using it, but since someone else asked the same question in the PDFMiner mailing\n",
      "list, I suspect it's the former.\n",
      "\n",
      "This requires a few updates to the _parse_pages() function, as follows:\n",
      "\n",
      "def _parse_pages (doc, images_folder):\n",
      "    \"\"\"With an open PDFDocument object, get the pages, parse each one, and return the entire text\n",
      "    [this is a higher-order function to be passed to with_pdf()]\"\"\"\n",
      "    rsrcmgr = PDFResourceManager()\n",
      "    laparams = LAParams()\n",
      "    device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
      "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
      "\n",
      "    text_content = [] # a list of strings, each representing text collected from each page of the doc\n",
      "    for i, page in enumerate(doc.get_pages()):\n",
      "        interpreter.process_page(page)\n",
      "        # receive the LTPage object for this page\n",
      "        layout = device.get_result()\n",
      "        # layout is an LTPage object which may contain child objects like LTTextBox, LTFigure, LTImage, etc.\n",
      "        text_content.append(parse_lt_objs(layout.objs, (i+1), images_folder))\n",
      "\n",
      "    return text_content\n",
      "\n",
      "and the updated get_pages() function becomes:\n",
      "\n",
      "def get_pages (pdf_doc, pdf_pwd='', images_folder='/tmp'):\n",
      "    \"\"\"Process each of the pages in this pdf file and print the entire text to stdout\"\"\"\n",
      "    print '\\n\\n'.join(with_pdf(pdf_doc, pdf_pwd, _parse_pages, *tuple([images_folder])))\n",
      "\n",
      "New in both functional signatures is images_folder, which is a parameter that refers to the place on the local filesystem where any extracted\n",
      "images will be be saved (this is also an example of why defining with_pdf() with an optional *args list comes in handy).\n",
      "\n",
      "Aggregating Text\n",
      "Within the _parse_pages() function, text_content is a new variable of type list, which collects the text of each page, and I've added an\n",
      "enumeration structure around doc.get_pages(), to keep track of which page we're accessing at any given time. This is useful for saving\n",
      "images correctly, since some pdf files use the same image name in multiple places to refer to different images (this creates problems for\n",
      "dumppdf.py's -i switch , for example).\n",
      "\n",
      "The new critical line in _parse_pages() is this one:\n",
      "\n",
      "text_content.append(parse_lt_objs(layout.objs, (i+1), images_folder))\n",
      "\n",
      "Since the tree of page objects is recursive in nature (e.g., a pdfminer.layout.LTFigure object may have multiple child objects), it's better to\n",
      "handle the actual text parsing and image collection in a separate function. That function, parse_lt_objs(), looks like this:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def parse_lt_objs (lt_objs, page_number, images_folder, text=[]):\n",
      "    \"\"\"Iterate through the list of LT* objects and capture the text or image data contained in each\"\"\"\n",
      "    text_content = [] \n",
      "\n",
      "    for lt_obj in lt_objs:\n",
      "        if isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\n",
      "            # text\n",
      "            text_content.append(lt_obj.get_text())\n",
      "        elif isinstance(lt_obj, LTImage):\n",
      "            # an image, so save it to the designated folder, and note it's place in the text \n",
      "            saved_file = save_image(lt_obj, page_number, images_folder)\n",
      "            if saved_file:\n",
      "                # use html style <img /> tag to mark the position of the image within the text\n",
      "                text_content.append('<img src=\"'+os.path.join(images_folder, saved_file)+'\" />')\n",
      "            else:\n",
      "                print >> sys.stderr, \"Error saving image on page\", page_number, lt_obj.__repr__\n",
      "        elif isinstance(lt_obj, LTFigure):\n",
      "            # LTFigure objects are containers for other LT* objects, so recurse through the children\n",
      "            text_content.append(parse_lt_objs(lt_obj.objs, page_number, images_folder, text_content))\n",
      "\n",
      "    return '\\n'.join(text_content)\n",
      "\n",
      "In this example, I'm concerned with just four objects which may appear within a pdfminer.layout.LTPage object:\n",
      "\n",
      "1. LTTextBox and LLTextLine (which, because the text extraction is exactly the same, I treat as one case)\n",
      "2. LTImage (which we'll try to save on to the local filesystem in the designated folder)\n",
      "3. LTFigure (which we'll treat as a simple container for other objects, hence the recursive call in that case)\n",
      "\n",
      "For the simple text and image extraction I'm doing here, this is enough. There is room for improvement, though, since I'm ignoring several\n",
      "types of pdfminer.layout.LT* objects which do appear in pdf pages.\n",
      "\n",
      "If you try to run get_pages() now, you might get this error, in the text_content.append(lt_obj.get_text()) line (it will depend on the content of\n",
      "the pdf file you're trying to parse, as well as how your instance of Python is configured, and whether or not you installed PDFMiner with\n",
      "cmap for CJK languages).\n",
      "\n",
      "UnicodeEncodeError: 'ascii' codec can't encode character u'\\u2014' in position 61: ordinal not in range(128)\n",
      "\n",
      "As Eliot explains, \"This error occurs when you pass a Unicode string containing non-English characters (Unicode characters beyond 128) to\n",
      "something that expects an ASCII bytestring. The default encoding for a Python bytestring is ASCII.\"\n",
      "\n",
      "This function, which I wrote after reading this article, solves the problem:\n",
      "\n",
      "def to_bytestring (s, enc='utf-8'):\n",
      "    \"\"\"Convert the given unicode string to a bytestring, using the standard encoding,\n",
      "    unless it's already a bytestring\"\"\"\n",
      "    if s:\n",
      "        if isinstance(s, str):\n",
      "            return s\n",
      "        else:\n",
      "            return s.encode(enc)\n",
      "\n",
      "So the updated version of parse_lt_objs() becomes:\n",
      "\n",
      "def parse_lt_objs (lt_objs, page_number, images_folder, text=[]):\n",
      "    \"\"\"Iterate through the list of LT* objects and capture the text or image data contained in each\"\"\"\n",
      "    text_content = [] \n",
      "\n",
      "    for lt_obj in lt_objs:\n",
      "        if isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\n",
      "            # text\n",
      "            text_content.append(lt_obj.get_text())\n",
      "        elif isinstance(lt_obj, LTImage):\n",
      "            # an image, so save it to the designated folder, and note it's place in the text \n",
      "            saved_file = save_image(lt_obj, page_number, images_folder)\n",
      "            if saved_file:\n",
      "                # use html style <img /> tag to mark the position of the image within the text\n",
      "                text_content.append('<img src=\"'+os.path.join(images_folder, saved_file)+'\" />')\n",
      "            else:\n",
      "                print >> sys.stderr, \"Error saving image on page\", page_number, lt_obj.__repr__\n",
      "        elif isinstance(lt_obj, LTFigure):\n",
      "            # LTFigure objects are containers for other LT* objects, so recurse through the children\n",
      "            text_content.append(parse_lt_objs(lt_obj.objs, page_number, images_folder, text_content))\n",
      "\n",
      "    return '\\n'.join(text_content)\n",
      "\n",
      "Running this version gives reasonable results on pdf files where the text is single-column, and without many sidebars, abstracts, summary\n",
      "quotes, or other fancy typesetting layouts.\n",
      "\n",
      "It really breaks down, though, in the case of multi-column pages: the resulting text_content jumps from one paragraph to the next, in no\n",
      "coherent order.\n",
      "\n",
      "PDFMiner does provide two grouping functions, group_textbox_lr_tb and group_textbox_tb_rl [lr=left-to-right, tb=top-to-bottom], but they do\n",
      "the grouping literally, without considering the likelihood that the content of one textbox logically belongs after another's.\n",
      "\n",
      "Fortunately, though, each object also provides a bbox (bounding box) attribute, which is a four-part tuple of the object's page position: (x0,\n",
      "y0, x1, y1).\n",
      "\n",
      "Using the bbox data, we can group the text according to its position and width, making it more likely the columns we join together this way\n",
      "represent the correct logical flow of the text.\n",
      "\n",
      "To aggregate the text this way, I added the following Python dictionary variable to the parse_lt_objs() code, just before iterating through the\n",
      "list of lt_objs: page_text={}.\n",
      "\n",
      "The key for each entry is a tuple of the bbox's (x0, x1) points, and the corresponding value is a list of text strings found within that bbox. The\n",
      "x0 value tells me the left offset for a given piece of text and the x1 value tells me how wide it is.\n",
      "\n",
      "So by grouping text which starts at the same horizontal plane and has the same width, I can aggregate all paragraphs belonging to the\n",
      "same column, regardless of their vertical position or length.\n",
      "\n",
      "Conceptually, each entry in the page_text dictionary represents all the text associated with each physical column.\n",
      "\n",
      "When I tried this the first time, I was surprised (though in retrospect, I shouldn't have been, since nothing about parsing pdfs is neat or\n",
      "clean), that two textboxes which look perfectly aligned visually have slightly different x0 and x1 values (at least according to PDFMiner).\n",
      "\n",
      "For example, one paragraph may have x0 and x1 values of 28.16 and 153.32 respectively, and the paragraph right underneath it had an x0\n",
      "value of 29.04 and an x1 value of 152.09.\n",
      "\n",
      "To get around this, I wrote the following update function, which assigns key tuples based on how close an (x0, x1) pair lies within an existing\n",
      "entry's key. The 20 percent value was arrived at by trial-and-error, and seems to be acceptable for most pdf files I tried.\n",
      "\n",
      "def update_page_text_hash (h, lt_obj, pct=0.2):\n",
      "    \"\"\"Use the bbox x0,x1 values within pct% to produce lists of associated text within the hash\"\"\"\n",
      "    x0 = lt_obj.bbox[0]\n",
      "    x1 = lt_obj.bbox[2]\n",
      "    key_found = False\n",
      "    for k, v in h.items():\n",
      "        hash_x0 = k[0]\n",
      "        if x0 >= (hash_x0 * (1.0-pct)) and (hash_x0 * (1.0+pct)) >= x0:\n",
      "            hash_x1 = k[1]\n",
      "            if x1 >= (hash_x1 * (1.0-pct)) and (hash_x1 * (1.0+pct)) >= x1:\n",
      "                # the text inside this LT* object was positioned at the same\n",
      "                # width as a prior series of text, so it belongs together\n",
      "                key_found = True\n",
      "                v.append(to_bytestring(lt_obj.get_text()))\n",
      "                h[k] = v\n",
      "    if not key_found:\n",
      "        # the text, based on width, is a new series,\n",
      "        # so it gets its own series (entry in the hash)\n",
      "        h[(x0,x1)] = [to_bytestring(lt_obj.get_text())]\n",
      "    return h\n",
      "\n",
      "With this in place, I could update the parse_lt_objs() to use it.\n",
      "\n",
      "def parse_lt_objs (lt_objs, page_number, images_folder, text=[]):\n",
      "    \"\"\"Iterate through the list of LT* objects and capture the text or image data contained in each\"\"\"\n",
      "    text_content = [] \n",
      "\n",
      "    page_text = {} # k=(x0, x1) of the bbox, v=list of text strings within that bbox width (physical column)\n",
      "    for lt_obj in lt_objs:\n",
      "        if isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\n",
      "            # text, so arrange is logically based on its column width\n",
      "            page_text = update_page_text_hash(page_text, lt_obj)\n",
      "        elif isinstance(lt_obj, LTImage):\n",
      "            # an image, so save it to the designated folder, and note it's place in the text \n",
      "            saved_file = save_image(lt_obj, page_number, images_folder)\n",
      "            if saved_file:\n",
      "                # use html style <img /> tag to mark the position of the image within the text\n",
      "                text_content.append('<img src=\"'+os.path.join(images_folder, saved_file)+'\" />')\n",
      "            else:\n",
      "                print >> sys.stderr, \"error saving image on page\", page_number, lt_obj.__repr__\n",
      "        elif isinstance(lt_obj, LTFigure):\n",
      "            # LTFigure objects are containers for other LT* objects, so recurse through the children\n",
      "            text_content.append(parse_lt_objs(lt_obj.objs, page_number, images_folder, text_content))\n",
      "\n",
      "    for k, v in sorted([(key,value) for (key,value) in page_text.items()]):\n",
      "        # sort the page_text hash by the keys (x0,x1 values of the bbox),\n",
      "        # which produces a top-down, left-to-right sequence of related columns\n",
      "        text_content.append('\\n'.join(v))\n",
      "\n",
      "    return '\\n'.join(text_content)\n",
      "\n",
      "The last block before the return statement sorts the page_text (x0, x1) keys so that the resulting text is returned in a top-down, left-to-right\n",
      "sequence, based on where the text appeared visually on the page.\n",
      "\n",
      "Extracting Images\n",
      "The last thing to discuss in this example is the extraction of images.\n",
      "\n",
      "As I mentioned above, this area needs improvement, since it seems that I can only extract jpeg images using PDFMiner (though to be fair to\n",
      "Yusuke, he does describe it as a tool that \"focuses entirely on getting and analyzing text data \", so perhaps doing more than jpeg is out-of-\n",
      "scope for this library).\n",
      "\n",
      "Within parse_lt_objs(), the following function is called if an LTImage is found; it was based on studying the dumppdf.py source code and\n",
      "how it handled image extraction requests:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def save_image (lt_image, page_number, images_folder):\n",
      "    \"\"\"Try to save the image data from this LTImage object, and return the file name, if successful\"\"\"\n",
      "    result = None\n",
      "    if lt_image.stream:\n",
      "        file_stream = lt_image.stream.get_rawdata()\n",
      "        file_ext = determine_image_type(file_stream[0:4])\n",
      "        if file_ext:\n",
      "            file_name = ''.join([str(page_number), '_', lt_image.name, file_ext])\n",
      "            if write_file(images_folder, file_name, lt_image.stream.get_rawdata(), flags='wb'):\n",
      "                result = file_name\n",
      "    return result\n",
      "\n",
      "The save_image() function needs the following two supporting functions defined:\n",
      "\n",
      "def determine_image_type (stream_first_4_bytes):\n",
      "    \"\"\"Find out the image file type based on the magic number comparison of the first 4 (or 2) bytes\"\"\"\n",
      "    file_type = None\n",
      "    bytes_as_hex = b2a_hex(stream_first_4_bytes)\n",
      "    if bytes_as_hex.startswith('ffd8'):\n",
      "        file_type = '.jpeg'\n",
      "    elif bytes_as_hex == '89504e47':\n",
      "        file_type = ',png'\n",
      "    elif bytes_as_hex == '47494638':\n",
      "        file_type = '.gif'\n",
      "    elif bytes_as_hex.startswith('424d'):\n",
      "        file_type = '.bmp'\n",
      "    return file_type\n",
      "\n",
      "The determine_image_type() function is based on the concept of magic numbers, where it's (sometimes) possible to tell what a binary\n",
      "stream means by exmaing the first two or fours bytes.\n",
      "\n",
      "In theory, a pdf file can have any of these image types, but in practice, the only one PDFMiner can seem to find as an LTImage object are\n",
      "jpegs.\n",
      "\n",
      "def write_file (folder, filename, filedata, flags='w'):\n",
      "    \"\"\"Write the file data to the folder and filename combination\n",
      "    (flags: 'w' for write text, 'wb' for write binary, use 'a' instead of 'w' for append)\"\"\"\n",
      "    result = False\n",
      "    if os.path.isdir(folder):\n",
      "        try:\n",
      "            file_obj = open(os.path.join(folder, filename), flags)\n",
      "            file_obj.write(filedata)\n",
      "            file_obj.close()\n",
      "            result = True\n",
      "        except IOError:\n",
      "            pass\n",
      "    return result\n",
      "\n",
      "The write_file() function is just basic file IO, but it does some convenient things around checking that the designated folder exists, too.\n",
      "\n",
      "Finally, to support all three image saving functions, we need the following python imports:\n",
      "\n",
      "import sys\n",
      "import os\n",
      "from binascii import b2a_hex\n",
      "\n",
      "Sample Results\n",
      "So, how well does it work? It's surprisingly good, as it turns out.\n",
      "\n",
      "Here's an example from using the above code to process the Hacker Monthly Issue 2 pdf file (this was part of the process I used to convert\n",
      "this file to e-book format for inclusion in the Fifobooks Catalog).\n",
      "\n",
      "Page 5, which looks like this visually:\n",
      "\n",
      "came out like this:\n",
      "\n",
      "<img src=\"/tmp/5_Im0.jpeg\" />\n",
      "\"Leave the ad revenue and crazy \n",
      "business model revenue streams \n",
      "to the startups with venture \n",
      "funding.\" \n",
      "\n",
      "on the company. But the advantage \n",
      "here is that after a few months off \n",
      "the ground you'll have a clear sense \n",
      "of how soon that day can come. \n",
      "Another advantage of a bootstrapped \n",
      "company on the SaaS model is that \n",
      "it's really easy to calculate your cash \n",
      "flow.\n",
      "It goes without saying that the \n",
      "people you work with should have \n",
      "complementary skills to your own, \n",
      "but the bootstrapper's \"slow but \n",
      "steady\" mindset is just as important \n",
      "to the health of your company. \n",
      "you'll find a lot of people may not \n",
      "be comfortable with this approach. \n",
      "Weed those people out as co-found-\n",
      "ers when you're bootstrapping a \n",
      "company. A one and done approach \n",
      "won't work here.\n",
      "\n",
      "off Hours\n",
      "Almost every bootstrapped company \n",
      "begins as an off-hours tinkering \n",
      "project. That's true of Carbonmade, \n",
      "which Dave built for himself first; \n",
      "that's true of TypeFrag, which I built \n",
      "over the course of a week during my \n",
      "\n",
      "sophomore year in college; that's \n",
      "true of 37signals' Basecamp, true of \n",
      "Anthony's Hype Machine and lots of \n",
      "other companies.\n",
      "\n",
      "The good thing about bootstrap-\n",
      "ping is that you don't need to spend \n",
      "\n",
      "ping is that you don't need to spend \n",
      "a single penny outside of server \n",
      "costs and you can even do most \n",
      "things locally before having to pay \n",
      "any money on a server. your biggest \n",
      "expense is time, and that's why off \n",
      "hours are so important.\n",
      "\n",
      "Consult on the Side\n",
      "The way we started Carbonmade, \n",
      "the way 37signals started, the way \n",
      "Harvest started, and many other \n",
      "startups too, was by first running a \n",
      "consulting shop. We ran a design con-\n",
      "sulting company called nterface that \n",
      "Carbonmade grew out of. It's great, \n",
      "because the money you're bringing \n",
      "in through client work tides you over \n",
      "while you're waiting for your startup \n",
      "to grow.\n",
      "Carbonmade was live for nearly 18 \n",
      "months before we started working \n",
      "\n",
      "on it full-time. During those first \n",
      "18 months, we were taking on lots \n",
      "of client work to pay our bills. The \n",
      "great thing about consulting through \n",
      "the early months is that you can \n",
      "take on fewer and fewer jobs as your \n",
      "revenue builds up. For example, you \n",
      "may need a dozen large projects \n",
      "during the first year and only two or \n",
      "three during the second year. That \n",
      "was the case for us.\n",
      "I know of other successful \n",
      "bootstrapped companies that during \n",
      "the first year would take on a single \n",
      "client project for a month or two, \n",
      "charging an appropriate amount, and \n",
      "that would give them just enough \n",
      "leeway to work on their startup for \n",
      "two or three months. Then they'd \n",
      "rinse and repeat. They did this \n",
      "for the first year and a half before \n",
      "making enough money to work on \n",
      "their startup full-time.\n",
      "\n",
      "there's no need to Rush\n",
      "When you're bootstrapping there's \n",
      "no rush to get things out the door, \n",
      "even though that's all you hear these \n",
      "\n",
      "  5\n",
      "\n",
      "While there were some small problems around capitalization and spacing, the conversion did recognize and save the background image, it\n",
      "distinguished the summary quote as being separate from the rest of the text, and the columns were merged correctly, flowing in the same\n",
      "manner the author wrote them.\n",
      "\n",
      "Room for Improvement\n",
      "There are several things I'd like to be able to do better; some probably require changes to PDFMiner itself, while others are things in my\n",
      "code which I should improve.\n",
      "\n",
      "Column Merging  while the fuzzy heuristic I described works well for the pdf files I've parsed so far, I can imagine more complex\n",
      "documents where it would break-down (perhaps this is where the analysis should be more sophisticated, and not ignore so many\n",
      "types of pdfminer.layout.LT* objects).\n",
      "Image Extraction  I'd like to be able to be at least as good as pdftoimages, and save every file in ppm or pnm default format, but I'm\n",
      "not sure what I could be doing differently\n",
      "Title and Heading Capitalization  this seems to be an issue with PDFMiner, since I get similar results in using the command line\n",
      "tools, but it is annoying to have to go back and fix all the mis-capitalizations manually, particularly for larger documents.\n",
      "Title and Heading Fonts and Spacing  a related issue, though probably something in my own code, is that those same title and\n",
      "paragraph headings aren't distinguished from the rest of the text. In many cases, I have to go back and add vertical spacing and font\n",
      "\n",
      "Failed\n",
      "attributes for those manually.\n",
      "Page Number Removal  originally, I thought I could just use a regex for an all-numeric value on a single physical line, but each\n",
      "document does page numbering slightly differently, and it's very difficult to get rid of these without manually proofreading each page.\n",
      "Footnotes  handling these where the note and the reference both appear on the same page is hard enough, but doing it when they\n",
      "span different (even consecutive) pages is worse.\n",
      "\n",
      "Failed\n",
      "Archived from the original at http://denis.papathanasiou.org/\n",
      " Bitcoin Donate: 14TM4ADKJbaGEi8Qr8dh4KfPBQmjTshkZ2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import importlib,sys\n",
    "importlib.reload(sys)\n",
    "from pdfminer.pdfparser import PDFParser, PDFDocument\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LTTextBoxHorizontal, LAParams\n",
    "from pdfminer.pdfinterp import PDFTextExtractionNotAllowed\n",
    " \n",
    "def parse(DataIO, save_path):\n",
    "    #对应图片1\n",
    "    #用文件对象创建一个PDF文档分析器\n",
    "    parser = PDFParser(DataIO)\n",
    "    #创建一个PDF文档\n",
    "    doc = PDFDocument()\n",
    "    #分析器和文档相互连接\n",
    "    parser.set_document(doc)\n",
    "    doc.set_parser(parser)\n",
    "    #提供初始化密码，没有默认为空\n",
    "    doc.initialize()\n",
    "    #对应图片2\n",
    "    #检查文档是否可以转成TXT，如果不可以就忽略\n",
    "    if not doc.is_extractable:\n",
    "        raise PDFTextExtractionNotAllowed\n",
    "    else:\n",
    "        #创建PDF资源管理器，来管理共享资源\n",
    "        rsrcmagr = PDFResourceManager()\n",
    "        #创建一个PDF设备对象\n",
    "        laparams = LAParams()\n",
    "        #将资源管理器和设备对象聚合\n",
    "        device = PDFPageAggregator(rsrcmagr, laparams=laparams)\n",
    "        #创建一个PDF解释器对象\n",
    "        interpreter = PDFPageInterpreter(rsrcmagr, device)\n",
    "        \n",
    "        #对应图片3\n",
    "        #循环遍历列表，每次处理一个page内容\n",
    "        #doc.get_pages()获取page列表\n",
    "        for page in doc.get_pages():\n",
    "            interpreter.process_page(page)\n",
    "            #接收该页面的LTPage对象（布局分析）\n",
    "            layout = device.get_result()\n",
    "            #这里的layout是一个LTPage对象 里面存放着page解析出来的各种对象\n",
    "            #一般包括LTTextBox，LTFigure，LTImage，LTTextBoxHorizontal等等一些对像\n",
    "            #想要获取文本就得获取对象的text属性\n",
    "            for x in layout:\n",
    "                try:\n",
    "                    if(isinstance(x, LTTextBoxHorizontal)):\n",
    "                        with open('%s' % (save_path), 'a') as f:\n",
    "                            result = x.get_text()\n",
    "                            print (result)\n",
    "                            f.write(result + \"\\n\")\n",
    "                except:\n",
    "                    print(\"Failed\")\n",
    "\n",
    "\n",
    "#解析本地PDF文本，保存到本地TXT\n",
    "with open(r'.\\Desktop\\pdfminer.pdf','rb') as pdf_html:\n",
    "    parse(pdf_html, r'.\\Desktop\\pdfminer.txt')\n",
    "#解析网络上的PDF，保存文本到本地\n",
    "# url = \"https:\"\n",
    "# pdf_html = urllib.urlopen(url).read()\n",
    "# DataIO = StringIO(pdf_html)\n",
    "# parse_pdf(DataIO, r'E:\\parse_pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 局限性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果PDF中只含有文本，那么可以完全解析出来，含有的图片无法获取，因为pdfminer只能获取PDF中的文本。\n",
    "- 如果这个PDF本身就不能提取文本会在\"if not doc.is_extractable:raise PDFTextExtractionNotAllowed\"抛出异常，处理带有水印PDF会抛出这个异常。\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT的全称为Bidirectional Encoder Representation from Transformers，是一个预训练的语言表征模型。它强调了不再像以往一样采用传统的单向语言模型或者把两个单向语言模型进行浅层拼接的方法进行预训练，而是采用新的masked language model（MLM），以致能生成深度的双向语言表征。\n",
    "\n",
    "主要优点：\n",
    "- 采用MLM对双向的Transformers进行预训练，以生成深层的双向语言表征。\n",
    "- 预训练后，只需要添加一个额外的输出层进行微调，就可以在各种各样的下游任务中取得很好的表现。在这过程中并不需要对BERT进行任务特定的结构修改。\n",
    "\n",
    "提出论文：BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding（https://arxiv.org/pdf/1810.04805.pdf ）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT的结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 总体结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以往的预训练模型的结构会受到单向语言模型（从左到右或者从右到左）的限制，因而也限制了模型的表征能力，使其只能获取单方向的上下文信息。而BERT利用MLM进行预训练并且采用深层的双向Transformer组件（单向的Transformer一般被称为Transformer decoder，其每一个token（符号）只会注意到到目前往左的token。而双向的Transformer则被称为Transformer encoder，其每一个token会注意到到所有的token来构建整个模型，因此最终生成能融合左右上下文信息的深层双向语言表征。\n",
    "\n",
    "隐藏了Transformer的详细结构后，我们就可以用一个只有输入和输出的黑盒子来表示它:\n",
    "![Transformer](.\\Desktop\\T-1.png)\n",
    "\n",
    "而Transformer又可以进行堆叠，形成一个更深的神经网络：\n",
    "![Transformer](.\\Desktop\\T-2.png)\n",
    "\n",
    "最终，经过多层Transformer结构的堆叠后，形成BERT的主体结构：\n",
    "![Transformer](.\\Desktop\\bert.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BERT的输入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![input](.\\Desktop\\input.png)\n",
    "\n",
    "- token embeddings使用WordPiece嵌入，WordPiece的一种主要的实现方式叫做BPE（Byte-Pair Encoding）双字节编码。BPE的过程可以理解为把一个单词再拆分，比如\"loved\",\"loving\",\"loves\"这三个单词，其实本身的语义都是“爱”的意思，但是如果我们以单词为单位，那它们就算不一样的词，在英语中不同后缀的词非常的多，就会使得词表变的很大，训练速度变慢，训练的效果也不是太好。BPE算法通过训练，能够把上面的3个单词拆分成\"lov\",\"ed\",\"ing\",\"es\"几部分，这样可以把词的本身的意思和时态分开，有效的减少了词表的数量。\n",
    "- positional embeddings用来表示句子中单词的位置信息。\n",
    "- segement embeddings则是对于句子整体的，不同的句子有不同的项，它用来实现句子级别的任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "由于BERT是一个预训练模型，其必须要适应各种各样的自然语言任务，因此模型所输入的序列必须有能力包含一句话（文本情感分类，序列标注任务）或者两句话以上（文本摘要，自然语言推断，问答任务）。\n",
    "\n",
    "为了完成具体的分类任务，除了单词的token之外，作者还在输入的每一个序列开头都插入特定的分类token（[CLS]），该分类token对应的最后一个Transformer层输出被用来起到聚集整个序列表征信息的作用。\n",
    "\n",
    "为了完成两个句子以上的任务，Bert在序列tokens中把分割token（[SEP]）插入到每个句子后，以分开不同的句子tokens，并为每一个token表征都添加一个可学习的segement embedding来指示其属于句子A还是句子B。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BERT的输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer的特点就是有多少个输入就有多少个对应的输出，C为分类token（[CLS]）对应最后一个Transformer的输出，$T_i$ 则代表其他token对应最后一个Transformer的输出。对于一些token级别的任务（如，序列标注和问答任务），就把$T_i$输入到额外的输出层中进行预测。对于一些句子级别的任务（如自然语言推断和情感分类任务），就把C输入到额外的输出层中，这里也就解释了为什么要在每一个token序列前都要插入特定的分类token。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT的预训练任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 预训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预训练就是在拿样本数据对模型进行训练之前做的训练。在NLP的下游任务（比如机器翻译、阅读理解等）中，可以使用的样本数据是比较少的，因为这些任务需要的都是经过专门标注的数据，这样就使得拿这些样本数据直接训练出来的模型效果比较一般，因此就需要对模型进行预训练了。\n",
    "\n",
    "预训练的目的就是，提前训练好这些下游任务中底层的、共性的部分模型，然后再用下游任务各自的样本数据来训练各自的模型，这样就可以极大地加快收敛速度。在这里举一个CV的例子，对于人脸识别和数字识别两种任务，显然它们有很多的区别，然而在用CNN进行训练的时候，其实比较浅的几层网络学习到的特征是很相似的，都是类似于边角线的这类基础特征，因此我们可以认为这几层网络可以共用，如果我们能够预先训练好这部分，那么模型的训练收敛速度将会大大加快。\n",
    "\n",
    "对于NLP的下游任务，尽管它们的最终目标各不相同，但是它们也有着共同的、也是必须首先要做的东西，那就是要让模型理解文档中的单词和句子，具体说就是将文本中的无法直接计算的单词转变为可以计算的向量或者矩阵等形式，并且这些数字化的向量要能够比较好地反映出对应单词在句子中的含义，这就NLP中预训练的目的。在NLP中采用的是语言模型来做预训练，从最初的word embedding到ELMO、再到GPT，以及现在的BERT，其实做的都是上面说的这件事，只不过效果变得越来越好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP领域可以利用大规模文本数据的自监督性质来构建预训练任务。因此BERT构建了两个预训练任务，分别是**Masked Language Model(MLM)** 和**Next Sentence Prediction(NSP)**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Masked Language Model(MLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLM是BERT能够不受单向语言模型所限制的原因。简单来说就是以15%的概率用mask token（[MASK]）随机地对每一个训练序列中的token进行替换，然后预测出[MASK]位置原有的单词。然而，由于[MASK]并不会出现在下游任务的微调（fine-tuning）阶段，因此预训练阶段和微调阶段之间产生了不匹配（这里很好解释，就是预训练的目标会令产生的语言表征对[MASK]敏感，但是却对其他token不敏感）。因此BERT采用了以下策略来解决这个问题：\n",
    "\n",
    "首先在每一个训练序列中以15%的概率随机地选中某个token位置用于预测，假如是第i个token被选中，则会被替换成以下三个token之一：\n",
    "\n",
    "1）80%的时候是[MASK]。如：my dog is hairy——>my dog is [MASK]\n",
    "\n",
    "2）10%的时候是随机的其他token。如：my dog is hairy——>my dog is apple\n",
    "\n",
    "3）10%的时候是原来的token（保持不变，个人认为是作为2中所对应的负类）。如：my dog is hairy——>my dog is hairy\n",
    "\n",
    "再用该位置对应的 $T_i$ 去预测出原来的token（输入到全连接，然后用softmax输出每个token的概率，最后用交叉熵计算loss）。\n",
    "\n",
    "该策略令到BERT不再只对[MASK]敏感，而是对所有的token都敏感，以致能抽取出任何token的表征信息。这里给出论文中关于该策略的实验数据：\n",
    "\n",
    "![MLM](.\\Desktop\\MLM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next Sentence Prediction(NSP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一些如问答、自然语言推断等任务需要理解两个句子之间的关系，而MLM任务倾向于抽取token层次的表征，因此不能直接获取句子层次的表征。为了使模型能够有能力理解句子间的关系，BERT使用了NSP任务来预训练，简单来说就是预测两个句子是否连在一起。具体的做法是：对于每一个训练样例，我们在语料库中挑选出句子A和句子B来组成，50%的时候句子B就是句子A的下一句（标注为IsNext），剩下50%的时候句子B是语料库中的随机句子（标注为NotNext）。接下来把训练样例输入到BERT模型中，用[CLS]对应的C信息去进行二分类的预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例如：\n",
    "\n",
    "Input1=[CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP]\n",
    "\n",
    "Label1=IsNext\n",
    "\n",
    "Input2=[CLS] the man [MASK] to the store [SEP] penguin [MASK] are flight ##less birds [SEP]\n",
    "\n",
    "Label2=NotNext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT的微调（fine-tuning）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过上面的方法，我们就实现了BERT模型的预训练，对于特定下游任务的模型，可以通将BERT与一个额外的输出层结合而形成，这样需要重新学习的参数量就会比较小，如下图所示，只需要按BERT模型要求的格式输入训练数据，就可以完成不同的下游任务。\n",
    "\n",
    "![fine-tuning](.\\Desktop\\fine-tuning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- keras_bert：是 CyberZHG 封装好了Keras版的Bert，可以直接调用官方发布的预训练权重，需要keras版本大于等于2.4.3。\n",
    "- bert4keras：keras4bert 是基于 keras-bert 重新编写的一个 keras 版的 bert，可以适配 albert，只需要在 build_bert_model 函数里加上model='albert'，使用体验和 keras_bert 差不多，需要keras版本小于等于2.3.1。\n",
    "- 以下代码部分使用keras_bert完成。\n",
    "- 需要提前下载TensorFlow。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 keras-bert 里面，使用 Tokenizer 会将文本拆分成字并生成相应的id。\n",
    "\n",
    "我们需要提供一个字典，字典存放着 token 和 id 的映射，以及 BERT 里特别的 token。\n",
    "\n",
    "下面是一个例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_bert import Tokenizer\n",
    "\n",
    "# 创建字典\n",
    "token_dict = {\n",
    "    '[CLS]': 0,\n",
    "    '[SEP]': 1,\n",
    "    'un': 2,\n",
    "    '##beauti': 3,\n",
    "    '##ful': 4,\n",
    "    '[UNK]': 5,\n",
    "}\n",
    "\n",
    "tokenizer = Tokenizer(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'un', '##beauti', '##ful', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# 拆分单词\n",
    "print(tokenizer.tokenize('unbeautiful'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3, 4, 1]\n",
      "[0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# indices 表示字对应的索引\n",
    "# segements 表示索引对应位置上的字属于第几句话\n",
    "# 此处只有一个单词，也就是只有一句话，所以segements均为0\n",
    "indices, segements = tokenizer.encode('unbeautiful')\n",
    "print(indices)\n",
    "print(segements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们用同样的字典，拆分不存在字典中的单词，结果如下，可以看到英语中会直接把不存在字典中的部分直接按字母拆分。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'un', '##k', '##n', '##o', '##w', '##n', '[SEP]']\n",
      "[0, 2, 5, 5, 5, 5, 5, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize('unknown'))\n",
    "indices, segements = tokenizer.encode('unknown')\n",
    "print(indices)\n",
    "print(segements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果输入两句话的例子，encode 函数中 我们可以带上参数 max_len，只看文本拆分出来的 max_len 个字\n",
    "\n",
    "如果拆分完的字不超过max_len，则用 0 填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'un', '##beauti', '##ful', '[SEP]', 'un', '##k', '##n', '##o', '##w', '##n', '[SEP]']\n",
      "[0, 2, 3, 4, 1, 2, 5, 5, 5, 5, 5, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(first = 'unbeautiful', second = 'unknown'))\n",
    "indices, segements = tokenizer.encode(first = 'unbeautiful', second = 'unknown', max_len = 15)\n",
    "print(indices)\n",
    "print(segements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 使用预训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用 load_trained_model_from_checkpoint() 函数使用本地已经下载好的预训练模型，可以从 BERT 的 github 上获取下载地址：\n",
    "\n",
    "- 谷歌BERT地址：https://github.com/google-research/bert\n",
    "- 中文预训练BERT-wwm：https://github.com/ymcui/Chinese-BERT-wwm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "# 设置预训练模型的路径\n",
    "pretrained_path = '.\\Desktop\\chinese_L-12_H-768_A-12'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n",
    " \n",
    "# 构建字典\n",
    "# keras_bert 中的 load_vocabulary() 函数 传入 vocab_path 即可\n",
    "from keras_bert import load_vocabulary\n",
    "token_dict = load_vocabulary(vocab_path)\n",
    " \n",
    "# import codecs\n",
    "# token_dict = {}\n",
    "# with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
    "#     for line in reader:\n",
    "#         token = line.strip()\n",
    "#         token_dict[token] = len(token_dict)\n",
    " \n",
    "# Tokenization\n",
    "from keras_bert import Tokenizer\n",
    "tokenizer = Tokenizer(token_dict)\n",
    "\n",
    "# 加载预训练模型\n",
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "model = load_trained_model_from_checkpoint(config_path, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 6427, 6241, 3563, 1798, 102, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[CLS] [-0.6339440941810608, 0.2029208391904831, 0.08104995638132095, -0.03268882632255554, 0.5675359964370728]\n",
      "语 [-0.7589294910430908, 0.09625153243541718, 1.0723156929016113, 0.006224863231182098, 0.6886612176895142]\n",
      "言 [0.549795389175415, -0.7931230664253235, 0.4425913393497467, -0.7123056054115295, 1.2054001092910767]\n",
      "模 [-0.2921682596206665, 0.6063656210899353, 0.4984249174594879, -0.4249313473701477, 0.42672020196914673]\n",
      "型 [-0.7458059191703796, 0.49491360783576965, 0.7189143896102905, -0.8728531002998352, 0.8354967832565308]\n",
      "[SEP] [-0.875252902507782, -0.21610864996910095, 1.3399081230163574, -0.10673174262046814, 0.3961647152900696]\n"
     ]
    }
   ],
   "source": [
    "text = '语言模型'\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "indices, segments = tokenizer.encode(first=text, max_len=512)\n",
    "print(indices[:10])\n",
    "print(segments[:10])\n",
    " \n",
    "# 提取特征\n",
    "import numpy as np\n",
    "predicts = model.predict([np.array([indices]), np.array([segments])])[0]\n",
    "for i, token in enumerate(tokens):\n",
    "    print(token, predicts[i].tolist()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '语', '言', '模', '型', '[SEP]']\n",
      "['[CLS]', '你', '好', '[SEP]']\n",
      "[101, 6427, 6241, 3563, 1798, 102, 872, 1962, 102, 0]\n",
      "[0, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "[CLS] [-0.3404940366744995, 0.5169008374214172, 0.8958086371421814, -0.5850769281387329, 0.16207797825336456]\n",
      "语 [-0.6919724345207214, 0.37331491708755493, 1.3196660280227661, -0.08652088046073914, 0.5522887706756592]\n",
      "言 [0.6706030368804932, -0.5946149826049805, 0.47515609860420227, -0.7590193748474121, 0.9860217571258545]\n",
      "模 [-0.42274874448776245, 0.7286521792411804, 0.5555981993675232, -0.43479907512664795, 0.3921997547149658]\n",
      "型 [-0.5974085330963135, 0.5976639986038208, 0.7734528183937073, -1.0439555644989014, 0.8142779469490051]\n",
      "[SEP] [-1.1663368940353394, 0.5416533350944519, 1.3963817358016968, 0.014762148261070251, -0.2048124074935913]\n",
      "[CLS] [-0.3404940366744995, 0.5169008374214172, 0.8958086371421814, -0.5850769281387329, 0.16207797825336456]\n",
      "你 [-0.6919724345207214, 0.37331491708755493, 1.3196660280227661, -0.08652088046073914, 0.5522887706756592]\n",
      "好 [0.6706030368804932, -0.5946149826049805, 0.47515609860420227, -0.7590193748474121, 0.9860217571258545]\n",
      "[SEP] [-0.42274874448776245, 0.7286521792411804, 0.5555981993675232, -0.43479907512664795, 0.3921997547149658]\n"
     ]
    }
   ],
   "source": [
    "text1 = '语言模型'\n",
    "text2 = '你好'\n",
    "tokens1 = tokenizer.tokenize(text1)\n",
    "print(tokens1)\n",
    "tokens2 = tokenizer.tokenize(text2)\n",
    "print(tokens2)\n",
    " \n",
    "indices_new, segments_new = tokenizer.encode(first=text1, second=text2 ,max_len=512)\n",
    "print(indices_new[:10])\n",
    "print(segments_new[:10])\n",
    " \n",
    "# 提取特征\n",
    "import numpy as np\n",
    "predicts_new = model.predict([np.array([indices_new]), np.array([segments_new])])[0]\n",
    "for i, token in enumerate(tokens1):\n",
    "    print(token, predicts_new[i].tolist()[:5])\n",
    "for i, token in enumerate(tokens2):\n",
    "    print(token, predicts_new[i].tolist()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill with:  ['数', '学']\n"
     ]
    }
   ],
   "source": [
    "#加载语言模型\n",
    "model = load_trained_model_from_checkpoint(config_path, checkpoint_path, training=True)\n",
    " \n",
    "token_dict_rev = {v: k for k, v in token_dict.items()}\n",
    " \n",
    "token_ids, segment_ids = tokenizer.encode(u'数学是利用符号语言研究数量、结构、变化以及空间等概念的一门学科', max_len=512)\n",
    "# mask掉“数学”\n",
    "token_ids[1] = token_ids[2] = tokenizer._token_dict['[MASK]']\n",
    "masks = np.array([[0, 1, 1] + [0] * (512 - 3)])\n",
    " \n",
    "# 模型预测被mask掉的部分\n",
    "predicts = model.predict([np.array([token_ids]), np.array([segment_ids]), masks])[0]\n",
    "pred_indice = predicts[0][1:3].argmax(axis=1).tolist()\n",
    "print('Fill with: ', list(map(lambda x: token_dict_rev[x], pred_indice)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FinBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提出论文：FinBERT: Financial Sentiment Analysis with Pre-trained Language Models（https://openreview.net/pdf?id=HylznxrYDr ）首次将BERT应用于金融领域，提出了FinBERT。\n",
    "\n",
    "背景：尽管当前很多情感分析方法在商品评论或者电影评论能获得很好的效果，但是这些方法在一些特定领域诸如金融，这些方法的效果还是远远落后。主要是有两方面原因，一是这些领域有许多特定的专用词，二是缺乏大规模高质量的标注数据。\n",
    "\n",
    "作者在一个更庞大的通用的金融语料集上预训练Bert,然后在特定的分类金融语料集上对上一步预训练好的Bert进行微调。具体过程如下图所示，具体的分类任务可以直接加到BERT模型的下游。\n",
    "\n",
    "![finbert](.\\Desktop\\finbert.png)\n",
    "\n",
    "预训练Bert的数据集介绍：作者构建的一个新的数据集TRC2-financial，它是在Reuters的RC2中根据一些金融关键词过滤得到的一个子集，包括46143个文档，超过29000000个单词和接近400000条句子。文章主要的情感分析数据集是Financial PhraseBank，是从LexisNexis数据库里的金融新闻中随机选中得到的4845条句子，对应的的标签由16个金融和商业背景的人打出，具体分布情况如下表所示，可以看到不同人对不同新闻判断是由一定差异的，只有不到50%的新闻所有人的观点是一致的。另一个数据集FiQA包括1174个金融新闻标题和对应得情感得分，对应得分从-1到1，其中1表示最积极。\n",
    "\n",
    "![DISTRIBUTION](.\\Desktop\\DISTRIBUTION.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
