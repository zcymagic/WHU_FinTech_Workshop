{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend Factor in China      \n",
    "——Yang Liu, Guofu Zhou and Yingzi Zhu (Version: February 8, 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "**Backgroud**:    \n",
    "China is the world's second largest stock market, it is important to examine how well asset pricing theory developed previously in the US applies in China.      \n",
    "**Motivation**:      \n",
    "1.The Fama-French 3-factor model is one of the most important models for pricing US stocks, but its replication doesn't work well for Chinese stocks.          \n",
    "2.LSY-3 (unique features of small stocks) still cannot explain certain important anomalies.   \n",
    "3.Another important feature: individual investors contribute about 80% of the total trading volume    \n",
    "**Main Work**:      \n",
    "1.construct a trend factor specific to China to summarize succinctly the impact of past price and volume trends on future expected stock returns     \n",
    "2.propose a 4-factor model consisting of the market, size, value, and trend    \n",
    "**Main Conclusions**:    \n",
    "1.Trend factor stands out in terms of average return, Sharpe ratio, the maximum drawdown.    \n",
    "2.Our 4-factor model improves the state of art models with greater explanatory power. (GRS test)   \n",
    "3.Our model is able to explain all reported pricing anomalies in China, including those not captured by LSY-3 or LSY-4. (GRS test)   \n",
    "4.Our model also excels in explaining mutual fund returns with smaller aggregate pricing errors than LSY-3 and LSY-4.(GRS test)   \n",
    "5.The Sharpe ratio of our 4-factor model is substantially greater than others.(Barillas and Shanken (2017))   \n",
    "6.Our 4-factor model outperforms substantially the replication of Fama and French's (2015) 5-factor model and Hou, Xue, and Zhang's (2015) q-factor model in China.   \n",
    "**Innovations**:    \n",
    "1.Our factor has volume information.(compared with Han, Zhou and Zhu(2016))   \n",
    "2.A new asset pricing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology:\n",
    "**Trend signals**:    \n",
    "1.the moving average (MA) price/volume signals with lag L (for each stock in each month)  \n",
    "2.normalize the MA price/volume signals by the closing price/trading volume on on the last trading day for stationarity   \n",
    "3.run the predictive cross-section regression in each month with signals on both price and volume to get the coefficient of the MA signal of price/volume   \n",
    "4.forecast coefficient of price/volume MA signals (exponential moving average)    \n",
    "5.get the expected return based on the trend signals for each stock in each month (ERtrend)   \n",
    "Note:    \n",
    "1.Following Brock, Lakonishok, and LeBaron (1992) and Han, Zhou, and Zhu (2016), we consider the MA signals with lag lengths 3-, 5-, 10-, 20-, 50-, 100-, 200-, 300-, and 400-days to capture short-, intermediate-, and long-term trends.     \n",
    "2.We skip 38 months to estimate the forecasting coefficients, the effiective sample period for our study is from January 2005 to July 2018.   \n",
    "3.During the suspension of trade period, we use the data right before the suspension to fill in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![0.png](https://i.loli.net/2020/06/20/P7HeFiVcyhSsfpr.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import scipy.stats as st\n",
    "from pandas.core.frame import DataFrame\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日收盘价、交易额数据\n",
    "a1 = pd.read_csv('1.csv')\n",
    "a2 = pd.read_csv('2.csv')\n",
    "a3 = pd.read_csv('3.csv')\n",
    "a4 = pd.read_csv('4.csv')\n",
    "a5 = pd.read_csv('5.csv')\n",
    "a6 = pd.read_csv('6.csv')\n",
    "a7 = pd.read_csv('7.csv')\n",
    "a8 = pd.read_csv('8.csv')\n",
    "a9 = pd.read_csv('9.csv')\n",
    "a10 = pd.read_csv('10.csv')\n",
    "a11 = pd.read_csv('11.csv')\n",
    "a12 = pd.read_csv('12.csv')\n",
    "\n",
    "data = pd.concat([a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11,a12])\n",
    "data['Trddt'] =  pd.to_datetime(data['Trddt'])\n",
    "data['year'] = data['Trddt'].dt.year\n",
    "data['month'] = data['Trddt'].dt.month\n",
    "data = data[(data['Trddt'] <= '2018-07-02 00:00:00')]\n",
    "#取出每月交易日最后一天, 从1999.12-2018.7\n",
    "trade1d = data.drop_duplicates(subset=['year','month'], keep='last').iloc[35:,:]['Trddt']\n",
    "\n",
    "#取出日度的收盘价和成交额数据\n",
    "dClsprc = pd.pivot_table(data,index='Trddt',columns='Stkcd',values='Clsprc')\n",
    "dDnvaltrd  = pd.pivot_table(data,index='Trddt',columns='Stkcd',values='Dnvaltrd')\n",
    "dDretwd = pd.pivot_table(data,index='Trddt',columns='Stkcd',values='Dretwd')\n",
    "#交易暂停时收盘价和成交额数据按前一个交易日的数据进行补充\n",
    "def fill_in(dataset1, dataset2):\n",
    "    allindex = list(pd.date_range('1997-1-2','2018-7-1',freq='D'))\n",
    "    realindex = list(dataset1.index)\n",
    "    needindex = []\n",
    "    for i in allindex:\n",
    "        if i not in realindex:\n",
    "            needindex.append(i)\n",
    "    need1 = pd.DataFrame(index=needindex,columns=dClsprc.columns)\n",
    "    need2 = pd.DataFrame(index=needindex,columns=dClsprc.columns)\n",
    "    for i in needindex:\n",
    "        k=1\n",
    "        while True:\n",
    "            if i + timedelta(days = -k) in realindex:\n",
    "                need1.loc[i,:] = dataset1.loc[i + timedelta(days = -k),:]\n",
    "                need2.loc[i,:] = dataset2.loc[i + timedelta(days = -k),:]\n",
    "                # print(k)\n",
    "                break\n",
    "            else:\n",
    "                k=k+1\n",
    "    dataset1_n = pd.concat([dataset1, need1])\n",
    "    dataset2_n = pd.concat([dataset2, need2])\n",
    "    return dataset1_n, dataset2_n\n",
    "\n",
    "dClsprc_n, dDnvaltrd_n = fill_in(dClsprc, dDnvaltrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dClsprc_n = pd.read_csv('dClsprc_n.csv',index_col=0)\n",
    "# dDnvaltrd_n = pd.read_csv('dDnvaltrd_n.csv',index_col=0)\n",
    "# 按时间顺序排序收盘价和交易额数据\n",
    "dClsprc_n['date'] = dClsprc_n.index.tolist()\n",
    "dDnvaltrd_n['date'] = dDnvaltrd_n.index.tolist()\n",
    "dClsprc_n.sort_values(by='date', ascending = True, inplace = True)\n",
    "dDnvaltrd_n.sort_values(by='date', ascending = True, inplace = True)\n",
    "del dClsprc_n['date'], dDnvaltrd_n['date']\n",
    "\n",
    "#导入月收益率2000.1-2018.7\n",
    "ret_month = pd.read_csv('TRD_Mnth111.csv')\n",
    "ret_month['Trdmnt'] = pd.to_datetime(ret_month['Trdmnt'])\n",
    "ret_month = ret_month[(ret_month['Trdmnt'] <= '2018-07-02 00:00:00')]\n",
    "ret = pd.pivot_table(ret_month,index='Trdmnt',columns='Stkcd',values='Mretwd')\n",
    "valid = [x for x in dClsprc_n.columns if x in ret.columns]\n",
    "dClsprc_n = dClsprc_n.loc[:, valid]\n",
    "dDnvaltrd_n = dDnvaltrd_n.loc[:, valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = locals()\n",
    "def ERtrend_month(dClsprc_n,dDnvaltrd_n,ret,trade1d,lamda):\n",
    "    #找到每月第一个交易日在日收盘价、日交易额数据中的标签\n",
    "    all_index = pd.to_datetime(dClsprc_n.index).tolist()\n",
    "    #pr_index = pd.to_datetime(dDretwd.index).tolist()\n",
    "    index_num = [all_index.index(x) for x in trade1d]\n",
    "    #pr_num = [pr_index.index(x) for x in trade1d]\n",
    "    #计算经过标准化的MA_p和MA_v, 从1999.12-2018.7\n",
    "    MA_list = pd.DataFrame()\n",
    "    for L in [3,5,10,20,50,100,200,300,400]:\n",
    "        names['nMAp'+str(L)] = pd.DataFrame()\n",
    "        names['nMAv'+str(L)] = pd.DataFrame()\n",
    "        for i in index_num:\n",
    "            temp1 = dClsprc_n.iloc[i-L+1:i+1,:].mean(axis = 0)/dClsprc_n.iloc[i,:]\n",
    "            temp1 = temp1.to_frame()\n",
    "            temp2 = dDnvaltrd_n.iloc[i-L+1:i+1,:].mean(axis = 0)/dDnvaltrd_n.iloc[i,:]\n",
    "            temp2 = temp2.to_frame()\n",
    "            print(i)\n",
    "            names['nMAp'+str(L)] = pd.concat([names['nMAp'+str(L)], temp1], axis = 1)\n",
    "            names['nMAv'+str(L)] = pd.concat([names['nMAv'+str(L)], temp2], axis = 1)\n",
    "    #计算2000.1-2018.7的MA_p和MA_vd的回归系数，其中2000.1-2018.7的收益率数据对应1999.12-2018.6的MA指标\n",
    "    coeff = pd.DataFrame(index = ['nMAp3','nMAv3','nMAp5','nMAv5','nMAp10','nMAv10','nMAp20','nMAv20','nMAp50','nMAv50','nMAp100','nMAv100','nMAp200','nMAv200','nMAp300','nMAv300','nMAp400','nMAv400'])\n",
    "    coeff_t = pd.DataFrame(index = ['nMAp3','nMAv3','nMAp5','nMAv5','nMAp10','nMAv10','nMAp20','nMAv20','nMAp50','nMAv50','nMAp100','nMAv100','nMAp200','nMAv200','nMAp300','nMAv300','nMAp400','nMAv400'])\n",
    "    for i in range(len(index_num)-1):\n",
    "        MA_list = pd.concat([ret.iloc[i,:],nMAp3.iloc[:,i],nMAv3.iloc[:,i],nMAp5.iloc[:,i],nMAv5.iloc[:,i],nMAp10.iloc[:,i],nMAv10.iloc[:,i],nMAp20.iloc[:,i],nMAv20.iloc[:,i],nMAp50.iloc[:,i],nMAv50.iloc[:,i],nMAp100.iloc[:,i],nMAv100.iloc[:,i],nMAp200.iloc[:,i],nMAv200.iloc[:,i],nMAp300.iloc[:,i],nMAv300.iloc[:,i],nMAp400.iloc[:,i],nMAv400.iloc[:,i]], axis=1)\n",
    "        #MA_list = MA_list.apply(pd.to_numeric, errors='ignore')\n",
    "        MA_list.columns = ['rt','nMAp3','nMAv3','nMAp5','nMAv5','nMAp10','nMAv10','nMAp20','nMAv20','nMAp50','nMAv50','nMAp100','nMAv100','nMAp200','nMAv200','nMAp300','nMAv300','nMAp400','nMAv400']\n",
    "        #model = smf.ols('rt ~ nMAp3+nMAv3+nMAp5+nMAv5+nMAp10+nMAv10+nMAp20+nMAv20+nMAp50+nMAv50+nMAp100+nMAv100+nMAp200+nMAv200+nMAp300+nMAv300+nMAp400+nMAv400',MA_list).fit(cov_type='HAC',cov_kwds={'maxlags':6})\n",
    "        model = smf.ols('rt ~ nMAp3+nMAv3+nMAp5+nMAv5+nMAp10+nMAv10+nMAp20+nMAv20+nMAp50+nMAv50+nMAp100+nMAv100+nMAp200+nMAv200+nMAp300+nMAv300+nMAp400+nMAv400',data = MA_list).fit()\n",
    "        print(i)\n",
    "        coeff = pd.concat([coeff, model.params], axis = 1)\n",
    "        coeff_t = pd.concat([coeff_t, model.tvalues], axis = 1)\n",
    "    coeff.columns = range(len(index_num)-1)\n",
    "    #用2000.1-2018.7的回归系数的指数移动平均作为下一期系数预测值\n",
    "    #系数的预测值初期取0，预测系数从2000.1-2018.8，第i行对应该期的系数的预测值\n",
    "    temp = pd.DataFrame([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],index = ['nMAp3','nMAv3','nMAp5','nMAv5','nMAp10','nMAv10','nMAp20','nMAv20','nMAp50','nMAv50','nMAp100','nMAv100','nMAp200','nMAv200','nMAp300','nMAv300','nMAp400','nMAv400'])\n",
    "    coeff_f = temp\n",
    "    for i in range(len(index_num)-1):#实际上我们只需要2000.1-2018.7的系数预测值\n",
    "        temp0 = pd.DataFrame(lamda*coeff.loc[['nMAp3','nMAv3','nMAp5','nMAv5','nMAp10','nMAv10','nMAp20','nMAv20','nMAp50','nMAv50','nMAp100','nMAv100','nMAp200','nMAv200','nMAp300','nMAv300','nMAp400','nMAv400'],i])\n",
    "        temp = (1-lamda)*temp[0] + temp0[i] #去掉截距项\n",
    "        coeff_f = pd.concat([coeff_f,temp], axis = 1)\n",
    "    coeff_f = coeff_f.iloc[:,:-1]\n",
    "    #基于MA_p和MA_v等指标的收益预测，从第60期也就是2005.1开始进行预测至2018.7，构建ERtrend\n",
    "    #其中MA指标对应1999.12-2018.7，系数预测值对应2000.1-2018.7的系数预测值，得到的ERtrend对应2000.1-2018.7\n",
    "    ER_trend = np.zeros((len(MA_list),len(index_num)-60-1), dtype = float)\n",
    "    ER_trendP = np.zeros((len(MA_list),len(index_num)-60-1), dtype = float)\n",
    "    ER_trendV = np.zeros((len(MA_list),len(index_num)-60-1), dtype = float)\n",
    "    for i in range(60,len(index_num)-1):\n",
    "        print(i)\n",
    "        MA_list = pd.concat([nMAp3.iloc[:,i],nMAv3.iloc[:,i],nMAp5.iloc[:,i],nMAv5.iloc[:,i],nMAp10.iloc[:,i],nMAv10.iloc[:,i],nMAp20.iloc[:,i],nMAv20.iloc[:,i],nMAp50.iloc[:,i],nMAv50.iloc[:,i],nMAp100.iloc[:,i],nMAv100.iloc[:,i],nMAp200.iloc[:,i],nMAv200.iloc[:,i],nMAp300.iloc[:,i],nMAv300.iloc[:,i],nMAp400.iloc[:,i],nMAv400.iloc[:,i]], axis=1).apply(pd.to_numeric, errors='ignore')\n",
    "        for j in range(len(MA_list)):\n",
    "            ER_trend[j,i-60] = np.nansum(coeff_f.iloc[:,i].values*MA_list.iloc[j,:].values)\n",
    "            ER_trendP[j,i-60] = np.nansum(coeff_f.iloc[[0,2,4,6,8,10,12,14,16],i].values*MA_list.iloc[j,[0,2,4,6,8,10,12,14,16]].values)\n",
    "            ER_trendV[j,i-60] = np.nansum(coeff_f.iloc[[1,3,5,7,9,11,13,15,17],i].values*MA_list.iloc[j,[1,3,5,7,9,11,13,15,17]].values)\n",
    "    ER_trend,ER_trendP,ER_trendV = pd.DataFrame(ER_trend),pd.DataFrame(ER_trendP),pd.DataFrame(ER_trendV)\n",
    "    ER_trend,ER_trendP,ER_trendV = ER_trend.replace(0, np.nan),ER_trendP.replace(0, np.nan),ER_trendV.replace(0, np.nan)\n",
    "    ER_trend.index,ER_trendP.index,ER_trendV.index= ret.columns,ret.columns,ret.columns\n",
    "    ER_trend.columns,ER_trendP.columns,ER_trendV.columns= range(1,164),range(1,164),range(1,164)\n",
    "    ER_trendP = ER_trendP.stack().reset_index().rename(columns={'level_0': 'Stkcd','level_1': 'mon_num',0: 'ER'})\n",
    "    ER_trendP['mon_num'] = ER_trendP['mon_num']+1\n",
    "    ER_trendV = ER_trendV.stack().reset_index().rename(columns={'level_0': 'Stkcd','level_1': 'mon_num',0: 'ER'})\n",
    "    ER_trendV['mon_num'] = ER_trendV['mon_num']+1\n",
    "    ER_trend = ER_trend.stack().reset_index().rename(columns={'level_0': 'Stkcd','level_1': 'mon_num',0: 'ER'})\n",
    "    ER_trend['mon_num'] = ER_trend['mon_num']+1\n",
    "    return ER_trend,ER_trendP,ER_trendV\n",
    "\n",
    "ER_trend,ER_trendP,ER_trendV = ERtrend_month(dClsprc_n,dDnvaltrd_n,ret,trade1d,0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trend Factor and Others**:   \n",
    "We use the trend-based expected return (ERtrend) along with the market capitalization (Size) and earnings-to-price ratio (EP) to construct the trend factor (Trend), the size factor (SMB), and the value factor (VMG) in our 4-factor model.   \n",
    "1.exclude the smallest 30% of stocks each month   \n",
    "2.sort the remaining 70% of stocks independently into two size groups (SizeSmall and SizeBig) by the median of the market capitalization, three EP groups (EPLow, EPMid, and EPHigh) and three trend groups (TrendLow, TrendMid, and TrendHigh) by the 30th and 70th percentiles of EP and ERtrend at the end of each month         \n",
    "3.define trend factor (Trend) as the average of value-weighted (VW) returns of 6 portfolios in the TrendHigh group minus that in the TrendLow group, define the size factor (SMB) as the average of VW returns of 9 portfolios in the Sizesmall group minus that in the SizeBig group, define the value factor (VMG) as the average of VW returns of 6 portfolios in the EPHigh group minus that in the EPLow group, define the market factor (MKT) as the return on the VW portfolio of the top 70% of stocks      \n",
    "Note: weigh each stock by the market capitalization of all its outstanding A-Shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#导入总市值数据2004.12-2018.6\n",
    "mktcap = pd.read_csv('TRD_Mnth1.csv')\n",
    "mktcap['Trdmnt'] = pd.to_datetime(mktcap['Trdmnt'])\n",
    "mktcap['year'] = mktcap['Trdmnt'].dt.year\n",
    "mktcap['month'] = mktcap['Trdmnt'].dt.month\n",
    "mktcap['mon_num'] = 12*(mktcap['year']-2005)+mktcap['month']+1#用上一个月的总市值计算ep\n",
    "#导入净利润数据\n",
    "earning = pd.read_csv('FS_Comins1.csv')\n",
    "earning = earning[earning['Typrep']=='A']\n",
    "earning['Accper'] = pd.to_datetime(earning['Accper'])\n",
    "earning['year'] = earning['Accper'].dt.year\n",
    "earning['month'] = earning['Accper'].dt.month\n",
    "earning['match_num'] = 12*(earning['year']-2005)+earning['month']\n",
    "earning['B002000201'] = earning['B002000201'].fillna(0)\n",
    "#根据财报数据填充每月净利润并计算EP\n",
    "def get_EP(mktcap, earning):\n",
    "    mkt0 = mktcap[(mktcap['month'] == 12)]\n",
    "    mkt0['match_num'] = 12*(mkt0['year']-2005+1)-3\n",
    "    mkt1 = mktcap[ (mktcap['month'] == 1) | (mktcap['month'] == 2) | (mktcap['month'] == 3) ]\n",
    "    mkt1['match_num'] = 12*(mkt1['year']-2005)-3\n",
    "    mkt2 = mktcap[(mktcap['month'] == 4) | (mktcap['month'] == 5) | (mktcap['month'] == 6) | (mktcap['month'] == 7) ]\n",
    "    mkt2['match_num'] = 12*(mkt2['year']-2005)+3\n",
    "    mkt3 = mktcap[(mktcap['month'] == 8) | (mktcap['month'] == 9)]\n",
    "    mkt3['match_num'] = 12*(mkt3['year']-2005)+6\n",
    "    mkt4 = mktcap[(mktcap['month'] == 10) | (mktcap['month'] == 11)]\n",
    "    mkt4['match_num'] = 12*(mkt4['year']-2005)+9\n",
    "    mktcap_m = pd.concat([mkt0, mkt1, mkt2, mkt3, mkt4])\n",
    "    mktcap_m = pd.merge(mktcap_m,earning,on=['Stkcd','match_num'],how='left')\n",
    "    mktcap_m['ep'] = (mktcap_m['B002000000']-mktcap_m['B002000201']) / mktcap_m['Msmvttl']/1000\n",
    "    ep_ratio = mktcap_m[['Stkcd','Trdmnt','ep','mon_num']]\n",
    "    return ep_ratio\n",
    "ep_ratio = get_EP(mktcap, earning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2005.1-2018.7月个股收益率\n",
    "ret_month = pd.read_csv('TRD_Mnth11.csv')\n",
    "ret_month['Trdmnt'] = pd.to_datetime(ret_month['Trdmnt'])\n",
    "ret_month['year'] = ret_month['Trdmnt'].dt.year\n",
    "ret_month['month'] = ret_month['Trdmnt'].dt.month\n",
    "ret_month['mon_num'] = 12*(ret_month['year']-2005)+ret_month['month']\n",
    "#流通市值用于计算加权收益\n",
    "mktcap = pd.read_csv('TRD_Mnth1vw.csv')\n",
    "mktcap['Trdmnt'] = pd.to_datetime(mktcap['Trdmnt'])\n",
    "mktcap['year'] = mktcap['Trdmnt'].dt.year\n",
    "mktcap['month'] = mktcap['Trdmnt'].dt.month\n",
    "mktcap['mon_num'] = 12*(mktcap['year']-2005)+mktcap['month']+1#用上一个月的流通市值分size组以及求加权收益\n",
    "\n",
    "factor = pd.merge(ep_ratio[['Stkcd','mon_num','ep']], mktcap[['Stkcd','mon_num','Msmvosd']], on=['Stkcd','mon_num'])\n",
    "factor = pd.merge(factor, ER_trend, on=['Stkcd','mon_num'], how = 'left')\n",
    "factor_ret = pd.merge(ret_month[['Stkcd','Mretwd','mon_num']], factor, on=['Stkcd','mon_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#建立分组标签\n",
    "def get_group(factor_ret, group1n, x, group2n, y, group3n, z):\n",
    "    X = pd.DataFrame()\n",
    "    factor_ret = factor_ret.dropna()\n",
    "    factor_ret['ret*mkt'] = factor_ret['Mretwd']*factor_ret['Msmvosd']\n",
    "    for i in range(1,164):\n",
    "        temp_value = factor_ret[factor_ret['mon_num'] == i]\n",
    "        temp_value['sample'] = pd.qcut(temp_value['Msmvosd'],[0,0.3,1],labels=False,duplicates='drop')\n",
    "        temp_value[group1n+'_n'] = pd.qcut(temp_value[(temp_value['sample'] == 1)][group1n],[0,0.5,1],labels=False,duplicates='drop')\n",
    "        temp_value[group2n+'_n'] = pd.qcut(temp_value[(temp_value['sample'] == 1)][group2n],[0,0.3,0.7,1],labels=False,duplicates='drop')\n",
    "        temp_value[group3n+'_n'] = pd.qcut(temp_value[(temp_value['sample'] == 1)][group3n],[0,0.3,0.7,1],labels=False,duplicates='drop')\n",
    "        X = pd.concat([X,temp_value],axis=0)\n",
    "    factor_ret = X[(X['sample'] == 1)]#去掉30%小市值股票\n",
    "    return factor_ret\n",
    "\n",
    "factor_ret = get_group(factor_ret, 'Msmvosd', 2, 'ep', 3, 'ER', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入月度无风险收益率\n",
    "rf = pd.read_csv('TRD_Nrrate1.csv')\n",
    "rf['Clsdt'] = pd.to_datetime(rf['Clsdt'])\n",
    "rf['year'] = rf['Clsdt'].dt.year\n",
    "rf['month'] = rf['Clsdt'].dt.month\n",
    "rf['mon_num'] = 12*(rf['year']-2005)+rf['month']\n",
    "rf = rf.drop_duplicates(subset=['year','month'], keep='first')[['Nrrmtdt','mon_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#按市值，EP和ERtrend进行三分组，计算Trend, SMB, VMG因子和MKT因子\n",
    "def get_factor(factor_ret, group1n, group2n, group3n):\n",
    "    Size_ep_T = pd.DataFrame(index=range(1,164))\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                for t in range(1,164):\n",
    "                    temp = factor_ret[factor_ret['mon_num'] == t]\n",
    "                    #print(t)\n",
    "                    Size_ep_T.loc[t,str(i)+str(j)+str(k)] = (temp[(temp[group1n+'_n'] == i)&(temp[group2n+'_n'] == j)&(temp[group3n+'_n'] == k)]['ret*mkt']/(temp[(temp[group1n+'_n'] == i)&(temp[group2n+'_n'] == j)&(temp[group3n+'_n'] == k)]['Msmvosd'].sum())).sum()\n",
    "    Trend = Size_ep_T[['002','012','022','102','112','122']].mean(axis=1) - Size_ep_T[['000','010','020','100','110','120']].mean(axis=1)\n",
    "    smb = Size_ep_T[['000','001','002','010','011','012','020','021','022']].mean(axis=1) - Size_ep_T[['100','101','102','110','111','112','120','121','122']].mean(axis=1)\n",
    "    vmg = Size_ep_T[['020','021','022','120','121','122']].mean(axis=1) - Size_ep_T[['000','001','002','100','101','102']].mean(axis=1)\n",
    "    mkt = []\n",
    "    for t in range(1,164):\n",
    "        temp = factor_ret[factor_ret['mon_num'] == t]\n",
    "        #print(t)\n",
    "        mkt.append((temp['Mretwd']*temp['Msmvosd']/(temp['Msmvosd'].sum())).sum())\n",
    "    mkt = mkt - 0.01* rf.iloc[:,0]\n",
    "    mkt.index = range(1,164)\n",
    "    mkt_avg = mkt.mean()\n",
    "    return Trend, smb, vmg, mkt, mkt_avg\n",
    "\n",
    "Trend, smb, vmg, mkt, mkt_avg = get_factor(factor_ret, 'Msmvosd', 'ep', 'ER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical results\n",
    "**Summary statistics**:    \n",
    "1.LSY-4 factors     \n",
    "2.our size factor (SMB\\*), value factor (VMG\\*) and trend factor (Trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NWtest(a, lags=4):\n",
    "    adj_a = np.array(a)\n",
    "    # 对常数回归\n",
    "    model = sm.OLS(adj_a, [1] * len(adj_a)).fit(cov_type='HAC', cov_kwds={'maxlags': lags})\n",
    "    return 100*adj_a.mean(), float(model.tvalues)\n",
    "\n",
    "def get_Sharpe(data, rf):\n",
    "    mean = data.mean() * 12\n",
    "    STD = data.std() * np.sqrt(12)\n",
    "    sharp = (mean - 0.01*rf.iloc[:,0].mean() * 12) / STD\n",
    "    return sharp\n",
    "\n",
    "def get_MDD(data):\n",
    "    data = data +1\n",
    "    data = data.values.cumprod()\n",
    "    index_j = np.argmax(np.maximum.accumulate(data) - data)  # 结束位置\n",
    "    index_i = np.argmax(data[:index_j])  # 开始位置\n",
    "    d = (data[index_j] - data[index_i]) / data[index_i]  # 最大回撤\n",
    "    return -d\n",
    "\n",
    "def Summary_statistic(data, rf): \n",
    "    result = pd.DataFrame(index=['Mean',' ','SD','Sharpe','Skew','MDD'], columns=['MKT','SMB','VMG','PMO','SMB*','VMG*','Trend'])\n",
    "    i=0\n",
    "    for temp in data: \n",
    "        mean, t = NWtest(temp)\n",
    "        result.iloc[:,i] = [mean, t, temp.std(), get_Sharpe(temp,rf), temp.skew(), get_MDD(temp)*100]\n",
    "        i=i+1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKT</th>\n",
       "      <th>SMB</th>\n",
       "      <th>VMG</th>\n",
       "      <th>PMO</th>\n",
       "      <th>SMB*</th>\n",
       "      <th>VMG*</th>\n",
       "      <th>Trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.931</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.095</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.765</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.164</td>\n",
       "      <td>2.498</td>\n",
       "      <td>4.307</td>\n",
       "      <td>3.348</td>\n",
       "      <td>2.482</td>\n",
       "      <td>3.996</td>\n",
       "      <td>2.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.084</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe</th>\n",
       "      <td>0.296</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>-0.384</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.216</td>\n",
       "      <td>-0.740</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDD</th>\n",
       "      <td>69.068</td>\n",
       "      <td>26.064</td>\n",
       "      <td>19.694</td>\n",
       "      <td>25.693</td>\n",
       "      <td>25.493</td>\n",
       "      <td>19.160</td>\n",
       "      <td>18.481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MKT     SMB     VMG     PMO    SMB*    VMG*   Trend\n",
       "Mean     0.931   1.000   1.095   0.886   0.765   1.046   0.528\n",
       "         1.164   2.498   4.307   3.348   2.482   3.996   2.671\n",
       "SD       0.084   0.050   0.040   0.039   0.041   0.039   0.026\n",
       "Sharpe   0.296   0.550   0.768   0.594   0.473   0.744   0.417\n",
       "Skew    -0.384  -0.052   0.216  -0.740   0.044   0.156  -0.654\n",
       "MDD     69.068  26.064  19.694  25.693  25.493  19.160  18.481"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#导入LSY4因子的因子数据\n",
    "Ch4 = pd.read_csv('CH_4_fac.csv',index_col = 0).iloc[60:223,:]/100\n",
    "Ch4.index = range(1,164)\n",
    "\n",
    "statistic = Summary_statistic([Ch4.mktrf, Ch4.SMB, Ch4.VMG, Ch4.PMO, smb, vmg, Trend], rf).applymap(lambda x:round(x, 3))\n",
    "statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1.png](https://i.loli.net/2020/06/20/4cC7r3ePguDx1AV.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKT</th>\n",
       "      <th>SMB</th>\n",
       "      <th>VMG</th>\n",
       "      <th>PMO</th>\n",
       "      <th>SMB*</th>\n",
       "      <th>VMG*</th>\n",
       "      <th>Trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MKT</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMB</th>\n",
       "      <td>0.14</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VMG</th>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PMO</th>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMB*</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VMG*</th>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trend</th>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MKT   SMB   VMG   PMO  SMB*  VMG*  Trend\n",
       "MKT    1.00  0.14 -0.30 -0.28  0.07 -0.26  -0.08\n",
       "SMB    0.14  1.00 -0.63  0.10  0.95 -0.63   0.37\n",
       "VMG   -0.30 -0.63  1.00 -0.03 -0.62  0.90  -0.17\n",
       "PMO   -0.28  0.10 -0.03  1.00  0.14  0.01   0.34\n",
       "SMB*   0.07  0.95 -0.62  0.14  1.00 -0.62   0.37\n",
       "VMG*  -0.26 -0.63  0.90  0.01 -0.62  1.00  -0.07\n",
       "Trend -0.08  0.37 -0.17  0.34  0.37 -0.07   1.00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Corr(data_list):\n",
    "    result = []\n",
    "    for data1 in data_list:\n",
    "        result_i = []\n",
    "        for data2 in data_list:\n",
    "            result_i.append(data1.corr(data2)) \n",
    "        result.append(result_i)\n",
    "    result = pd.DataFrame(result,index=['MKT','SMB','VMG','PMO','SMB*','VMG*','Trend'], columns=['MKT','SMB','VMG','PMO','SMB*','VMG*','Trend']).T\n",
    "    return result\n",
    "\n",
    "corr = Corr([Ch4.mktrf, Ch4.SMB, Ch4.VMG, Ch4.PMO, smb, vmg, Trend]).applymap(lambda x:round(x, 2))\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2.png](https://i.loli.net/2020/06/20/dIqLzhBtik91u3F.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**    \n",
    "1.PMO is trending up, say, by its long-leg stocks only, Trend should capture these stocks in its long-leg, resulting in a positive correlation.   \n",
    "2.LSY-3's size (value) factor has a strong correlation, over 90%, with ours.    \n",
    "3.As smaller stocks tend to be growth stocks, SMG (SMG\\*) and VMG (VMG\\*) exhibit a strong negative correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison of PMO and Trend in sub-samples：**       \n",
    "the average monthly returns for the turnover factor (PMO) and our trend factor (Trend) in sub-samples using 2\\*3\\*3 independent sortings    \n",
    "1.Stocks are independently sorted by two kinds of control variables (2\\*3) and PMO / Trend(\\*3).    \n",
    "2.In each one of the 6 sub-samples, the trend factor (Trend)/ turnover factor (PMO) are defined as the return of the Trend-High/ AbTurn-Low Portfolio minus that of the Trend-Low/ AbTurn-High portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入异常换手率因子\n",
    "AbTurn = pd.read_csv('ret_turn_abn.csv',index_col = 0).iloc[71:-5,:]\n",
    "AbTurn.columns = pd.to_numeric(AbTurn.columns)\n",
    "valid = [x for x in AbTurn.columns if x in ret.columns]\n",
    "AbTurn = AbTurn.loc[:, valid]\n",
    "AbTurn.columns = ret.columns\n",
    "AbTurn.index = range(1,164)\n",
    "AbTurn = AbTurn.stack().reset_index().rename(columns={'level_0': 'mon_num',0: 'AbTurn'})\n",
    "factor = pd.merge(ep_ratio[['Stkcd','mon_num','ep']], mktcap[['Stkcd','mon_num','Msmvosd']], on=['Stkcd','mon_num'])\n",
    "factor = pd.merge(factor, ER_trend, on=['Stkcd','mon_num'])\n",
    "factor = pd.merge(factor, AbTurn, on=['Stkcd','mon_num'])\n",
    "factor_ret0 = pd.merge(ret_month[['Stkcd','Mretwd','mon_num']], factor, on=['Stkcd','mon_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "def get_group4(factor_ret, group1n, group2n, group3n, group4n):\n",
    "    X = pd.DataFrame()\n",
    "    factor_ret = factor_ret.dropna()\n",
    "    factor_ret['ret*mkt'] = factor_ret['Mretwd']*factor_ret['Msmvosd']\n",
    "    for i in range(1,164):\n",
    "        temp_value = factor_ret[factor_ret['mon_num'] == i]\n",
    "        temp_value['sample'] = pd.qcut(temp_value['Msmvosd'],[0,0.3,1],labels=False,duplicates='drop')\n",
    "        temp_value[group1n+'_n'] = pd.qcut(temp_value[(temp_value['sample'] == 1)][group1n],[0,0.5,1],labels=False,duplicates='drop')\n",
    "        temp_value[group2n+'_n'] = pd.qcut(temp_value[(temp_value['sample'] == 1)][group2n],[0,0.3,0.7,1],labels=False,duplicates='drop')\n",
    "        temp_value[group3n+'_n'] = pd.qcut(temp_value[(temp_value['sample'] == 1)][group3n],[0,0.3,0.7,1],labels=False,duplicates='drop')\n",
    "        temp_value[group4n+'_n'] = pd.qcut(temp_value[(temp_value['sample'] == 1)][group4n],[0,0.3,0.7,1],labels=False,duplicates='drop')\n",
    "        X = pd.concat([X,temp_value],axis=0)\n",
    "    factor_ret = X[(X['sample'] == 1)]\n",
    "    return factor_ret\n",
    "\n",
    "factor_ret_g = get_group4(factor_ret0, 'Msmvosd', 'ep', 'AbTurn', 'ER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Tab2(factor_ret_g, fac_n, control1, control2, s_minus_b = 1):\n",
    "    result = pd.DataFrame(index = range(8), columns = ['Size-Small','Size-Big','Size-Average'])\n",
    "    temp_fac = pd.DataFrame(index=range(1,164))\n",
    "    for t in range(1,164):\n",
    "        temp = factor_ret_g[factor_ret_g['mon_num'] == t]\n",
    "        for i in range(2):\n",
    "            for j in range(3):\n",
    "                temp['last_n'] = pd.qcut(temp[fac_n],[0,0.3,0.7,1],labels=False,duplicates='drop')\n",
    "                if s_minus_b == 1:\n",
    "                    temp_fac.loc[t,str(i)+str(j)] = (temp[(temp[control1+'_n'] == i)&(temp[control2+'_n'] == j)&(temp['last_n'] == 0)]['ret*mkt']/(temp[(temp[control1+'_n'] == i)&(temp[control2+'_n'] == j)&(temp['last_n'] == 0)]['Msmvosd'].sum())).sum()\\\n",
    "                        - (temp[(temp[control1+'_n'] == i)&(temp[control2+'_n'] == j)&(temp['last_n'] == 2)]['ret*mkt']/(temp[(temp[control1+'_n'] == i)&(temp[control2+'_n'] == j)&(temp['last_n'] == 2)]['Msmvosd'].sum())).sum()\n",
    "                else:\n",
    "                    temp_fac.loc[t,str(i)+str(j)] = (temp[(temp[control1+'_n'] == i)&(temp[control2+'_n'] == j)&(temp['last_n'] == 2)]['ret*mkt']/(temp[(temp[control1+'_n'] == i)&(temp[control2+'_n'] == j)&(temp['last_n'] == 2)]['Msmvosd'].sum())).sum()\\\n",
    "                        - (temp[(temp[control1+'_n'] == i)&(temp[control2+'_n'] == j)&(temp['last_n'] == 0)]['ret*mkt']/(temp[(temp[control1+'_n'] == i)&(temp[control2+'_n'] == j)&(temp['last_n'] == 0)]['Msmvosd'].sum())).sum()\n",
    "    temp_fac.loc[:,'A0'] = temp_fac[['00','10']].mean(axis = 1)\n",
    "    temp_fac.loc[:,'A1'] = temp_fac[['01','11']].mean(axis = 1)\n",
    "    temp_fac.loc[:,'A2'] = temp_fac[['02','12']].mean(axis = 1)\n",
    "    temp_fac.loc[:,'AA'] = temp_fac[['A0','A1','A2']].mean(axis = 1)\n",
    "    temp_fac.loc[:,'0A'] = temp_fac[['00','01']].mean(axis = 1)\n",
    "    temp_fac.loc[:,'1A'] = temp_fac[['10','11']].mean(axis = 1)\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            result.iloc[2*j,i], result.iloc[2*j+1,i] = NWtest(temp_fac.iloc[:, i*3+j])\n",
    "    result.iloc[0:2,2] = NWtest(temp_fac.loc[:,'A0'])\n",
    "    result.iloc[2:4,2] = NWtest(temp_fac.loc[:,'A1'])\n",
    "    result.iloc[4:6,2] = NWtest(temp_fac.loc[:,'A2'])\n",
    "    result.iloc[6:8,2] = NWtest(temp_fac.loc[:,'AA'])\n",
    "    result.iloc[6:8,0] = NWtest(temp_fac.loc[:,'0A'])\n",
    "    result.iloc[6:8,1] = NWtest(temp_fac.loc[:,'1A'])\n",
    "    result.index = [control2+'-Low','',control2+'-Mid','',control2+'-Hign','','Average','']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size-Small</th>\n",
       "      <th>Size-Big</th>\n",
       "      <th>Size-Average</th>\n",
       "      <th>Size-Small</th>\n",
       "      <th>Size-Big</th>\n",
       "      <th>Size-Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ep-Low</th>\n",
       "      <td>1.68445</td>\n",
       "      <td>0.545741</td>\n",
       "      <td>1.1151</td>\n",
       "      <td>0.426534</td>\n",
       "      <td>1.20075</td>\n",
       "      <td>0.813642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>6.66051</td>\n",
       "      <td>1.20163</td>\n",
       "      <td>3.55752</td>\n",
       "      <td>1.93266</td>\n",
       "      <td>2.73156</td>\n",
       "      <td>2.70358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ep-Mid</th>\n",
       "      <td>1.25743</td>\n",
       "      <td>0.555118</td>\n",
       "      <td>0.906273</td>\n",
       "      <td>0.267717</td>\n",
       "      <td>0.46416</td>\n",
       "      <td>0.365939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>5.11431</td>\n",
       "      <td>1.62978</td>\n",
       "      <td>3.52782</td>\n",
       "      <td>1.44157</td>\n",
       "      <td>1.42138</td>\n",
       "      <td>1.67628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ep-Hign</th>\n",
       "      <td>1.32883</td>\n",
       "      <td>-0.109645</td>\n",
       "      <td>0.609593</td>\n",
       "      <td>0.393692</td>\n",
       "      <td>0.449088</td>\n",
       "      <td>0.42139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>4.56679</td>\n",
       "      <td>-0.320191</td>\n",
       "      <td>2.31301</td>\n",
       "      <td>1.90549</td>\n",
       "      <td>1.65579</td>\n",
       "      <td>2.25056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>1.47094</td>\n",
       "      <td>0.55043</td>\n",
       "      <td>0.876988</td>\n",
       "      <td>0.347126</td>\n",
       "      <td>0.832455</td>\n",
       "      <td>0.533657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>6.83707</td>\n",
       "      <td>1.53207</td>\n",
       "      <td>3.62017</td>\n",
       "      <td>1.95685</td>\n",
       "      <td>2.44088</td>\n",
       "      <td>2.72243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Size-Small  Size-Big Size-Average Size-Small  Size-Big Size-Average\n",
       "ep-Low     1.68445  0.545741       1.1151   0.426534   1.20075     0.813642\n",
       "           6.66051   1.20163      3.55752    1.93266   2.73156      2.70358\n",
       "ep-Mid     1.25743  0.555118     0.906273   0.267717   0.46416     0.365939\n",
       "           5.11431   1.62978      3.52782    1.44157   1.42138      1.67628\n",
       "ep-Hign    1.32883 -0.109645     0.609593   0.393692  0.449088      0.42139\n",
       "           4.56679 -0.320191      2.31301    1.90549   1.65579      2.25056\n",
       "Average    1.47094   0.55043     0.876988   0.347126  0.832455     0.533657\n",
       "           6.83707   1.53207      3.62017    1.95685   2.44088      2.72243"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Control for Size and EP: PMO & Trend\n",
    "PanelA_PMO = get_Tab2(factor_ret_g, 'AbTurn','Msmvosd','ep')\n",
    "PanelA_Trend = get_Tab2(factor_ret_g, 'ER','Msmvosd','ep', s_minus_b = 0)\n",
    "pd.concat([PanelA_PMO,PanelA_Trend],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3.png](https://i.loli.net/2020/06/20/ByGjAIPHiD7dbLF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**     \n",
    "1.PMO earns a monthly return of 0.87% (t-statistic: 3.62), with contributions mainly from small stocks.   \n",
    "2.Trend earns a monthly return of 0.53% (t-statistic: 2.72), with contributions mainly from big stocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size-Small</th>\n",
       "      <th>Size-Big</th>\n",
       "      <th>Size-Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ER-Low</th>\n",
       "      <td>1.67115</td>\n",
       "      <td>0.305616</td>\n",
       "      <td>0.988385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>6.03694</td>\n",
       "      <td>0.772603</td>\n",
       "      <td>3.41912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER-Mid</th>\n",
       "      <td>1.50802</td>\n",
       "      <td>0.406677</td>\n",
       "      <td>0.957349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>5.57431</td>\n",
       "      <td>1.0458</td>\n",
       "      <td>3.43636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER-Hign</th>\n",
       "      <td>1.30436</td>\n",
       "      <td>-0.0556964</td>\n",
       "      <td>0.624334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>5.20587</td>\n",
       "      <td>-0.129373</td>\n",
       "      <td>2.3016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>1.58959</td>\n",
       "      <td>0.356146</td>\n",
       "      <td>0.856689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>6.57609</td>\n",
       "      <td>0.995167</td>\n",
       "      <td>3.6716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Size-Small   Size-Big Size-Average\n",
       "ER-Low     1.67115   0.305616     0.988385\n",
       "           6.03694   0.772603      3.41912\n",
       "ER-Mid     1.50802   0.406677     0.957349\n",
       "           5.57431     1.0458      3.43636\n",
       "ER-Hign    1.30436 -0.0556964     0.624334\n",
       "           5.20587  -0.129373       2.3016\n",
       "Average    1.58959   0.356146     0.856689\n",
       "           6.57609   0.995167       3.6716"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Control for Size and ER：PMO\n",
    "PanelB_PMO = get_Tab2(factor_ret_g, 'AbTurn','Msmvosd','ER')\n",
    "PanelB_PMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![4.png](https://i.loli.net/2020/06/20/DGxco83YIMRpO6T.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**     \n",
    "1.PMO earns a significant monthly return with contributions mainly from small stocks.   \n",
    "2.The predictability of turnover can't be subsumed by the trend signals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size-Small</th>\n",
       "      <th>Size-Big</th>\n",
       "      <th>Size-Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AbTurn-Low</th>\n",
       "      <td>0.0357256</td>\n",
       "      <td>0.604582</td>\n",
       "      <td>0.320154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.179181</td>\n",
       "      <td>1.64418</td>\n",
       "      <td>1.33802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AbTurn-Mid</th>\n",
       "      <td>0.0833079</td>\n",
       "      <td>0.718061</td>\n",
       "      <td>0.400685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.391995</td>\n",
       "      <td>2.18353</td>\n",
       "      <td>1.88109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AbTurn-Hign</th>\n",
       "      <td>0.402515</td>\n",
       "      <td>0.965894</td>\n",
       "      <td>0.684205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.6255</td>\n",
       "      <td>2.03184</td>\n",
       "      <td>2.24859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.0595167</td>\n",
       "      <td>0.661322</td>\n",
       "      <td>0.468348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.367344</td>\n",
       "      <td>2.55095</td>\n",
       "      <td>2.43075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Size-Small  Size-Big Size-Average\n",
       "AbTurn-Low   0.0357256  0.604582     0.320154\n",
       "              0.179181   1.64418      1.33802\n",
       "AbTurn-Mid   0.0833079  0.718061     0.400685\n",
       "              0.391995   2.18353      1.88109\n",
       "AbTurn-Hign   0.402515  0.965894     0.684205\n",
       "                1.6255   2.03184      2.24859\n",
       "Average      0.0595167  0.661322     0.468348\n",
       "              0.367344   2.55095      2.43075"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Control for Size and AbTurn：Trend\n",
    "PanelC_Trend = get_Tab2(factor_ret_g, 'ER','Msmvosd','AbTurn', s_minus_b = 0)\n",
    "PanelC_Trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5.png](https://i.loli.net/2020/06/20/wsjWYHShV8gePmb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**    \n",
    "1.Our trend measure provides independent information beyond size, EP, and turnover.     \n",
    "2.It is able to capture trends in large stocks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model performances in explaining factors in other models:**     \n",
    "1.We compare the explanatory power of our 4-factor with LSY-3, LSY-4 as well as the replications of Hou, Xue, and Zhang's (2015) q-factor model (q-4) and Fama and French's (2015) 5-factor model (FF-5).     \n",
    "2.We report the average absolute monthly alpha (%), the average absolute t -statistics, the aggregate pricing error △, and the Gibbons, Ross, and Shanken (1898) (GRS) F-statistics with associated p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#本文的四因子模型\n",
    "Our4 = pd.concat([pd.DataFrame(Trend), pd.DataFrame(smb), pd.DataFrame(vmg), pd.DataFrame(mkt)], axis = 1)\n",
    "Our4.columns = ['Trend', 'smb', 'vmg', 'mkt_r']\n",
    "#q4因子模型\n",
    "q4factor = pd.read_csv('q4factor.csv',index_col = 0).iloc[96:-17,[3,4,5]]\n",
    "q4factor = pd.read_csv('q4factor.csv',index_col = 0).iloc[96:-17,[3,4,5]]\n",
    "#FF5因子模型\n",
    "FF5_monthly = pd.read_csv('FF5_monthly.csv',index_col = 0).iloc[131:-9,[0,1,2,8,9]]\n",
    "FF5_monthly.index = range(1,164)\n",
    "#LSY3因子模型\n",
    "Ch3 = pd.read_csv('CH_3_fac.csv',index_col = 0).iloc[60:223,1:]/100\n",
    "Ch3.index = range(1,164)\n",
    "#LSY4因子模型\n",
    "Ch4 = pd.read_csv('CH_4_fac.csv',index_col = 0).iloc[60:223,1:]/100\n",
    "Ch4.index = range(1,164)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSY3</th>\n",
       "      <th>Our4</th>\n",
       "      <th>LSY4</th>\n",
       "      <th>Our4</th>\n",
       "      <th>q4</th>\n",
       "      <th>Our4</th>\n",
       "      <th>FF5</th>\n",
       "      <th>Our4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ave_abs_α</th>\n",
       "      <td>0.153797</td>\n",
       "      <td>0.187090</td>\n",
       "      <td>0.105423</td>\n",
       "      <td>0.334027</td>\n",
       "      <td>0.858361</td>\n",
       "      <td>0.348225</td>\n",
       "      <td>4.726090e-01</td>\n",
       "      <td>0.301758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave_abs_t</th>\n",
       "      <td>0.931625</td>\n",
       "      <td>1.331932</td>\n",
       "      <td>0.726685</td>\n",
       "      <td>1.594597</td>\n",
       "      <td>2.382261</td>\n",
       "      <td>2.071139</td>\n",
       "      <td>2.658894e+00</td>\n",
       "      <td>1.699075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>△</th>\n",
       "      <td>0.035676</td>\n",
       "      <td>0.059569</td>\n",
       "      <td>0.026658</td>\n",
       "      <td>0.119689</td>\n",
       "      <td>0.268083</td>\n",
       "      <td>0.153109</td>\n",
       "      <td>3.847990e-01</td>\n",
       "      <td>0.231339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRS</th>\n",
       "      <td>1.046389</td>\n",
       "      <td>2.386166</td>\n",
       "      <td>0.744070</td>\n",
       "      <td>3.572753</td>\n",
       "      <td>8.754998</td>\n",
       "      <td>6.133141</td>\n",
       "      <td>1.297136e+01</td>\n",
       "      <td>5.488812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRS_p</th>\n",
       "      <td>0.385211</td>\n",
       "      <td>0.071219</td>\n",
       "      <td>0.563364</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>3.977894e-09</td>\n",
       "      <td>0.000112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LSY3      Our4      LSY4      Our4        q4      Our4  \\\n",
       "ave_abs_α  0.153797  0.187090  0.105423  0.334027  0.858361  0.348225   \n",
       "ave_abs_t  0.931625  1.331932  0.726685  1.594597  2.382261  2.071139   \n",
       "△          0.035676  0.059569  0.026658  0.119689  0.268083  0.153109   \n",
       "GRS        1.046389  2.386166  0.744070  3.572753  8.754998  6.133141   \n",
       "GRS_p      0.385211  0.071219  0.563364  0.008111  0.000002  0.000572   \n",
       "\n",
       "                    FF5      Our4  \n",
       "ave_abs_α  4.726090e-01  0.301758  \n",
       "ave_abs_t  2.658894e+00  1.699075  \n",
       "△          3.847990e-01  0.231339  \n",
       "GRS        1.297136e+01  5.488812  \n",
       "GRS_p      3.977894e-09  0.000112  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GRS_test(factor, resid, alpha):\n",
    "    resid = resid.fillna(0)\n",
    "    T, N = resid.shape\n",
    "    L = factor.shape[1]\n",
    "    mu_mean = factor.mean(0)\n",
    "    cov_e = np.cov(resid.T)\n",
    "    cov_f = np.cov(factor.T).reshape((L, L))\n",
    "    alpha = np.asmatrix(alpha).reshape(N, 1)\n",
    "    mu_mean = np.asmatrix(mu_mean).reshape(L, 1)\n",
    "    # matrix operation with np.ndarray\n",
    "    delta = alpha.T @ inv(cov_e) @ alpha\n",
    "    GRS = float((T / N) * ((T - N - L) / (T - L - 1))) * (alpha.T @ inv(cov_e) @ alpha) / (1 + mu_mean.T @ inv(cov_f) @ mu_mean)\n",
    "    GRS = GRS[0, 0]\n",
    "    GRSp = st.f.sf(GRS, N, (T - N - L))\n",
    "    grs = [GRS, GRSp]\n",
    "    return  delta[:, 0][0, 0], grs\n",
    "\n",
    "def fac_in_others(model1, model2):\n",
    "    alpha = []\n",
    "    t = []\n",
    "    re = pd.DataFrame()\n",
    "    for i in model1.columns:\n",
    "        Y = model1[[i]]\n",
    "        model = sm.OLS(Y.values,sm.add_constant(model2).values).fit()\n",
    "        alpha.append(model.params[0])\n",
    "        t.append(abs(model.tvalues[0]))\n",
    "        residual = pd.DataFrame(model.resid)\n",
    "        re = pd.concat([re, residual], axis=1)\n",
    "    absalpha = [abs(x) for x in alpha]\n",
    "    alpha = DataFrame(alpha)\n",
    "    delta, grs = GRS_test(model2, re, alpha)\n",
    "    return np.mean(absalpha)*100, np.mean(t), delta, grs\n",
    "\n",
    "def get_Tab3():\n",
    "    results = pd.DataFrame()\n",
    "    for i in [[Our4,Ch3],[Ch3,Our4],[Our4,Ch4],[Ch4,Our4],[Our4,q4factor],[q4factor,Our4],[Our4,FF5_monthly],[FF5_monthly,Our4]]:\n",
    "        a,b,c,d = fac_in_others(i[0], i[1])\n",
    "        temp=pd.DataFrame([a,b,c]+d)\n",
    "        results = pd.concat([results, temp], axis=1)\n",
    "    results.index = ['ave_abs_α','ave_abs_t','△','GRS','GRS_p']\n",
    "    results.columns = ['LSY3','Our4','LSY4','Our4','q4','Our4','FF5','Our4']\n",
    "    return results\n",
    "\n",
    "Tab3 = get_Tab3()\n",
    "Tab3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![6.png](https://i.loli.net/2020/06/20/fHESRs5gdBqitxZ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model performances in explaining anomalies:**     \n",
    "We compare the pricing ability of different factor models in explaining stock return anomalies(14) in China, and report the average absolute monthly alpha (%), the average absolute t -statistics, the aggregate pricing error △, and the Gibbons, Ross, and Shanken (1898) (GRS) F-statistics with associated p-values.    \n",
    "1.exclude the smallest 30% of stocks in forming all the anomalies     \n",
    "2.compute the standard long-short return spread between the extreme decile portfolios sorted by the corresponding\n",
    "anomaly variable in the most recent month, and rebalance the portfolios monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取14个异象因子数据并进行处理\n",
    "bm = pd.read_csv('bm.csv',index_col = 0).iloc[72:-5,:]\n",
    "cp = pd.read_csv('cp.csv',index_col = 0).iloc[72:-5,:]\n",
    "ep = pd.read_csv('ep.csv',index_col = 0).iloc[72:-5,:]\n",
    "illq = pd.read_csv('illq.csv',index_col = 0).iloc[69:-5,:]\n",
    "me = pd.read_csv('me.csv',index_col = 0).iloc[60:-5,:]\n",
    "ret_max = pd.read_csv('ret_max.csv',index_col = 0).iloc[69:-5,:]\n",
    "ret_rev = pd.read_csv('ret_rev.csv',index_col = 0).iloc[69:-5,:]\n",
    "ret_turn = pd.read_csv('ret_turn.csv',index_col = 0).iloc[60:-5,:]\n",
    "roe = pd.read_csv('roe.csv',index_col = 0).iloc[72:-5,:]\n",
    "vol_1m = pd.read_csv('vol_1m.csv',index_col = 0).iloc[69:-5,:]\n",
    "\n",
    "bm.columns, cp.columns, ep.columns, illq.columns, me.columns, ret_max.columns, ret_rev.columns, ret_turn.columns, roe.columns, vol_1m.columns = pd.to_numeric(bm.columns), pd.to_numeric(cp.columns), pd.to_numeric(ep.columns), pd.to_numeric(illq.columns), pd.to_numeric(me.columns), pd.to_numeric(ret_max.columns), pd.to_numeric(ret_rev.columns), pd.to_numeric(ret_turn.columns), pd.to_numeric(roe.columns), pd.to_numeric(vol_1m.columns)\n",
    "valid = [x for x in bm.columns if x in ret.columns]\n",
    "bm,cp,ep,illq,me,ret_max,ret_rev,ret_turn,roe,vol_1m = bm.loc[:, valid],cp.loc[:, valid],ep.loc[:, valid],illq.loc[:, valid],me.loc[:, valid],ret_max.loc[:, valid],ret_rev.loc[:, valid],ret_turn.loc[:, valid],roe.loc[:, valid],vol_1m.loc[:, valid]\n",
    "bm.index, cp.index, ep.index, illq.index, me.index, ret_max.index, ret_rev.index, ret_turn.index, roe.index, vol_1m.index = range(1,164),range(1,164),range(1,164),range(1,164),range(1,164),range(1,164),range(1,164),range(1,164),range(1,164),range(1,164)\n",
    "\n",
    "ER_trend = pd.pivot_table(ER_trend,index='mon_num',columns='Stkcd',values='ER')\n",
    "ER_trendP = pd.pivot_table(ER_trendP,index='mon_num',columns='Stkcd',values='ER')\n",
    "ER_trendV = pd.pivot_table(ER_trendV,index='mon_num',columns='Stkcd',values='ER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mktcap = mktcap[['Stkcd','mon_num','Msmvosd']]#用于加权\n",
    "#计算异象因子对应的高减低组收益率\n",
    "def get_anomalies(factor, ret_month, anomalies, size = 0):\n",
    "    factor_ret = pd.merge(ret_month[['Stkcd','Mretwd','mon_num']], mktcap, on=['Stkcd','mon_num'])\n",
    "    if size == 0:\n",
    "        factor = factor.stack().reset_index().rename(columns={'level_0': 'mon_num','level_1': 'Stkcd',0: anomalies})\n",
    "        factor_ret = pd.merge(factor_ret, factor, on=['Stkcd','mon_num'], how = 'left')\n",
    "    X = pd.DataFrame()\n",
    "    factor_ret = factor_ret.dropna()\n",
    "    factor_ret['ret*mkt'] = factor_ret['Mretwd']*factor_ret['Msmvosd']\n",
    "    for i in range(1,164):\n",
    "        temp_value = factor_ret[factor_ret['mon_num'] == i]\n",
    "        temp_value['sample'] = pd.qcut(temp_value['Msmvosd'],[0,0.3,1],labels=False,duplicates='drop')#去掉30%小市值\n",
    "        temp_value[anomalies+'_n'] = pd.qcut(temp_value[(temp_value['sample'] == 1)][anomalies],10,labels=False,duplicates='drop')\n",
    "        X = pd.concat([X,temp_value],axis=0)\n",
    "    factor_ret = X[(X['sample'] == 1)]\n",
    "    anomaliesHL = pd.DataFrame(index=range(1,164))\n",
    "    for i in [0,9]:\n",
    "        for t in range(1,164):\n",
    "            temp = factor_ret[factor_ret['mon_num'] == t]\n",
    "            #print(t)\n",
    "            anomaliesHL.loc[t,i] = (temp[temp[anomalies+'_n'] == i]['ret*mkt']/(temp[temp[anomalies+'_n'] == i]['Msmvosd'].sum())).sum()\n",
    "    anomalies_fac = pd.DataFrame(anomaliesHL[9] - anomaliesHL[0],index = range(1,164))\n",
    "    return anomalies_fac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "size_f = get_anomalies(mktcap, ret_month, 'Msmvosd', size = 1)\n",
    "ER_f = get_anomalies(ER_trend, ret_month, 'ER')\n",
    "ERp_f = get_anomalies(ER_trendP, ret_month, 'ERp')\n",
    "ERv_f = get_anomalies(ER_trendV, ret_month, 'ERv')\n",
    "bm_f = get_anomalies(bm, ret_month, 'bm')\n",
    "cp_f = get_anomalies(cp, ret_month, 'cp')\n",
    "ep_f = get_anomalies(ep, ret_month, 'ep')\n",
    "illq_f = get_anomalies(illq, ret_month, 'illq')\n",
    "me_f = get_anomalies(me, ret_month, 'me')\n",
    "ret_max_f = get_anomalies(ret_max, ret_month, 'ret_max')\n",
    "ret_rev_f = get_anomalies(ret_rev, ret_month, 'ret_rev')\n",
    "ret_turn_f = get_anomalies(ret_turn, ret_month, 'ret_turn')\n",
    "roe_f = get_anomalies(roe, ret_month, 'roe')\n",
    "vol_1m_f = get_anomalies(vol_1m, ret_month, 'vol_1m')\n",
    "#合并\n",
    "all_anomalies = pd.concat([size_f,ER_f,ERp_f,ERv_f,bm_f,cp_f,ep_f,illq_f,me_f,ret_max_f,ret_rev_f,ret_turn_f,roe_f,vol_1m_f], axis=1)\n",
    "all_anomalies.columns = range(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSY3</th>\n",
       "      <th>LSY4</th>\n",
       "      <th>q4</th>\n",
       "      <th>FF5</th>\n",
       "      <th>Our4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ave_abs_α</th>\n",
       "      <td>0.482395</td>\n",
       "      <td>0.350055</td>\n",
       "      <td>1.021899</td>\n",
       "      <td>0.871186</td>\n",
       "      <td>0.489930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave_abs_t</th>\n",
       "      <td>1.173493</td>\n",
       "      <td>0.855464</td>\n",
       "      <td>2.289888</td>\n",
       "      <td>2.340053</td>\n",
       "      <td>1.265763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>△</th>\n",
       "      <td>0.261769</td>\n",
       "      <td>0.239754</td>\n",
       "      <td>0.316712</td>\n",
       "      <td>0.456817</td>\n",
       "      <td>0.258130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRS</th>\n",
       "      <td>2.428045</td>\n",
       "      <td>2.115499</td>\n",
       "      <td>3.270893</td>\n",
       "      <td>4.866370</td>\n",
       "      <td>2.435868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRS_p</th>\n",
       "      <td>0.006597</td>\n",
       "      <td>0.019119</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.006443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LSY3      LSY4        q4       FF5      Our4\n",
       "ave_abs_α  0.482395  0.350055  1.021899  0.871186  0.489930\n",
       "ave_abs_t  1.173493  0.855464  2.289888  2.340053  1.265763\n",
       "△          0.261769  0.239754  0.316712  0.456817  0.258130\n",
       "GRS        2.428045  2.115499  3.270893  4.866370  2.435868\n",
       "GRS_p      0.006597  0.019119  0.000329  0.000001  0.006443"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_Tab4(anomalies, models):\n",
    "    results = pd.DataFrame()\n",
    "    for model in models:\n",
    "        a,b,c,d = fac_in_others(anomalies, model)\n",
    "        temp=pd.DataFrame([a,b,c]+d)\n",
    "        results = pd.concat([results, temp], axis=1)\n",
    "    results.index = ['ave_abs_α','ave_abs_t','△','GRS','GRS_p']\n",
    "    results.columns = ['LSY3','LSY4','q4','FF5','Our4']#\n",
    "    return results\n",
    "\n",
    "all_anomalies1 = all_anomalies.iloc[:,1:]\n",
    "Tab4 = get_Tab4(all_anomalies1, [Ch3, Ch4, q4factor, FF5_monthly, Our4])\n",
    "Tab4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![7.png](https://i.loli.net/2020/06/20/YSVKqGQLk1wfybl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model performances in explaining mutual fund returns:**     \n",
    "We sort the funds at the end of each month by assets under management (AUM) into ten decile portfolios, examine how the various models perform in explaining the fund returns, and report the average absolute monthly alpha (%), the average absolute t -statistics, the aggregate pricing error △, and the Gibbons, Ross, and Shanken (1898) (GRS) F-statistics with associated p-values.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSY3</th>\n",
       "      <th>LSY4</th>\n",
       "      <th>q4</th>\n",
       "      <th>FF5</th>\n",
       "      <th>Our4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ave_abs_α</th>\n",
       "      <td>0.136630</td>\n",
       "      <td>0.168494</td>\n",
       "      <td>0.709988</td>\n",
       "      <td>0.193179</td>\n",
       "      <td>0.133940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave_abs_t</th>\n",
       "      <td>0.439625</td>\n",
       "      <td>0.529377</td>\n",
       "      <td>1.231936</td>\n",
       "      <td>0.689860</td>\n",
       "      <td>0.408834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>△</th>\n",
       "      <td>0.082716</td>\n",
       "      <td>0.099757</td>\n",
       "      <td>0.129600</td>\n",
       "      <td>0.061977</td>\n",
       "      <td>0.106085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRS</th>\n",
       "      <td>0.933128</td>\n",
       "      <td>1.070639</td>\n",
       "      <td>1.627865</td>\n",
       "      <td>0.803129</td>\n",
       "      <td>1.217636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRS_p</th>\n",
       "      <td>0.504713</td>\n",
       "      <td>0.388423</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.625906</td>\n",
       "      <td>0.284089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LSY3      LSY4        q4       FF5      Our4\n",
       "ave_abs_α  0.136630  0.168494  0.709988  0.193179  0.133940\n",
       "ave_abs_t  0.439625  0.529377  1.231936  0.689860  0.408834\n",
       "△          0.082716  0.099757  0.129600  0.061977  0.106085\n",
       "GRS        0.933128  1.070639  1.627865  0.803129  1.217636\n",
       "GRS_p      0.504713  0.388423  0.103700  0.625906  0.284089"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_Tab5():\n",
    "    fund = pd.read_csv('fund.csv',encoding='gbk')\n",
    "    fund['size'] = fund['最新基金份额']*fund['单位净值']#分组指标\n",
    "    fund['年'] = [int(x) for x in fund['月度']/100]\n",
    "    fund['月'] = fund['月度']%100\n",
    "    fund['mon_num'] = 12*(fund['年']-2005)+fund['月']\n",
    "    X = pd.DataFrame()\n",
    "    fund = fund.dropna()\n",
    "    fund['ret*mkt'] = fund['净值增长率']*fund['size']\n",
    "    for i in range(1,164):\n",
    "        temp_value = fund[fund['mon_num'] == i]\n",
    "        temp_value['size_n'] = pd.qcut(temp_value['size'],10,labels=False,duplicates='drop')\n",
    "        X = pd.concat([X,temp_value],axis=0)\n",
    "    fund = X\n",
    "    fund_fac = pd.DataFrame(index=range(1,164))\n",
    "    #构建基金AUM十分组对应的十个alpha\n",
    "    for i in range(10):\n",
    "        for t in range(1,164):\n",
    "            temp = fund[fund['mon_num'] == t]\n",
    "            #print(t)\n",
    "            fund_fac.loc[t,i] = (temp[temp['size_n'] == i]['ret*mkt']/(temp[temp['size_n'] == i]['size'].sum())).sum()\n",
    "    Tab5 = get_Tab4(fund_fac, [Ch3, Ch4, q4factor, FF5_monthly, Our4])\n",
    "    Tab5.iloc[0,:] = Tab5.iloc[0,:]*0.01\n",
    "    return Tab5\n",
    "\n",
    "Tab5 = get_Tab5()\n",
    "Tab5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![8.png](https://i.loli.net/2020/06/20/KMPz98rjDqc5Gog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sharpe ratio tests:**    \n",
    "We conduct the Sharpe ratio test of Barillas and Shanken (2017) to compare the explaining power without using test assets (defined as the squared Sharpe ratio of the tangency portfolio spanned by the factors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSY3</th>\n",
       "      <th>LSY4</th>\n",
       "      <th>q4</th>\n",
       "      <th>FF5</th>\n",
       "      <th>Our4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sh</th>\n",
       "      <td>0.363114</td>\n",
       "      <td>0.432251</td>\n",
       "      <td>0.224246</td>\n",
       "      <td>0.18576</td>\n",
       "      <td>0.33922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSY3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0691371</td>\n",
       "      <td>-0.138867</td>\n",
       "      <td>-0.177353</td>\n",
       "      <td>-0.0238933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSY4</th>\n",
       "      <td>-0.0691371</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.208005</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>-0.0930304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q4</th>\n",
       "      <td>0.138867</td>\n",
       "      <td>0.208005</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0384857</td>\n",
       "      <td>0.114974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FF5</th>\n",
       "      <td>0.177353</td>\n",
       "      <td>0.24649</td>\n",
       "      <td>0.0384857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Our4</th>\n",
       "      <td>0.0238933</td>\n",
       "      <td>0.0930304</td>\n",
       "      <td>-0.114974</td>\n",
       "      <td>-0.15346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LSY3       LSY4         q4        FF5       Our4\n",
       "Sh     0.363114   0.432251   0.224246    0.18576    0.33922\n",
       "LSY3          0  0.0691371  -0.138867  -0.177353 -0.0238933\n",
       "LSY4 -0.0691371          0  -0.208005   -0.24649 -0.0930304\n",
       "q4     0.138867   0.208005          0 -0.0384857   0.114974\n",
       "FF5    0.177353    0.24649  0.0384857          0    0.15346\n",
       "Our4  0.0238933  0.0930304  -0.114974   -0.15346          0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_Sh(factor):\n",
    "    L = factor.shape[1]\n",
    "    mu_mean = factor.mean(0)\n",
    "    cov_f = np.cov(factor.T).reshape((L, L))\n",
    "    mu_mean = np.asmatrix(mu_mean).reshape(L, 1)\n",
    "    # matrix operation with np.ndarray\n",
    "    Sh = mu_mean.T @ inv(cov_f) @ mu_mean\n",
    "    return  Sh[:, 0][0, 0]\n",
    "\n",
    "def get_Tab6(fac_list):\n",
    "    Sh = []\n",
    "    for i in range(len(fac_list)):\n",
    "        Sh.append(get_Sh(fac_list[i]))\n",
    "    Sh = pd.DataFrame(Sh).T\n",
    "    Sh.columns = ['LSY3','LSY4','q4','FF5','Our4']\n",
    "    \n",
    "    Sh_diff = pd.DataFrame(index = range(5),columns = ['LSY3','LSY4','q4','FF5','Our4'])\n",
    "    for i in range(len(Sh.iloc[0,:])):\n",
    "        for j in range(len(Sh.iloc[0,:])):\n",
    "            Sh_diff.iloc[i,j] = Sh.iloc[0,j] - Sh.iloc[0,i]\n",
    "    Tab6 = pd.concat([Sh,Sh_diff], axis = 0)\n",
    "    return Tab6\n",
    "\n",
    "Tab6 = get_Tab6([Ch3, Ch4, q4factor, FF5_monthly, Our4])\n",
    "Tab6.index = ['Sh', 'LSY3', 'LSY4', 'q4', 'FF5', 'Our4']\n",
    "Tab6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![9.png](https://i.loli.net/2020/06/20/j1BwR5At2ozIbn7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness:     \n",
    "1.The trend factor is robust to alternative formations and transaction costs, and it remains strong after controlling for major firm characteristics.     \n",
    "2.Show further that it also holds in the US, albeit with smaller volume effects due to less individual trading(No report).\n",
    "\n",
    "**Performances of the trend factor under alternative informations:**    \n",
    "Exponential moving average: lamda——the parameter in Equation that determines the weight of the coefficients over different horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>CAPM_α</th>\n",
       "      <th>LSY3_α</th>\n",
       "      <th>LSY4_α</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.717</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>3.330</td>\n",
       "      <td>3.473</td>\n",
       "      <td>1.828</td>\n",
       "      <td>1.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.03</th>\n",
       "      <td>0.421</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.676</td>\n",
       "      <td>1.559</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>0.389</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.849</td>\n",
       "      <td>2.157</td>\n",
       "      <td>1.477</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Mean  CAPM_α  LSY3_α  LSY4_α\n",
       "0.01  0.717   0.718   0.418   0.282\n",
       "      3.330   3.473   1.828   1.211\n",
       "0.03  0.421   0.388   0.141   0.083\n",
       "      1.676   1.559   0.560   0.328\n",
       "0.05  0.389   0.434   0.322   0.242\n",
       "      1.849   2.157   1.477   0.971"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_Tab7():\n",
    "    ER_trend003,_,_ = ERtrend_month(dClsprc_n,dDnvaltrd_n,ret,trade1d,0.03) #取lamda = 0.03\n",
    "    ER_trend001,_,_ = ERtrend_month(dClsprc_n,dDnvaltrd_n,ret,trade1d,0.01) #取lamda = 0.01\n",
    "    ER_trend005,_,_ = ERtrend_month(dClsprc_n,dDnvaltrd_n,ret,trade1d,0.05) #取lamda = 0.05\n",
    "    factor0 = pd.merge(ep_ratio[['Stkcd','mon_num','ep']], mktcap[['Stkcd','mon_num','Msmvosd']], on=['Stkcd','mon_num'])\n",
    "    result = pd.DataFrame()\n",
    "    for ER_trend in [ER_trend001, ER_trend003, ER_trend005]:\n",
    "        factor = pd.merge(factor0, ER_trend, on=['Stkcd','mon_num'], how = 'left')\n",
    "        factor_ret = pd.merge(ret_month[['Stkcd','Mretwd','mon_num']], factor, on=['Stkcd','mon_num'])\n",
    "        factor_ret = get_group(factor_ret, 'Msmvosd', 2, 'ep', 3, 'ER', 3)\n",
    "        Trend,_,_,_,_ = get_factor(factor_ret, 'Msmvosd', 'ep', 'ER')\n",
    "        alpha= []\n",
    "        tvalue = []\n",
    "        mean, t = NWtest(Trend)\n",
    "        alpha.append(mean)\n",
    "        tvalue.append(t)\n",
    "        for i in [[0],[0,1,2],[0,1,2,3]]:\n",
    "            Y = Ch4.iloc[:,i]\n",
    "            model = sm.OLS(Trend.values,sm.add_constant(Y).values).fit(cov_type='HAC',cov_kwds={'maxlags':4})\n",
    "            alpha.append(model.params[0]*100)\n",
    "            tvalue.append(abs(model.tvalues[0]))\n",
    "        result = pd.concat([result, pd.DataFrame([alpha,tvalue])],axis = 0)\n",
    "    result.columns = ['Mean','CAPM_α','LSY3_α','LSY4_α']\n",
    "    result.index = [0.01,'',0.03,'',0.05,'']\n",
    "    return result\n",
    "\n",
    "Tab7 = get_Tab7()\n",
    "Tab7.applymap(lambda x:round(x, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![10.png](https://i.loli.net/2020/06/20/4gOUWfj8EwxdTPl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transaction costs:**     \n",
    "reports the turnover rate and the break-even transaction costs (BETCs) of the trend factor (Trend) and of the turnover factor (PMO)(following Grundy and Martin (2001), and Barroso and Santa-Clara(2015))      \n",
    "1.Zero return: BETCs that would completely offset the returns or the risk-adjusted returns (CAPM alpha)    \n",
    "2.5% Insignificant: BETCs that make the returns or the risk-adjusted returns insignificant at the 5% level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zero return</th>\n",
       "      <th>5% Insignificant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trend-Return</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trend-CAPM alpha</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PMO-Return</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PMO-CAPM alpha</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Zero return  5% Insignificant\n",
       "Trend-Return             0.49              0.12\n",
       "Trend-CAPM alpha         0.52              0.13\n",
       "PMO-Return               0.81              0.34\n",
       "PMO-CAPM alpha           0.97              0.44"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_Cost_005(factor, adjust):\n",
    "    a = 0.01\n",
    "    b = -0.01\n",
    "    while True:\n",
    "        i = (a+b)/2\n",
    "        factor0 = factor - i\n",
    "        if adjust == 0:\n",
    "            _, t = NWtest(factor0)\n",
    "        else:\n",
    "            model = sm.OLS(factor0.values,sm.add_constant(mkt).values).fit()\n",
    "            t = model.tvalues[0]\n",
    "        if t<2:\n",
    "            a = i\n",
    "        elif t>2.05:\n",
    "            b = i\n",
    "        else:\n",
    "            break\n",
    "    return i\n",
    "\n",
    "def get_Tab8(factor,fac_name):\n",
    "    result = pd.DataFrame(columns = ['Zero return', '5% Insignificant'], index = [fac_name+'-Return',fac_name+'-CAPM alpha'])\n",
    "    result.iloc[0,0] = pow(((factor+1).prod(axis = 0)),1/163)-1\n",
    "    result.iloc[0,1] = get_Cost_005(factor, 0)\n",
    "    model = sm.OLS(factor.values,sm.add_constant(mkt).values).fit(cov_type='HAC',cov_kwds={'maxlags':4})\n",
    "    result.iloc[1,0] = pow((((factor-model.params[1]*mkt)+1).prod(axis = 0)),1/163)-1\n",
    "    result.iloc[1,1] = get_Cost_005(factor, 1)\n",
    "    return result*100\n",
    "\n",
    "Tab8 = pd.concat([get_Tab8(Trend,'Trend'),get_Tab8(Ch4.loc[:,'PMO'],'PMO')], axis = 0).applymap(lambda x:round(x, 2))\n",
    "Tab8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![11.png](https://i.loli.net/2020/06/20/qfEibc12AKawMDp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance after controlling for firm characteristics:**      \n",
    "Consider the performance of the trend factor after controlling for size, EP, BM, beta, R_1, R_6_2, R_12_2, IVOL, ILLIQ, and turnover.    \n",
    "1.first sort the stocks by one of the control variables into five quintile groups, and then in each quintile stocks are further sorted into five trend quintile portfolios      \n",
    "2.then average the resulting 5\\*5 portfolios across the five quintiles of the control variable to form five new trend quintile portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入公司特征\n",
    "beta = pd.read_csv('beta.csv',index_col = 0).T.iloc[60:-17,:]\n",
    "valid = [x for x in beta.columns if x in ret.columns]\n",
    "beta = beta.loc[:, valid]\n",
    "beta.index = range(1,164)\n",
    "idio = pd.read_csv('idio_ff_1m.csv',index_col = 0).iloc[95:-17,:]\n",
    "idio.index = range(1,164)\n",
    "import re\n",
    "idio.columns = [re.sub(\"\\D\", \"\", x) for x in idio.columns]\n",
    "idio.columns = pd.to_numeric(idio.columns)\n",
    "valid = sorted([x for x in idio.columns if x in ret.columns])\n",
    "idio = idio.loc[:, valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the prior month return\n",
    "r_1 = ret.shift().iloc[60:,:]\n",
    "r_1.index = range(1,164)\n",
    "\n",
    "def get_R(ret, L):\n",
    "    ret0 = ret+1\n",
    "    X = pd.DataFrame()\n",
    "    for i in range(61,224):\n",
    "        temp = pd.DataFrame(ret0.iloc[i-L-1:i-2,:].prod(axis = 0)).T\n",
    "        X = pd.concat([X, temp],axis=0)\n",
    "    X.index = range(1,164)\n",
    "    return X\n",
    "#the past six-month cumulative return skipping the last month\n",
    "#the past twelve-month cumulative return skipping the last month\n",
    "r_6_2 = get_R(ret, 6)\n",
    "r_12_2 = get_R(ret, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trend-L</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>Trend-H</th>\n",
       "      <th>Trend-H-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Size-Small</th>\n",
       "      <td>1.73</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.69</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.37</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.37</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.43</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.71</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.47</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.78</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.58</td>\n",
       "      <td>-0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.24</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.32</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size-Big</th>\n",
       "      <td>0.94</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.08</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size-Average</th>\n",
       "      <td>1.40</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.51</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Trend-L     2     3     4  Trend-H  Trend-H-L\n",
       "Size-Small       1.73  2.38  2.43  2.57     2.00       0.27\n",
       "                 1.69  2.31  2.37  2.58     2.15       1.01\n",
       "2                1.37  1.84  1.85  2.19     1.87       0.50\n",
       "                 1.43  1.89  1.90  2.20     1.97       2.16\n",
       "3                1.71  1.78  1.68  1.88     1.47      -0.24\n",
       "                 1.78  1.86  1.76  1.99     1.58      -0.96\n",
       "4                1.24  1.54  1.42  1.69     1.57       0.33\n",
       "                 1.32  1.60  1.45  1.76     1.68       1.14\n",
       "Size-Big         0.94  1.46  1.53  1.22     1.53       0.58\n",
       "                 1.08  1.57  1.70  1.43     1.80       1.90\n",
       "Size-Average     1.40  1.80  1.78  1.91     1.69       0.29\n",
       "                 1.51  1.91  1.91  2.07     1.88       1.49"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_Tab9(data1,data2,rt):\n",
    "    '''\n",
    "    输出等权收益和CAPM调整后α，以及两个数值的NW六期滞后t检验值\n",
    "    \n",
    "    参数\n",
    "    data1：分组变量1，面板数据包括股票代码、月份编码和变量值三列\n",
    "    data2：分组变量2，格式同上\n",
    "    rt: 超额收益，格式同上\n",
    "    \n",
    "    输出\n",
    "    df,两个变量1,2,3,4,5,5-1和avg组中的加权平均超额收益和各自5-1组回归CAPMα\n",
    "    ''' \n",
    "    # grouping\n",
    "    X = pd.DataFrame()\n",
    "    data = pd.merge(data1,data2,on=['Stkcd','mon_num'])\n",
    "    data = pd.merge(data,rt,on=['Stkcd','mon_num'])\n",
    "    data = data.dropna()\n",
    "    data['ret*mkt'] = data['Mretwd']*data['Msmvosd']\n",
    "    data1_name = data1.columns[2]\n",
    "    data2_name = data2.columns[2]\n",
    "    \n",
    "    for i in range(1,164):\n",
    "        temp_value = data[data['mon_num'] == i]\n",
    "        temp_value['sample'] = pd.qcut(temp_value['Msmvosd'],[0,0.3,1],labels=False,duplicates='drop')\n",
    "        X = pd.concat([X,temp_value],axis=0)# panel data with group index\n",
    "    data = X[(X['sample'] == 1)]\n",
    "    del data['sample']\n",
    "    X = pd.DataFrame()\n",
    "    for i in range(1,164):\n",
    "        temp_value = data[data['mon_num'] == i]\n",
    "        temp_value['group1'] = pd.qcut(temp_value[data1_name],5,labels=False,duplicates='drop')\n",
    "        x = pd.DataFrame()\n",
    "        for j in range(5):\n",
    "            temp_value2 = temp_value[temp_value['group1']==j]\n",
    "            temp_value2['group2'] = pd.qcut(temp_value2[data2_name],5,labels=False,duplicates='drop')\n",
    "            x = pd.concat([x,temp_value2],axis=0)\n",
    "        X = pd.concat([X,x],axis=0)# panel data with group index\n",
    "    temp = (X.groupby(['mon_num','group1','group2'])['ret*mkt'].sum()/X.groupby(['mon_num','group1','group2'])['Msmvosd'].sum()).reset_index()\n",
    "    temp = temp.rename(columns={0:'rt_w'})\n",
    "    temp = pd.pivot_table(temp,index = ['mon_num','group2'],columns = 'group1')['rt_w'].reset_index()\n",
    "    # avg and 5-1\n",
    "    temp.loc[:,5] = temp.iloc[:,2:7].mean(axis=1)\n",
    "    df = pd.DataFrame()\n",
    "    for i in list(set(temp['mon_num'])):\n",
    "        x = temp[temp['mon_num'] == i].reset_index(drop=True)\n",
    "        x.loc[5,0:] = x.iloc[4,2:]-x.iloc[0,2:]\n",
    "        x.iloc[5,:2] = [i,5]\n",
    "        df = pd.concat([df,x],axis=0)\n",
    "    df.reset_index(drop=True)\n",
    "    # 计算所有组平均超额收益\n",
    "    table = df.groupby('group2').mean().reset_index(drop=True)*100\n",
    "    del table['mon_num']\n",
    "    # 计算所有data2分组内data1 5-1组值调整t检验以及CAPMα回归和调整t值\n",
    "    avg_t = pd.DataFrame(index = range(6), columns = range(6))\n",
    "    for j in range(6):\n",
    "        temp1 = df[df['group2']==j]\n",
    "        temp1.index = temp1['mon_num']\n",
    "        for i in range(6):\n",
    "            model = sm.OLS(temp1.iloc[:,2+i],[1]*len(temp1.iloc[:,2+i]), missing='drop').fit(cov_type='HAC',cov_kwds={'maxlags':4})\n",
    "            avg_t.iloc[j,i] = model.tvalues[0]\n",
    "    tableWhole = pd.DataFrame()\n",
    "    for i in range(6):\n",
    "        tableWhole = pd.concat([tableWhole,table.T.iloc[i,:],avg_t.T.iloc[i,:]],axis=1)\n",
    "    return tableWhole.T\n",
    "\n",
    "Tab9PanelA = get_Tab9(mktcap[['Stkcd','mon_num','Msmvosd']],ER_trend,ret_month[['Stkcd','Mretwd','mon_num']])\n",
    "Tab9PanelA.columns = ['Trend-L',2,3,4,'Trend-H','Trend-H-L']\n",
    "Tab9PanelA.index = ['Size-Small','',2,'',3,'',4,'','Size-Big','','Size-Average','']\n",
    "Tab9PanelA.applymap(lambda x:round(x, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![12.png](https://i.loli.net/2020/06/20/dzGKeOEx8nj6CVJ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trend-L</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>Trend-H</th>\n",
       "      <th>Trend-H-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ep-Average</th>\n",
       "      <td>0.94</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.02</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm-Average</th>\n",
       "      <td>1.14</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.27</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.96</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta-Average</th>\n",
       "      <td>1.13</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.16</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-1-Average</th>\n",
       "      <td>1.13</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.21</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.74</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-6-2-Average</th>\n",
       "      <td>1.33</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.39</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-12-2-Average</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.06</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IVOL-Average</th>\n",
       "      <td>1.34</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.49</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>illq-Average</th>\n",
       "      <td>1.13</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.24</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turnover-Average</th>\n",
       "      <td>1.05</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1.13</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Trend-L     2     3     4  Trend-H  Trend-H-L\n",
       "ep-Average           0.94  1.17  1.38  1.54     1.59       0.66\n",
       "                     1.02  1.34  1.49  1.71     1.78       2.53\n",
       "bm-Average           1.14  1.28  1.52  1.59     1.79       0.65\n",
       "                     1.27  1.42  1.67  1.79     1.96       2.54\n",
       "beta-Average         1.13  1.22  1.36  1.60     1.65       0.52\n",
       "                     1.16  1.29  1.47  1.76     1.82       1.82\n",
       "R-1-Average          1.13  1.40  1.55  1.86     1.82       0.69\n",
       "                     1.21  1.57  1.74  2.01     2.07       2.19\n",
       "R-6-2-Average        1.33  1.37  1.37  1.63     1.66       0.32\n",
       "                     1.39  1.48  1.52  1.86     1.90       1.14\n",
       "R-12-2-Average       0.99  1.26  1.42  1.62     1.72       0.73\n",
       "                     1.06  1.36  1.66  1.84     1.93       2.84\n",
       "IVOL-Average         1.34  1.53  1.72  1.93     1.83       0.49\n",
       "                     1.49  1.74  1.94  2.13     2.07       2.10\n",
       "illq-Average         1.13  1.28  1.48  1.57     1.83       0.71\n",
       "                     1.24  1.41  1.63  1.76     2.09       2.52\n",
       "turnover-Average     1.05  1.20  1.41  1.60     1.66       0.61\n",
       "                     1.13  1.26  1.55  1.75     1.82       2.54"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_Tab9B(control_list,name_list):\n",
    "    i=0\n",
    "    X = pd.DataFrame()\n",
    "    for control in control_list:\n",
    "        control = control.stack().reset_index().rename(columns={'level_0': 'mon_num','level_1': 'Stkcd',0: name_list[i]})\n",
    "        i = i+1\n",
    "        control = pd.merge(control,mktcap[['Stkcd','mon_num','Msmvosd']],on=['Stkcd','mon_num'])\n",
    "        temp = get_Tab9(control,ER_trend,ret_month[['Stkcd','Mretwd','mon_num']]).iloc[-2:,:]\n",
    "        X = pd.concat([X,temp],axis=0)\n",
    "    X.index = ['ep-Average','','bm-Average','','beta-Average','','R-1-Average','','R-6-2-Average','','R-12-2-Average','','IVOL-Average','','illq-Average','','turnover-Average','']\n",
    "    X.columns = ['Trend-L',2,3,4,'Trend-H','Trend-H-L']\n",
    "    return X\n",
    "\n",
    "Tab9B = get_Tab9B([ep,bm,beta,r_1,r_6_2,r_12_2,illq,idio,ret_turn],['ep','bm','beta','R-1','R-6-2','R-12-2','IVOL','illq','ret_turn'])\n",
    "Tab9B.applymap(lambda x:round(x, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![13.png](https://i.loli.net/2020/06/20/uZBjbo8Sze1IAXd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**    \n",
    "The evidence suggests that our trend factor captures unique features of the Chinese stock market that cannot be replicated by the usual firm characteristics.\n",
    "\n",
    "**The US evidence:(No data)**     \n",
    "1.Even in the US, volume can still provide incremental predictive information, albeit small, in addition to price.    \n",
    "2.The the price trend are more important in the USA. This is consistent with the fact that the trading in the Chinese\n",
    "stock market is dominated by individual investors.     \n",
    "\n",
    "**Trend and the participation of retail investors:(No data)**    \n",
    "We use the share-holding ratio of retail investorsin each stock to approximate the uninformed investors' population for the risky asset(data comes from WIND database), and find that the greater the retail investor participation, the better the trend factor performance.     \n",
    "\n",
    "**Trend and volatility of noise trader demand:**     \n",
    "We construct the normalized residual volatility of trading volume to measure noise trader demand volatility (regress the monthly trading volume in month t on that in month t - 1 over the past 12 months), and find that the trend factor earns significantly higher returns in stocks with greater volatility of noise trader demand."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
