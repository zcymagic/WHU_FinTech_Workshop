{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mktcap, Size, BM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\statsmodels\\compat\\pandas.py:23: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mktcap&Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'D:/Postgraduate/2020/asset pricing/data/size_bm_mom_crsp_m.csv' does not exist: b'D:/Postgraduate/2020/asset pricing/data/size_bm_mom_crsp_m.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2f6872ae2845>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#全市场所有股票对应的Market Capital和size指标的构造\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcrsp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:/Postgraduate/2020/asset pricing/data/size_bm_mom_crsp_m.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcrsp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'D:/Postgraduate/2020/asset pricing/data/size_bm_mom_crsp_m.csv' does not exist: b'D:/Postgraduate/2020/asset pricing/data/size_bm_mom_crsp_m.csv'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#全市场所有股票对应的Market Capital和size指标的构造\n",
    "crsp = pd.read_csv(os.path.join(path, '数据', 'size_bm_mom_crsp_m.csv'))\n",
    "crsp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crsp' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-561dc2ad9fe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#US-based common stock filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcrsp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shrcd'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcrsp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shrcd'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcrsp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrsp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrsp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shrcd'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcrsp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shrcd'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'crsp' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#US-based common stock filter\n",
    "crsp[['shrcd']]=crsp[['shrcd']].astype('int')\n",
    "crsp = crsp[(crsp['shrcd'] == 11) | (crsp['shrcd'] == 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mktcap.png](attachment:Mktcap.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# calculate market equity\n",
    "crsp['me'] = crsp['prc'].abs()*crsp['shrout']/1000 \n",
    "crsp.sort_values(by = ['date','permco','me'],inplace = True)\n",
    "\n",
    "#change date format\n",
    "crsp['date']=pd.to_datetime(crsp['date'])\n",
    "crsp['year']=crsp['date'].dt.year\n",
    "crsp['month']=crsp['date'].dt.month\n",
    "\n",
    "# keep December data\n",
    "decme = crsp[crsp['month']==12]\n",
    "decme['size'] = np.log(decme['me'])\n",
    "decme = decme[['year','me','size']]\n",
    "decme = decme[(decme['year'] >= 1988) & (decme['year']<=2012)]\n",
    "mrtcap_size = decme.groupby('year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM=BE/ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了构造BM首先处理公司的加总market equity\n",
    "crsp_summe = crsp.groupby(['date','permco'])['me'].sum().reset_index()\n",
    "crsp_summe.rename(columns = {'me':'me_sum'},inplace = True)\n",
    "crsp2 = pd.merge(crsp, crsp_summe, how = 'inner', on = ['date','permno'])\n",
    "\n",
    "# sort by permno and date and also drop duplicates\n",
    "crsp2 = crsp2.sort_values(by = ['permco','date']).drop_duplicates()\n",
    "crsp2 = crsp2[crsp2['month'] == 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>datadate</th>\n",
       "      <th>cusip</th>\n",
       "      <th>sich</th>\n",
       "      <th>seq</th>\n",
       "      <th>pstkrv</th>\n",
       "      <th>pstkl</th>\n",
       "      <th>pstk</th>\n",
       "      <th>txdb</th>\n",
       "      <th>itcb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1970/12/31</td>\n",
       "      <td>32102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1971/12/31</td>\n",
       "      <td>32102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1972/12/31</td>\n",
       "      <td>32102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1187</td>\n",
       "      <td>1970/12/31</td>\n",
       "      <td>8482101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>1973/12/31</td>\n",
       "      <td>32102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  gvkey    datadate    cusip  sich     seq  pstkrv  pstkl  pstk  \\\n",
       "0           0   1000  1970/12/31    32102   NaN  10.544     0.0    0.0   0.0   \n",
       "1           1   1000  1971/12/31    32102   NaN   8.382     0.0    0.0   0.0   \n",
       "2           2   1000  1972/12/31    32102   NaN   7.021     0.0    0.0   0.0   \n",
       "3           3   1187  1970/12/31  8482101   NaN     NaN     NaN    NaN   NaN   \n",
       "4           4   1000  1973/12/31    32102   NaN   8.567     0.0    0.0   0.0   \n",
       "\n",
       "    txdb  itcb  \n",
       "0  0.000   0.0  \n",
       "1  0.000   0.0  \n",
       "2  0.288   0.0  \n",
       "3    NaN   NaN  \n",
       "4  0.231   0.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#计算Book Equity\n",
    "comp = pd.read_csv(os.path.join(path, '数据', 'size_bm_mom_comp.csv'))\n",
    "comp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BM.png](attachment:BM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert datadate to date fmt\n",
    "comp['datadate'] = pd.to_datetime(comp['datadate']) \n",
    "comp['year'] = comp['datadate'].dt.year\n",
    "\n",
    "# create preferrerd stock\n",
    "comp['ps'] = np.where(comp['pstkrv'].isnull(), comp['pstkl'], comp['pstkrv'])\n",
    "comp['ps'] = np.where(comp['ps'].isnull(), comp['pstk'], comp['ps'])\n",
    "comp['ps'] = np.where(comp['ps'].isnull(), 0, comp['ps'])\n",
    "comp['txdb'] = comp['txdb'].fillna(0)\n",
    "# create book equity\n",
    "comp['be'] = comp['seq'] + comp['txdb'] + comp['itcb'] - comp['ps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>permco</th>\n",
       "      <th>linktype</th>\n",
       "      <th>linkprim</th>\n",
       "      <th>linkdt</th>\n",
       "      <th>linkenddt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>23369.0</td>\n",
       "      <td>LU</td>\n",
       "      <td>P</td>\n",
       "      <td>1970-11-13</td>\n",
       "      <td>1978-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>6398.0</td>\n",
       "      <td>LU</td>\n",
       "      <td>P</td>\n",
       "      <td>1983-09-20</td>\n",
       "      <td>1986-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1002</td>\n",
       "      <td>22159.0</td>\n",
       "      <td>LC</td>\n",
       "      <td>C</td>\n",
       "      <td>1972-12-14</td>\n",
       "      <td>1973-06-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1003</td>\n",
       "      <td>6672.0</td>\n",
       "      <td>LU</td>\n",
       "      <td>C</td>\n",
       "      <td>1983-12-07</td>\n",
       "      <td>1989-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1004</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>LU</td>\n",
       "      <td>P</td>\n",
       "      <td>1972-04-24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gvkey   permco linktype linkprim      linkdt   linkenddt\n",
       "0   1000  23369.0       LU        P  1970-11-13  1978-06-30\n",
       "1   1001   6398.0       LU        P  1983-09-20  1986-07-31\n",
       "2   1002  22159.0       LC        C  1972-12-14  1973-06-05\n",
       "3   1003   6672.0       LU        C  1983-12-07  1989-08-16\n",
       "4   1004  20000.0       LU        P  1972-04-24         NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将me与be通过中介表格ccm匹配\n",
    "ccm = pd.read_csv(os.path.join(path, '数据','size_bm_mom_ccm.csv',index_col=0)\n",
    "ccm['LINKDT']=pd.to_datetime(ccm['LINKDT'], format = '%Y%m%d')\n",
    "ccm['LINKENDDT']=np.where(ccm['LINKENDDT'].str.isnumeric(), ccm['LINKENDDT'], '20200229')\n",
    "ccm['LINKENDDT']=pd.to_datetime(ccm['LINKENDDT'], format = '%Y%m%d')\n",
    "ccm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comp(be)与ccm匹配\n",
    "ccm.rename(columns={'LPERMNO':'permno'},inplace = True)\n",
    "ccm1=pd.merge(comp[['gvkey','datadate','year','be']],ccm,how='left',on=['gvkey'])\n",
    "ccm1=ccm1[(ccm1['datadate']>=ccm1['LINKDT'])&(ccm1['datadate']<=ccm1['LINKENDDT'])]\n",
    "ccm1=ccm1[['gvkey','permno','datadate','year','be']]\n",
    "ccm1.rename(columns={'datadate':'date'},inplace = True)\n",
    "\n",
    "#ccm1与crsp(me)匹配\n",
    "ccm2 = pd.merge(crsp2, ccm1, how='inner', on=['permno', 'year']).drop_duplicates()\n",
    "ccm2 = ccm2[ccm2['me_sum'] != 0]\n",
    "ccm2['bm']=ccm2['be']/ccm2['me_sum']\n",
    "ccm3 = ccm2[['year','bm']]\n",
    "ccm3 = ccm3[ccm3['year']<=2012]\n",
    "bm = ccm3.groupby('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b754d6093005>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m                       index=['Mean','SD','Skew','Kurt','Min','5%','25%','Median','75%','95%','Max','n'])\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MktCap'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmktcap_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'me'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmktcap_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#对分组进行计算求平均\n",
    "def status(groupdata,dataname) : \n",
    "    x = groupdata[dataname]\n",
    "    temp = []\n",
    "    for i in range(1988,2013):\n",
    "        temp.append(x.get_group(i).kurt())\n",
    "    kurt_num = np.mean(temp)\n",
    "    return pd.Series([x.mean().mean(),x.std().mean(),x.skew().mean(),kurt_num,x.min().mean(),x.quantile(.05).mean(),x.quantile(.25).mean(),x.median().mean(),\n",
    "                      x.quantile(.75).mean(),x.quantile(.95).mean(),x.max().mean(),x.count().mean()],\n",
    "                      index=['Mean','SD','Skew','Kurt','Min','5%','25%','Median','75%','95%','Max','n'])\n",
    "df = pd.DataFrame([])\n",
    "df['MrtCap'] = status(mrtcap_size,'me')\n",
    "df['Size'] = status(mrtcap_size,'size')\n",
    "df['BM'] = status(bm,'bm')\n",
    "df = df.apply(lambda x:round(x, 2))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Book.png](attachment:Book.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面计算r_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff=pd.read_csv(os.path.join(path, '数据','F-F_Year_Factors.csv',header=0,index_col=0) #导入年度无风险利率\n",
    "data=crsp[['permno','year','month','ret']] \n",
    "data=data.dropna() #删除缺失值\n",
    "data=data[data['ret']!='C'] #有些数据为C\n",
    "data[['ret']]=data[['ret']].astype(float)  #把ret转成数值\n",
    "data1 = data[(data['year'] >= 1989) & (data['year']<=2012)]      #r_t+1的时间区间与其他指标不同         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['ret2']=data1['ret']+1\n",
    "data2 = (data1['ret2'].groupby([data1['year'], data1['permno']]).prod()-1)*100#根据year和permno分组对ret2连乘求积\n",
    "data2 = data2.reset_index() #重置索引，将原有索引转成列\n",
    "data2 = data2.set_index(\"year\",drop=False)\n",
    "data2=pd.merge(data2, ff, left_index=True,right_index=True)\n",
    "data2['ret3']=data2['ret2']-data2['RF']\n",
    "data3=data2[['year','permno','ret3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#只保留12月有交易的样本\n",
    "data4 = data1[data1['month']==12]   \n",
    "data4 = data4[['permno','month','year']]\n",
    "data5 = pd.merge(data4, data3, how='inner', on=['year','permno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['mean','sd','skew','kurt','min','5%','25%','median','75%','95%','max','n']\n",
    "result=pd.DataFrame(index=list(range(1989,2013)),columns=name)\n",
    "i=0\n",
    "for year in range(1989,2013):\n",
    "    # print(year)\n",
    "    df=data5[data5['year']==year]\n",
    "    result.iloc[i,0]=df['ret3'].mean()\n",
    "    result.iloc[i,1]=df['ret3'].std()\n",
    "    result.iloc[i,2]=df['ret3'].skew()\n",
    "    result.iloc[i,3]=df['ret3'].kurt()\n",
    "    result.iloc[i,4]=df['ret3'].min()\n",
    "    result.iloc[i,5]=df['ret3'].quantile(0.05)\n",
    "    result.iloc[i,6]=df['ret3'].quantile(0.25)\n",
    "    result.iloc[i,7]=df['ret3'].quantile(0.50)\n",
    "    result.iloc[i,8]=df['ret3'].quantile(0.75)\n",
    "    result.iloc[i,9]=df['ret3'].quantile(0.95)\n",
    "    result.iloc[i,10]=df['ret3'].max()\n",
    "    result.iloc[i,11]=len(df)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_t=pd.DataFrame(index=['r_t'],columns=name)\n",
    "for i in range(12):\n",
    "    r_t.iloc[0,i]=result.iloc[:,i].mean()\n",
    "print(r_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面计算beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbd = pd.read_csv(os.path.join(path, '数据', 'crsp_beta_daily.csv'))\n",
    "cbd = cbd[cbd['date'] < 20130101]  # all dates turn out to be < 2013\n",
    "cbd['date'] = cbd['date'].astype(str)\n",
    "cbd['year'] = [x[:4] for x in cbd['date']]\n",
    "for i in range(1988, 2013):\n",
    "    i = str(i)\n",
    "    temp = cbd[cbd['year'] == i]\n",
    "    temp.to_csv(os.path.join(path, '处理后数据', 'cbd_yearly', str(i) + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# something important is that RET has values of 'B' and 'C'\n",
    "temp1 = []\n",
    "for i in range(1988, 2013):\n",
    "    temp = pd.read_csv(os.path.join(path, '处理后数据', 'cbd_yearly', str(i) + '.csv'))\n",
    "    for x in temp['RET']:\n",
    "        try:\n",
    "            float(x)\n",
    "        except:\n",
    "            temp1.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate beta of each permno\n",
    "for i in range(1988, 2013):\n",
    "    temp = pd.read_csv(os.path.join(path,  str(i) + '.csv'))\n",
    "    temp1 = temp.pivot(index='PERMNO', columns='date', values='RET')     #个股收益率\n",
    "    temp2 = temp.pivot(index='PERMNO', columns='date', values='sprtrn')  #市场收益率\n",
    "    temp1.to_csv(os.path.join(path, '处理后数据', 'cbd_yearly_pivot', str(i) + '.csv'))\n",
    "    temp2.to_csv(os.path.join(path, '处理后数据', 'cbd_yearly_sprtrn_pivot', str(i) + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter stocks\n",
    "stock_universe = pd.read_csv('stock_universe.csv', index_col=0)\n",
    "stock_universe['permno'] = stock_universe['permno'].astype(int)\n",
    "for i in range(1988, 2013):\n",
    "    temp1 = pd.read_csv(os.path.join(path, '处理后数据', 'cbd_yearly_pivot', str(i) + '.csv'), index_col=0)  # stock return\n",
    "    temp1.index = temp1.index.astype(int)\n",
    "    valid_stock = [x for x in temp1.index if x in list(stock_universe['permno'])]\n",
    "    temp1 = temp1.loc[valid_stock]\n",
    "    temp1.to_csv(os.path.join(path, '处理后数据', 'cbd_yearly_pivot', str(i) + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def beta(dailyret, Mret):\n",
    "    '''\n",
    "    Calculate beta for stock i at year t.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dailyret: Daily return of stock i in year t.  (pd.Series)\n",
    "    Mret: All daily excess market return and risk-free rate.  (pd.DataFrame)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Beta of stock i at year t.\n",
    "    '''\n",
    "    # 'B', 'C', 0, na are all missing values\n",
    "    dailyret.index = dailyret.index.astype(int)\n",
    "    dailyret = pd.Series(np.where((dailyret == 'B') | (dailyret == 'C'), np.nan, dailyret), index=dailyret.index)\n",
    "    dailyret = dailyret.astype(float)\n",
    "    # daily excess stock return\n",
    "    id1 = Mret.index.tolist().index(dailyret.index[0])\n",
    "    id2 = Mret.index.tolist().index(dailyret.index[-1])\n",
    "    rf = Mret.iloc[id1 : (id2+1), -1]\n",
    "    excessret = dailyret - rf\n",
    "    # daily market return\n",
    "    #mret = Mret + rf\n",
    "    # check valid or not\n",
    "    valid_num = dailyret.notna().sum()\n",
    "    if valid_num >= 200:\n",
    "        X = []\n",
    "        for i in range(-5, 6):\n",
    "            X.append(Mret.iloc[(id1+i) : (id2+i+1), 0])\n",
    "        X = pd.DataFrame(X, columns=dailyret.index).T\n",
    "        model = sm.OLS(excessret, sm.add_constant(X), missing='drop').fit()\n",
    "        result = np.sum(model.params[1:])\n",
    "    else:\n",
    "        result = np.nan\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_beta():\n",
    "    '''\n",
    "    Calculate all betas.\n",
    "    '''\n",
    "    # excess market return and risk-free rate\n",
    "    m_rf = pd.read_csv(os.path.join(path, '数据', 'F-F_Research_Data_Factors_daily.csv'), index_col=0)\n",
    "    m_rf = m_rf / 100\n",
    "    m_rf.index = m_rf.index.astype(int)\n",
    "\n",
    "    for i in range(1988, 2013):\n",
    "        temp = pd.read_csv(os.path.join(path, '处理后数据', 'cbd_yearly_pivot', str(i) + '.csv'), index_col=0)\n",
    "        # market return\n",
    "        beta_i = temp.apply(beta, Mret=m_rf, axis=1)\n",
    "        beta_i = pd.DataFrame(beta_i)\n",
    "        beta_i.to_csv(os.path.join(path, '计算所得指标', 'beta', str(i) + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_beta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "def merge_beta():\n",
    "    '''\n",
    "    Merge yearly beta.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    All betas.  (pd.DataFrame)\n",
    "    '''\n",
    "    temp0 = pd.DataFrame()\n",
    "    for i in range(1988, 2013):\n",
    "        temp = pd.read_csv(os.path.join(path, '计算所得指标', 'beta', str(i) + '.csv'), index_col=0)\n",
    "        temp.columns = [i]\n",
    "        temp0 = pd.concat([temp0, temp], axis=1)\n",
    "\n",
    "    temp0.to_csv(os.path.join(path, '计算所得指标', 'beta.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_beta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = pd.read_csv(os.path.join(path, '计算所得指标', 'beta.csv'), index_col=0)  # merged beta\n",
    "mb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annual summary statistic\n",
    "def annual_summary(df):\n",
    "    '''\n",
    "    Annual summary statistic for df as in the book.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: Merged variable for all years, the columns are years.  (pd.DataFrame)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Annual summary.  (pd.DataFrame)\n",
    "    '''\n",
    "    des = df.describe().T\n",
    "    des[\"5%\"] = df.apply(lambda x: np.percentile(x[x.notna()], q=5))\n",
    "    des['95%'] = df.apply(lambda x: np.percentile(x[x.notna()], q=95))\n",
    "    des['Skew'] = df.skew(axis=0)\n",
    "    des['Kurt'] = df.kurt(axis=0)\n",
    "    des = des[[\n",
    "        'mean', 'std', 'Skew', 'Kurt',\n",
    "        'min', '5%', '25%', '50%',\n",
    "        '75%', '95%', 'max', 'count'\n",
    "    ]]\n",
    "\n",
    "    return des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_summary(df=mb).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
