{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 SKEWNESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Content:\n",
    "* approaches to measuring total skewness, co-skewness (aka systematic skewness), and idiosyncratic skewness\n",
    "* the ability of these variables to predict future stock returns\n",
    "\n",
    "##### Motivation:\n",
    "* The empirical failures of the CAPM prompted researchers to search for other models to describe expected security returns.\n",
    "\n",
    "##### Total skewness:\n",
    "* Arditti (1967, 1971) shows theoretically and empirically that investors demand a higher (lower) rate of return on investments whose return distributions are negatively (positively) skewed.\n",
    "* Scott and Horvath (1980) extend this analysis to include not just the third moment, but all higher moments of the distribution of returns.\n",
    "\n",
    "#####  Systematic skewness: \n",
    "* Kraus and Litzenberger (1976) shows expected security returns are determined not only by the amount of systematic (undiversifiable) variance associated with the security but also by the security's systematic skewness.\n",
    "* Harvey and Siddique (2000) find that systematic skewness commands a risk premium\n",
    "\n",
    "##### Idiosyncratic skewness: \n",
    "* Kane (1982), Beedles (1978) and Conine and Tamarkin (1981): idiosyncratic skewness may be relevant to the pricing of securities\n",
    "* Boyer, Mitton, and Vorkink (2010), Bali, Cakici, and Whitelaw (2011): a strong negative cross-sectional relation with future stock returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1 MEASURING SKEWNESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![skew12.png](https://i.loli.net/2020/05/01/JYoNIOdj5b1KaA7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![skew3.png](https://i.loli.net/2020/05/01/lzTw6YqH71FAyei.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Several different measures(vary in the length of the measurement period and the frequency of the data used to calculate):\n",
    "* calculate each of the variables using one, three, six, and 12 months worth of daily return data(require a minimum of 15, 50, 100, and 200 days of valid returns during the measurement period respectively)\n",
    "* calculate each of the variables using one, two, three, and five years worth of monthly return data(require a minimum of 10, 20, 24, and 24 months of valid returns during the measurement period respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats.mstats import winsorize\n",
    "import openpyxl  # 用于向excel中写入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################拼接初步处理收益数据\n",
    "############日度数据处理\n",
    "a1 = pd.read_csv('1.csv')\n",
    "a2 = pd.read_csv('2.csv')\n",
    "a3 = pd.read_csv('3.csv')\n",
    "a4 = pd.read_csv('4.csv')\n",
    "a5 = pd.read_csv('5.csv')\n",
    "a6 = pd.read_csv('6.csv')\n",
    "a7 = pd.read_csv('7.csv')\n",
    "a8 = pd.read_csv('8.csv')\n",
    "a9 = pd.read_csv('9.csv')\n",
    "a10 = pd.read_csv('10.csv')\n",
    "a11 = pd.read_csv('11.csv')\n",
    "a12 = pd.read_csv('12.csv')\n",
    "a13 = pd.read_csv('13.csv')\n",
    "\n",
    "daily_data = pd.concat([a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11,a12,a13])##concat之后就可以删掉前面单独的数据\n",
    "daily_data['date'] =  pd.to_datetime(daily_data['date'])\n",
    "daily_data['rt'] = daily_data['rt']*100\n",
    "daily_data['year'] = daily_data['date'].dt.year\n",
    "daily_data['month'] = daily_data['date'].dt.month\n",
    "daily_data = daily_data[daily_data['year']>=1995]\n",
    "daily_data = daily_data[daily_data['year']<=2019]\n",
    "\n",
    "Acode = pd.read_csv('Acode.csv')\n",
    "daily_data = pd.merge(daily_data,Acode,on='code')\n",
    "daily_data = daily_data[(daily_data['exchcd']!=2)&(daily_data['exchcd']!=8)]# Sample selection\n",
    "\n",
    "factor_daily = pd.read_csv('fivefactor_daily.csv')\n",
    "factor_daily['date'] =  pd.to_datetime(factor_daily['date'])\n",
    "factor_daily.iloc[:,1:] = factor_daily.iloc[:,1:]*100\n",
    "factor_daily = factor_daily[factor_daily['date'].dt.year>=1995]\n",
    "factor_daily = factor_daily[factor_daily['date'].dt.year<=2019]\n",
    "rf_daily = factor_daily[['date','rf']]\n",
    "daily_data = pd.merge(daily_data,rf_daily,on='date')\n",
    "daily_data['rt'] = daily_data['rt']-daily_data['rf']\n",
    "\n",
    "daily_exrt = pd.pivot_table(daily_data,index='date',columns='code',values='rt')\n",
    "daily_exrt['month_num'] = (daily_exrt.index.year-1995)*12 + daily_exrt.index.month\n",
    "\n",
    "mktrf_daily = factor_daily[['mkt_rf']]\n",
    "mktrf_daily['mkt_rf2'] = mktrf_daily['mkt_rf']**2\n",
    "mktrf_daily.index = factor_daily['date']\n",
    "\n",
    "threefactor_daily = factor_daily[['mkt_rf','smb','hml']]# FF-factor\n",
    "threefactor_daily.index = factor_daily['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "##############月度数据处理\n",
    "monthly = pd.read_csv('monthly.csv')\n",
    "monthly['mktcap'] = monthly['mktcap']*1000\n",
    "monthly = monthly[(monthly['type']!=2)&(monthly['type']!=8)]\n",
    "monthly['date'] = pd.to_datetime(monthly['date'])\n",
    "monthly['month'] = monthly['date'].dt.month\n",
    "monthly['year'] = monthly['date'].dt.year\n",
    "monthly = monthly[monthly['year']>=1995]\n",
    "monthly = monthly[monthly['year']<=2019]\n",
    "monthly['rt'] = monthly['rt']*100\n",
    "\n",
    "factor_monthly = pd.read_csv('fivefactor_monthly.csv')\n",
    "factor_monthly['year'] = factor_monthly['date']//100\n",
    "factor_monthly['month'] = factor_monthly['date']%100\n",
    "factor_monthly = factor_monthly[(factor_monthly['year']>=1995)&(factor_monthly['year']<=2019)]\n",
    "del factor_monthly['date']\n",
    "rf_monthly = factor_monthly[['year','month','rf']]\n",
    "factor_monthly = factor_monthly[(factor_monthly['year']>=2000)&(factor_monthly['year']<=2019)]\n",
    "factor_monthly['month_num'] = (factor_monthly['year']-2000)*12+factor_monthly['month']\n",
    "factor_monthly[['mkt_rf','smb','hml','mom','rf']] = factor_monthly[['mkt_rf','smb','hml','mom','rf']]*100\n",
    "\n",
    "monthly = pd.merge(monthly,rf_monthly,on=['year','month'])\n",
    "monthly['rt'] = monthly['rt'] - monthly['rf']\n",
    "monthly['month_num'] = (monthly['year']-1995)*12+monthly['month']\n",
    "monthly_exrt = pd.pivot_table(monthly,index='month_num',columns='code',values='rt')\n",
    "monthly_exrt['month_num'] = monthly_exrt.index\n",
    "\n",
    "mktrf_monthly = factor_monthly[['mkt_rf']]\n",
    "mktrf_monthly['mkt_rf2'] = mktrf_monthly['mkt_rf']**2\n",
    "mktrf_monthly.index = factor_monthly['month_num']\n",
    "\n",
    "threefactor_monthly = factor_monthly[['mkt_rf','smb','hml']]\n",
    "threefactor_monthly.index= range(1,241)\n",
    "FFCPSfactor_monthly = factor_monthly[['mkt_rf','smb','hml','mom']]\n",
    "FFCPSfactor_monthly.index = range(1,241)\n",
    "\n",
    "psl = pd.read_csv('PSL.csv',index_col=0)\n",
    "psl.index = range(1,241)\n",
    "psl.columns = ['pls']\n",
    "FFCPSfactor_monthly = pd.concat([FFCPSfactor_monthly,psl],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut2000(df):\n",
    "    x = df.loc[:,61:]\n",
    "    x.columns = range(1,241)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################三个偏度指标计算\n",
    "#############skew\n",
    "def skew_calculator(data,span,low_limit):\n",
    "    '''\n",
    "    用来计算skew指标的表格函数，输出计算好的skew的表格。\n",
    "    \n",
    "    输入\n",
    "    ----------\n",
    "    data是以date为index，code为columns（最后一列是date对应的month_num），rt为value\n",
    "    span是每次回归跨度月份数，一年为12\n",
    "    low_limit是计算beta的最低样本数（天数或月数），一个月为10，三个月为50或者一年为10，两年为20等\n",
    "    \n",
    "    输出\n",
    "    -------\n",
    "    index为股票代码，columns为月份编号，value为对应样本期限长度算出skew的df\n",
    "    '''\n",
    "    X = pd.DataFrame()\n",
    "    for i in range(max(data['month_num'])-span+1):\n",
    "        same_time_data = data[(data['month_num']>i)&(data['month_num']<=i+span)]\n",
    "        same_time = []\n",
    "        code_list = list(data.columns[:-1])\n",
    "        for code in code_list:\n",
    "            temp_data = same_time_data[code]\n",
    "            if temp_data.notna().sum() >= low_limit:\n",
    "                skew = temp_data.skew()\n",
    "            else:\n",
    "                skew = np.nan\n",
    "            same_time.append(skew)\n",
    "        same_time = pd.Series(same_time,index = code_list,name = i+span)\n",
    "        X = pd.concat([X,same_time],axis=1,sort=False)\n",
    "    return X    \n",
    "\n",
    "skew_1m = skew_calculator(daily_exrt,1,10)\n",
    "skew_3m = skew_calculator(daily_exrt,3,50)\n",
    "skew_6m = skew_calculator(daily_exrt,6,100)\n",
    "skew_12m = skew_calculator(daily_exrt,12,200)\n",
    "skew_1y = skew_calculator(monthly_exrt,12,10)\n",
    "skew_2y = skew_calculator(monthly_exrt,24,20)\n",
    "skew_3y = skew_calculator(monthly_exrt,36,24)\n",
    "skew_5y = skew_calculator(monthly_exrt,60,24)\n",
    "\n",
    "skew_1m = cut2000(skew_1m)\n",
    "skew_3m = cut2000(skew_3m)\n",
    "skew_6m = cut2000(skew_6m)\n",
    "skew_12m = cut2000(skew_12m)\n",
    "skew_1y = cut2000(skew_1y)\n",
    "skew_2y = cut2000(skew_2y)\n",
    "skew_3y = cut2000(skew_3y)\n",
    "skew_5y = cut2000(skew_5y)\n",
    "\n",
    "skew_1m.to_csv('skew_1m.csv')\n",
    "skew_3m.to_csv('skew_3m.csv')\n",
    "skew_6m.to_csv('skew_6m.csv')\n",
    "skew_12m.to_csv('skew_12m.csv')\n",
    "skew_1y.to_csv('skew_1y.csv')\n",
    "skew_2y.to_csv('skew_2y.csv')\n",
    "skew_3y.to_csv('skew_3y.csv')\n",
    "skew_5y.to_csv('skew_5y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_1m = pd.read_csv('skew_1m.csv',index_col=0)\n",
    "skew_1m.columns = range(1,241)\n",
    "skew_3m = pd.read_csv('skew_3m.csv',index_col=0)\n",
    "skew_3m.columns = range(1,241)\n",
    "skew_6m = pd.read_csv('skew_6m.csv',index_col=0)\n",
    "skew_6m.columns = range(1,241)\n",
    "skew_12m = pd.read_csv('skew_12m.csv',index_col=0)\n",
    "skew_12m.columns = range(1,241)\n",
    "skew_1y = pd.read_csv('skew_1y.csv',index_col=0)\n",
    "skew_1y.columns = range(1,241)\n",
    "skew_2y = pd.read_csv('skew_2y.csv',index_col=0)\n",
    "skew_2y.columns = range(1,241)\n",
    "skew_3y = pd.read_csv('skew_3y.csv',index_col=0)\n",
    "skew_3y.columns = range(1,241)\n",
    "skew_5y = pd.read_csv('skew_5y.csv',index_col=0)\n",
    "skew_5y.columns = range(1,241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############coskew\n",
    "def coskew_calculator(data,factor,span,low_limit):\n",
    "    '''\n",
    "    用来计算coskew指标的表格函数，输出计算好的coskew的表格。\n",
    "    \n",
    "    输入\n",
    "    ----------\n",
    "    data是以date为index，code为columns（最后一列是date对应的month_num），rt为value\n",
    "    factor是市场因子的数据，index为日期或者月份数\n",
    "    span是每次回归跨度月份数，一年为12\n",
    "    low_limit是计算beta的最低样本数（天数或月数），一个月为10，三个月为50或者一年为10，两年为20等\n",
    "    \n",
    "    输出\n",
    "    -------\n",
    "    index为股票代码，columns为月份编号，value为对应样本期限长度算出coskew的df\n",
    "    '''\n",
    "    X = pd.DataFrame()\n",
    "    for i in range(max(data['month_num'])-span+1):\n",
    "        same_time_data = data[(data['month_num']>i)&(data['month_num']<=i+span)]\n",
    "        same_time = []\n",
    "        code_list = list(data.columns[:-1])\n",
    "        for code in code_list:\n",
    "            temp_data = same_time_data[code]\n",
    "            temp_data.name = 'rt'\n",
    "            reg_data = pd.concat([temp_data,factor],axis=1,sort=False,join='inner')\n",
    "            if reg_data['rt'].notna().sum() >= low_limit:\n",
    "                model = smf.ols('rt~mkt_rf+mkt_rf2',reg_data,missing='drop').fit()\n",
    "                coskew = model.params[2]\n",
    "            else:\n",
    "                coskew = np.nan\n",
    "            same_time.append(coskew)\n",
    "        same_time = pd.Series(same_time,index = code_list,name = i+span)\n",
    "        X = pd.concat([X,same_time],sort=False,axis=1)\n",
    "        print(i)\n",
    "    return X\n",
    "\n",
    "coskew_1m = coskew_calculator(daily_exrt,mktrf_daily,1,10)\n",
    "coskew_3m = coskew_calculator(daily_exrt,mktrf_daily,3,50)\n",
    "coskew_6m = coskew_calculator(daily_exrt,mktrf_daily,6,100)\n",
    "coskew_12m = coskew_calculator(daily_exrt,mktrf_daily,12,200)\n",
    "coskew_1y = coskew_calculator(monthly_exrt,mktrf_monthly,12,10)\n",
    "coskew_2y = coskew_calculator(monthly_exrt,mktrf_monthly,24,20)\n",
    "coskew_3y = coskew_calculator(monthly_exrt,mktrf_monthly,36,24)\n",
    "coskew_5y = coskew_calculator(monthly_exrt,mktrf_monthly,60,24)\n",
    "\n",
    "coskew_1m = cut2000(coskew_1m)\n",
    "coskew_3m = cut2000(coskew_3m)\n",
    "coskew_6m = cut2000(coskew_6m)\n",
    "coskew_12m = cut2000(coskew_12m)\n",
    "coskew_1y = cut2000(coskew_1y)\n",
    "coskew_2y = cut2000(coskew_2y)\n",
    "coskew_3y = cut2000(coskew_3y)\n",
    "coskew_5y = cut2000(coskew_5y)\n",
    "\n",
    "coskew_1m.to_csv('coskew_1m.csv')\n",
    "coskew_3m.to_csv('coskew_3m.csv')\n",
    "coskew_6m.to_csv('coskew_6m.csv')\n",
    "coskew_12m.to_csv('coskew_12m.csv')\n",
    "coskew_1y.to_csv('coskew_1y.csv')\n",
    "coskew_2y.to_csv('coskew_2y.csv')\n",
    "coskew_3y.to_csv('coskew_3y.csv')\n",
    "coskew_5y.to_csv('coskew_5y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coskew_1m = pd.read_csv('coskew_1m.csv',index_col=0)\n",
    "coskew_1m.columns = range(1,241)\n",
    "coskew_3m = pd.read_csv('coskew_3m.csv',index_col=0)\n",
    "coskew_3m.columns = range(1,241)\n",
    "coskew_6m = pd.read_csv('coskew_6m.csv',index_col=0)\n",
    "coskew_6m.columns = range(1,241)\n",
    "coskew_12m = pd.read_csv('coskew_12m.csv',index_col=0)\n",
    "coskew_12m.columns = range(1,241)\n",
    "coskew_1y = pd.read_csv('coskew_1y.csv',index_col=0)\n",
    "coskew_1y.columns = range(1,241)\n",
    "coskew_2y = pd.read_csv('coskew_2y.csv',index_col=0)\n",
    "coskew_2y.columns = range(1,241)\n",
    "coskew_3y = pd.read_csv('coskew_3y.csv',index_col=0)\n",
    "coskew_3y.columns = range(1,241)\n",
    "coskew_5y = pd.read_csv('coskew_5y.csv',index_col=0)\n",
    "coskew_5y.columns = range(1,241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################idioskew\n",
    "def idioskew_calculator(data,factor,span,low_limit):\n",
    "    '''\n",
    "    用来计算coskew指标的表格函数，输出计算好的coskew的表格。\n",
    "    \n",
    "    输入\n",
    "    ----------\n",
    "    data是以date为index，code为columns（最后一列是date对应的month_num），rt为value\n",
    "    factor是三因子的数据，index为日期或者月份数\n",
    "    span是每次回归跨度月份数，一年为12\n",
    "    low_limit是计算beta的最低样本数（天数或月数），一个月为10，三个月为50或者一年为10，两年为20等\n",
    "    \n",
    "    输出\n",
    "    -------\n",
    "    index为股票代码，columns为月份编号，value为对应样本期限长度算出coskew的df\n",
    "    '''\n",
    "    X = pd.DataFrame()\n",
    "    for i in range(max(data['month_num'])-span+1):\n",
    "        same_time_data = data[(data['month_num']>i)&(data['month_num']<=i+span)]\n",
    "        same_time = []\n",
    "        code_list = list(data.columns[:-1])\n",
    "        for code in code_list:\n",
    "            temp_data = same_time_data[code]\n",
    "            temp_data.name = 'rt'\n",
    "            reg_data = pd.concat([temp_data,factor],axis=1,sort=False,join='inner')\n",
    "            if reg_data['rt'].notna().sum() >= low_limit:\n",
    "                model = smf.ols('rt~mkt_rf+smb+hml',reg_data,missing='drop').fit()\n",
    "                temp = model.resid\n",
    "                idioskew = temp.skew()\n",
    "            else:\n",
    "                idioskew = np.nan\n",
    "            same_time.append(idioskew)\n",
    "        same_time = pd.Series(same_time,index = code_list,name = i+span)\n",
    "        X = pd.concat([X,same_time],sort=False,axis=1)\n",
    "        print(i)\n",
    "    return X\n",
    "\n",
    "idioskew_1m = idioskew_calculator(daily_exrt,threefactor_daily,1,10)\n",
    "idioskew_3m = idioskew_calculator(daily_exrt,threefactor_daily,3,50)\n",
    "idioskew_6m = idioskew_calculator(daily_exrt,threefactor_daily,6,100)\n",
    "idioskew_12m = idioskew_calculator(daily_exrt,threefactor_daily,12,200)\n",
    "idioskew_1y = idioskew_calculator(monthly_exrt,threefactor_monthly,12,10)\n",
    "idioskew_2y = idioskew_calculator(monthly_exrt,threefactor_monthly,24,20)\n",
    "idioskew_3y = idioskew_calculator(monthly_exrt,threefactor_monthly,36,24)\n",
    "idioskew_5y = idioskew_calculator(monthly_exrt,threefactor_monthly,60,24)\n",
    "\n",
    "idioskew_1m = cut2000(idioskew_1m)\n",
    "idioskew_3m = cut2000(idioskew_3m)\n",
    "idioskew_6m = cut2000(idioskew_6m)\n",
    "idioskew_12m = cut2000(idioskew_12m)\n",
    "idioskew_1y = cut2000(idioskew_1y)\n",
    "idioskew_2y = cut2000(idioskew_2y)\n",
    "idioskew_3y = cut2000(idioskew_3y)\n",
    "idioskew_5y = cut2000(idioskew_5y)\n",
    "\n",
    "idioskew_1m.to_csv('idioskew_1m.csv')\n",
    "idioskew_3m.to_csv('idioskew_3m.csv')\n",
    "idioskew_6m.to_csv('idioskew_6m.csv')\n",
    "idioskew_12m.to_csv('idioskew_12m.csv')\n",
    "idioskew_1y.to_csv('idioskew_1y.csv')\n",
    "idioskew_2y.to_csv('idioskew_2y.csv')\n",
    "idioskew_3y.to_csv('idioskew_3y.csv')\n",
    "idioskew_5y.to_csv('idioskew_5y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idioskew_1m = pd.read_csv('idioskew_1m.csv',index_col=0)\n",
    "idioskew_1m.columns = range(1,241)\n",
    "idioskew_3m = pd.read_csv('idioskew_3m.csv',index_col=0)\n",
    "idioskew_3m.columns = range(1,241)\n",
    "idioskew_6m = pd.read_csv('idioskew_6m.csv',index_col=0)\n",
    "idioskew_6m.columns = range(1,241)\n",
    "idioskew_12m = pd.read_csv('idioskew_12m.csv',index_col=0)\n",
    "idioskew_12m.columns = range(1,241)\n",
    "idioskew_1y = pd.read_csv('idioskew_1y.csv',index_col=0)\n",
    "idioskew_1y.columns = range(1,241)\n",
    "idioskew_2y = pd.read_csv('idioskew_2y.csv',index_col=0)\n",
    "idioskew_2y.columns = range(1,241)\n",
    "idioskew_3y = pd.read_csv('idioskew_3y.csv',index_col=0)\n",
    "idioskew_3y.columns = range(1,241)\n",
    "idioskew_5y = pd.read_csv('idioskew_5y.csv',index_col=0)\n",
    "idioskew_5y.columns = range(1,241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################样本筛选\n",
    "codelist = pd.read_csv('codelist.csv',index_col=0)\n",
    "codelist.columns = range(1,241)\n",
    "codelist = codelist.astype(bool)\n",
    "\n",
    "skew_1m,skew_3m,skew_6m,skew_12m,skew_1y,skew_2y,skew_3y,skew_5y=skew_1m[codelist],skew_3m[codelist],skew_6m[codelist],skew_12m[codelist],skew_1y[codelist],skew_2y[codelist],skew_3y[codelist],skew_5y[codelist]\n",
    "coskew_1m,coskew_3m,coskew_6m,coskew_12m,coskew_1y,coskew_2y,coskew_3y,coskew_5y = coskew_1m[codelist],coskew_3m[codelist],coskew_6m[codelist],coskew_12m[codelist],coskew_1y[codelist],coskew_2y[codelist],coskew_3y[codelist],coskew_5y[codelist]\n",
    "idioskew_1m,idioskew_3m,idioskew_6m,idioskew_12m,idioskew_1y,idioskew_2y,idioskew_3y,idioskew_5y = idioskew_1m[codelist],idioskew_3m[codelist],idioskew_6m[codelist],idioskew_12m[codelist],idioskew_1y[codelist],idioskew_2y[codelist],idioskew_3y[codelist],idioskew_5y[codelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################描述性统计表1\n",
    "def data_statistic(list_of_data):\n",
    "    X = pd.DataFrame()\n",
    "    name_of_data = ['1M','3M','6M','12M','1Y','2Y','3Y','5Y']\n",
    "    for i in range(len(list_of_data)):\n",
    "        x = list_of_data[i]\n",
    "        new = pd.Series([x.mean().mean(),x.std().mean(),x.skew().mean(),x.kurt().mean(),x.min().mean(),x.quantile(.05).mean(),x.quantile(.25).mean(),x.median().mean(),x.quantile(.75).mean(),x.quantile(.95).mean(),x.max().mean(),x.count().mean()],index = ['Mean','SD','Skew','Kurt','Min','5%','25%','Median','75%','95%','Max','n'],name = name_of_data[i])\n",
    "        X = pd.concat([X,new],axis=1)\n",
    "        cols = ['Mean','SD','Skew','Kurt','Min','5%','25%','Median','75%','95%','Max','n']\n",
    "        X = X.loc[cols,:]\n",
    "    X = X.T\n",
    "    X = X.applymap(lambda x:round(x, 2))\n",
    "    return X\n",
    "\n",
    "skew_list = [skew_1m,skew_3m,skew_6m,skew_12m,skew_1y,skew_2y,skew_3y,skew_5y]\n",
    "coskew_list = [coskew_1m,coskew_3m,coskew_6m,coskew_12m,coskew_1y,coskew_2y,coskew_3y,coskew_5y]\n",
    "idioskew_list = [idioskew_1m,idioskew_3m,idioskew_6m,idioskew_12m,idioskew_1y,idioskew_2y,idioskew_3y,idioskew_5y]\n",
    "\n",
    "table1A = data_statistic(skew_list)\n",
    "table1B = data_statistic(coskew_list)\n",
    "table1C = data_statistic(idioskew_list)\n",
    "table1 = pd.concat([table1A,table1B,table1C],keys=['Skew','CoSkew','IdioSkew'])\n",
    "table1.loc[:,'n'] = table1.loc[:,'n'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Table1.png](https://i.loli.net/2020/05/01/N4bSYBWz6LJreDc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The summary statistics show that the measured values of return skewness increase as the measurement period gets longer because the mean, as well as each percentile of the cross-sectional distribution (with the exception of the minimum value) increases when the measurement period is extended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################相关系数表2,3,4&5\n",
    "#####同算法因子相关性矩阵\n",
    "def personcorr_calculator(dataname1,dataname2):\n",
    "    X = []\n",
    "    if len(dataname1.columns)>=len(dataname2.columns):\n",
    "        month_list = dataname2.columns\n",
    "    else:\n",
    "        month_list = dataname1.columns\n",
    "    for y in month_list:\n",
    "        x1 = dataname1[y]\n",
    "        x2 = dataname2[y]\n",
    "        x = pd.concat([x1,x2],axis=1)\n",
    "        x = x.dropna(axis=0,how='any')\n",
    "        person_corr = x.corr().iloc[0,1]\n",
    "        X.append(person_corr)\n",
    "    X = pd.Series(X)\n",
    "    x = X.mean()\n",
    "    return x\n",
    "\n",
    "def spearman_calculator(dataname1,dataname2):\n",
    "    X = []\n",
    "    if len(dataname1.columns)>=len(dataname2.columns):\n",
    "        month_list = dataname2.columns\n",
    "    else:\n",
    "        month_list = dataname1.columns\n",
    "    for y in month_list:\n",
    "        x1 = dataname1[y]\n",
    "        x2 = dataname2[y]\n",
    "        x = pd.concat([x1,x2],axis=1)\n",
    "        x = x.dropna(axis=0,how='any')\n",
    "        spearman_corr = x.corr(method = 'spearman').iloc[0,1]\n",
    "        X.append(spearman_corr)\n",
    "    X = pd.Series(X)\n",
    "    x = X.mean()\n",
    "    return x\n",
    "\n",
    "def corr_in_list(list_of_data):\n",
    "    '''\n",
    "    *data的list顺序要固定\n",
    "    输出对角上半部分为斯皮尔曼系数，对角下半部分为皮尔森系数\n",
    "    '''\n",
    "    name_of_data = ['1M','3M','6M','12M','1Y','2Y','3Y','5Y']\n",
    "    X = pd.DataFrame([],index = name_of_data,columns = name_of_data)\n",
    "    for i in range(len(list_of_data)):\n",
    "        for j in range(len(list_of_data)):\n",
    "            if i<=j:\n",
    "                X.iloc[i,j] = spearman_calculator(list_of_data[i],list_of_data[j])\n",
    "            else:\n",
    "                X.iloc[i,j] = personcorr_calculator(list_of_data[i],list_of_data[j])\n",
    "    X = X.applymap(lambda x:round(x, 2))\n",
    "    return X\n",
    "\n",
    "table2 = corr_in_list(skew_list)\n",
    "table3 = corr_in_list(coskew_list)\n",
    "table4 = corr_in_list(idioskew_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Table2_3_4.png](https://i.loli.net/2020/05/01/5YqVRmkJwdSlsv7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The correlations increase as the amount of overlap in the estimation periods increases.\n",
    "* For a fixed amount of data overlap, the correlations are decreasing as the amount of nonoverlapping data increases.\n",
    "* These patterns are likely to be highly mechanical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########不同算法因子相关性矩阵\n",
    "def corr_in_list2(list_of_data1,list_of_data2,corr_type='person'):\n",
    "    '''\n",
    "    输入\n",
    "    corr_type选择'person'或者'spearman' \n",
    "    *两个datalist顺序要对应\n",
    "    '''\n",
    "    X = []\n",
    "    if corr_type =='person':\n",
    "        for i in range(len(list_of_data1)):\n",
    "            corr = personcorr_calculator(list_of_data1[i],list_of_data2[i])\n",
    "            X.append(corr)\n",
    "    else:\n",
    "        for i in range(len(list_of_data1)):\n",
    "            corr = spearman_calculator(list_of_data1[i],list_of_data2[i])\n",
    "            X.append(corr)      \n",
    "    X = pd.Series(X,index=['1M','3M','6M','12M','1Y','2Y','3Y','5Y'])\n",
    "    return X\n",
    "\n",
    "def corr_df(list_of_data1,list_of_data2,list_of_data3):\n",
    "    x1 = corr_in_list2(list_of_data1,list_of_data2)\n",
    "    x2 = corr_in_list2(list_of_data1,list_of_data3)\n",
    "    x3 = corr_in_list2(list_of_data2,list_of_data3)\n",
    "    X1 = pd.concat([x1,x2,x3],axis=1)\n",
    "    X1.columns = ['Skew-CoSkew','Skew-IdioSkew','CoSkew-IdioSkew']\n",
    "    x4 = corr_in_list2(list_of_data1,list_of_data2,corr_type='spearman')\n",
    "    x5 = corr_in_list2(list_of_data1,list_of_data3,corr_type='spearman')\n",
    "    x6 = corr_in_list2(list_of_data2,list_of_data3,corr_type='spearman')    \n",
    "    X2 = pd.concat([x4,x5,x6],axis=1)\n",
    "    X2.columns = ['Skew-CoSkew','Skew-IdioSkew','CoSkew-IdioSkew']\n",
    "    X = pd.concat([X1.T,X2.T],axis=0,keys=['person','spearman'])\n",
    "    return X\n",
    "        \n",
    "table5 = corr_df(skew_list,coskew_list,idioskew_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Table5.png](https://i.loli.net/2020/05/01/2rA4aSh9TQtP1JN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a positive cross-sectional correlation between skewness and co-skewness\n",
    "* a positive cross-sectional correlation between co-skewness and idiosyncratic skewness\n",
    "* a weak negative cross-sectional correlation between co-skewness and idiosyncratic skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    }
   ],
   "source": [
    "#######################################################与其他因子的相关系数表6\n",
    "def corr_in_list3(list_of_data1,list_of_data2,skew_name):\n",
    "    '''\n",
    "    list1为skew相关因子，list2为其他因子，顺序按照课本表格上顺序\n",
    "    skew_name为因子名，填'skew','coskew'或者'idioskew'\n",
    "    '''\n",
    "    index_name = [skew_name+'1M',skew_name+'3M',skew_name+'6M',skew_name+'12M',skew_name+'1Y',skew_name+'2Y',skew_name+'3Y',skew_name+'5Y']\n",
    "    X1 = pd.DataFrame(index = index_name,columns=['β','Size','BM','Mom','Rev','Illiq'])\n",
    "    X2 = X1.copy()\n",
    "    for i in range(len(list_of_data1)):\n",
    "        for j in range(len(list_of_data2)):\n",
    "            X1.iloc[i,j] = personcorr_calculator(list_of_data1[i],list_of_data2[j])\n",
    "            X2.iloc[i,j] = spearman_calculator(list_of_data1[i],list_of_data2[j])\n",
    "    X = pd.concat([X1,X2],axis=1,keys=['person','spearman'])\n",
    "    return X\n",
    "\n",
    "#########读其他因子值\n",
    "beta = pd.read_csv('beta.csv',index_col=0)\n",
    "beta.columns = range(1,241)\n",
    "size = pd.read_csv('size.csv',index_col=0)\n",
    "size.columns = range(1,241)\n",
    "bm = pd.read_csv('bm.csv',index_col=0)\n",
    "valid = [x for x in bm.index if x in beta.index]\n",
    "bm = bm.loc[valid]\n",
    "bm.columns = range(1,241)\n",
    "mom = pd.read_csv('mom.csv',index_col=0)\n",
    "mom.columns = range(1,241)\n",
    "rev = pd.read_csv('rev.csv',index_col=0)\n",
    "rev.columns = range(1,241)\n",
    "illiq = pd.read_csv('illiq12.csv',index_col=0)\n",
    "valid = [x for x in bm.index if x in beta.index]\n",
    "illiq = illiq.loc[valid]\n",
    "illiq.columns = range(1,241)\n",
    "#########其他因子筛选\n",
    "beta,size,bm,mom,rev,illiq = beta[codelist],size[codelist],bm[codelist],mom[codelist],rev[codelist],illiq[codelist]\n",
    "\n",
    "otherfactor_list = [beta,size,bm,mom,rev,illiq]\n",
    "table6A = corr_in_list3(skew_list,otherfactor_list,'Skew')\n",
    "table6B = corr_in_list3(coskew_list,otherfactor_list,'CoSkew')\n",
    "table6C = corr_in_list3(idioskew_list,otherfactor_list,'IdioSkew')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Table6.png](https://i.loli.net/2020/05/01/sqfPlnoCItviVam.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################持续性表格7,8,9\n",
    "def Persistence_calculator(df):\n",
    "    corr = df.corr()\n",
    "    delay_list = [1,3,6,12,24,36,48,60,120]\n",
    "    X = pd.DataFrame([],index = df.columns,columns = delay_list)\n",
    "    for x in range(len(df.columns)):\n",
    "        for y in range(9):\n",
    "            if x+delay_list[y] < df.shape[1]:\n",
    "                X.iloc[x,y] = corr.iloc[x,x+delay_list[y]]\n",
    "    stats_df = X.mean()\n",
    "    return stats_df\n",
    "\n",
    "def data_autocorr(list_of_data,name):\n",
    "    X = pd.DataFrame()\n",
    "    name_list=[name+'1M',name+'3M',name+'6M',name+'12M',name+'1Y',name+'2Y',name+'3Y',name+'5Y']\n",
    "    for i in list_of_data:\n",
    "        x = Persistence_calculator(i)\n",
    "        X = pd.concat([X,x],axis=1)\n",
    "    del_list = [1,2,3,3,4,5,7]\n",
    "    for j in range(7):\n",
    "        k = del_list[j]\n",
    "        X.iloc[:k,j+1] = np.nan\n",
    "    X.columns = name_list\n",
    "    X = X.applymap(lambda x:round(x, 2))\n",
    "    return X          \n",
    "\n",
    "table7 = data_autocorr(coskew_list,'CoSkew')        \n",
    "table7[table7.isna()] = ' '\n",
    "table8 = data_autocorr(idioskew_list,'IdioSkew')\n",
    "table8[table8.isna()] = ' '\n",
    "table9 = data_autocorr(skew_list,'Skew')    \n",
    "table9[table9.isna()] = ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Table7_8_9.png](https://i.loli.net/2020/05/01/ZInzuftSERkg8Dr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* very little cross-sectional persistence in the these variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################单因子回归10,11,12\n",
    "#生成单因子等权函数\n",
    "def reg_equal_single(factor,factor_name,rt,ffc_factor):\n",
    "    '''\n",
    "    输入因子和收益数据，输出等权超额收益和CAPM调整后的α以及两个数值NW调整滞后六期t检验\n",
    "    \n",
    "    参数\n",
    "    factor：因子值表格，index为股票代码，columns为月份编号\n",
    "    factor_name: 用于分组的因子名\n",
    "    rt: 超额收益，格式同上\n",
    "    ffc_factor：四因子因子，index为月份编号，columns为四个因子缩写\n",
    "    \n",
    "    输出\n",
    "    df，每一行分别为：超额收益，超额收益t检验，CAPMα，α的t检验\n",
    "    columns为1到10还有10-1组\n",
    "    '''\n",
    "    rt_list = pd.DataFrame()\n",
    "    for i in rt.columns:\n",
    "        temp_factor = factor[i]\n",
    "        temp_rt = rt[i]\n",
    "        x = pd.concat([temp_factor,temp_rt],axis=1)\n",
    "        x.columns = ['factor','rt']\n",
    "        x = x.dropna()\n",
    "        x['group'] = pd.qcut(x['factor'],10,duplicates='drop',labels=False)\n",
    "        rt_avg_i = x.groupby('group')['rt'].mean()\n",
    "        rt_list = pd.concat([rt_list,rt_avg_i],axis=1)\n",
    "    rt_list.columns = rt.columns\n",
    "    rt_list = rt_list.T\n",
    "    rt_list.columns = range(1,11)\n",
    "    rt_list['10-1'] = rt_list[10] - rt_list[1]\n",
    "    j ='10-1'\n",
    "    reg_list = pd.concat([rt_list[j],ffc_factor],axis=1,join='inner')\n",
    "#    reg_list.columns = ['rt','mkt_rf','smb','hml','mom']\n",
    "    reg_list.columns = ['rt','mkt_rf','smb','hml','mom','pls']#########\n",
    "    model = smf.ols('rt~mkt_rf+smb+hml+mom',reg_list).fit(cov_type='HAC',cov_kwds={'maxlags':6})\n",
    "    alpha = model.params[0]\n",
    "    alpha_t = model.tvalues[0]\n",
    "    model2 = sm.OLS(rt_list[j],[1]*len(rt_list[j]), missing='drop').fit(cov_type='HAC',cov_kwds={'maxlags':6})\n",
    "    avg_t = model2.tvalues[0]\n",
    "# =============================================================================\n",
    "    model3 = smf.ols('rt~mkt_rf+smb+hml+mom+pls',reg_list).fit(cov_type='HAC',cov_kwds={'maxlags':6})\n",
    "    FFCPSalpha = model3.params[0]\n",
    "    FFCPSalpha_t = model3.tvalues[0]\n",
    "# =============================================================================\n",
    "    rt_avg = round(rt_list.mean(),2)\n",
    "    rt_avg.name = factor_name\n",
    "#    temp = pd.Series([],index = [1,2,3,4,5,6,7,8,9,10,'10-1','FFCα'],name = ' ')\n",
    "    temp = pd.DataFrame(index=[1,2,3,4,5,6,7,8,9,10,'10-1','FFC α'],columns= [' '])\n",
    "    X = pd.concat([rt_avg,temp],axis=1).T\n",
    "    X.loc[' ','10-1'] = '('+str(round(avg_t, 2))+')'\n",
    "    X.loc[factor_name,'FFC α'] = round(alpha, 2)\n",
    "    X.loc[' ','FFC α'] = '('+str(round(alpha_t, 2))+')'\n",
    "# =============================================================================\n",
    "    X.loc[factor_name,'FFCPS α'] = round(FFCPSalpha, 2)\n",
    "    X.loc[' ','FFCPS α'] = '('+str(round(FFCPSalpha_t, 2))+')'\n",
    "# =============================================================================\n",
    "    return X\n",
    "\n",
    "def reg_mktweight_single(factor,factor_name,rt,mkt,ffc_factor):\n",
    "    '''\n",
    "    输入因子和收益数据，输出等权超额收益和CAPM调整后的α以及两个数值NW调整滞后六期t检验\n",
    "    \n",
    "    参数\n",
    "    factor：因子值表格，index为股票代码，columns为月份编号\n",
    "    factor_name: 用于分组的因子名\n",
    "    rt: 超额收益，格式同上\n",
    "    mkt：用来加权的值，这里是市值，格式同上\n",
    "    ffc_factor：四因子因子，index为月份编号，columns为四个因子缩写\n",
    "    \n",
    "    输出\n",
    "    df，每一行分别为：超额收益，超额收益t检验，CAPMα，α的t检验\n",
    "    columns为1到10还有10-1组\n",
    "    '''\n",
    "    rt_list = pd.DataFrame()\n",
    "    for i in rt.columns:\n",
    "        temp_factor = factor[i]\n",
    "        temp_rt = rt[i]\n",
    "        temp_mkt = mkt[i]\n",
    "        x = pd.concat([temp_factor,temp_rt,temp_mkt],axis=1)\n",
    "        x.columns = ['factor','rt','mktcap']\n",
    "        x['rt*mkt'] = x['rt']*x['mktcap']\n",
    "        x = x.dropna()\n",
    "        x['group'] = pd.qcut(temp_factor,10,duplicates='drop',labels=False)\n",
    "        rt_avg_i = x.groupby('group')['rt*mkt'].sum()/x.groupby('group')['mktcap'].sum()\n",
    "        rt_list = pd.concat([rt_list,rt_avg_i],axis=1)\n",
    "    rt_list.columns = rt.columns\n",
    "    rt_list = rt_list.T\n",
    "    rt_list.columns = range(1,11)\n",
    "    rt_list['10-1'] = rt_list[10] - rt_list[1]\n",
    "    j ='10-1'\n",
    "    reg_list = pd.concat([rt_list[j],ffc_factor],axis=1,join='inner')\n",
    "#    reg_list.columns = ['rt','mkt_rf','smb','hml','mom']\n",
    "    reg_list.columns = ['rt','mkt_rf','smb','hml','mom','pls']#########\n",
    "    model = smf.ols('rt~mkt_rf+smb+hml+mom',reg_list).fit(cov_type='HAC',cov_kwds={'maxlags':6})\n",
    "    alpha = model.params[0]\n",
    "    alpha_t = model.tvalues[0]\n",
    "    model2 = sm.OLS(rt_list[j],[1]*len(rt_list[j]), missing='drop').fit(cov_type='HAC',cov_kwds={'maxlags':6})\n",
    "    avg_t = model2.tvalues[0]\n",
    "# =============================================================================\n",
    "    model3 = smf.ols('rt~mkt_rf+smb+hml+mom+pls',reg_list).fit(cov_type='HAC',cov_kwds={'maxlags':6})\n",
    "    FFCPSalpha = model3.params[0]\n",
    "    FFCPSalpha_t = model3.tvalues[0]\n",
    "# =============================================================================\n",
    "    rt_avg = round(rt_list.mean(),2)\n",
    "    rt_avg.name = factor_name\n",
    "#    temp = pd.Series([],index = [1,2,3,4,5,6,7,8,9,10,'10-1','FFCα'],name = ' ')\n",
    "    temp = pd.DataFrame(index=[1,2,3,4,5,6,7,8,9,10,'10-1','FFC α'],columns= [' '])\n",
    "    X = pd.concat([rt_avg,temp],axis=1).T\n",
    "    X.loc[' ','10-1'] = '('+str(round(avg_t, 2))+')'\n",
    "    X.loc[factor_name,'FFC α'] = round(alpha, 2)\n",
    "    X.loc[' ','FFC α'] = '('+str(round(alpha_t, 2))+')'\n",
    "# =============================================================================\n",
    "    X.loc[factor_name,'FFCPS α'] = round(FFCPSalpha, 2)\n",
    "    X.loc[' ','FFCPS α'] = '('+str(round(FFCPSalpha_t, 2))+')'\n",
    "# =============================================================================\n",
    "    return X\n",
    "\n",
    "def reg_list(list_of_factor,list_of_factor_name,rt,mkt,ffc_factor,mktweight=False):\n",
    "    '''\n",
    "    list_of_factor:要进行分类的因子，每个因子表格的格式为：index为股票代码，columns为月份编号\n",
    "    list_of_factor_name：进行分类因子的名称，与factorlist中的顺序要对应\n",
    "    rt: 超额收益，格式同因子数据\n",
    "    mkt：用来加权的值，这里是市值，格式同因子数据\n",
    "    ffc_factor：四因子因子，index为月份编号，columns为四个因子缩写\n",
    "    mktweight:是否用市值加权,输入True和False\n",
    "    '''\n",
    "    X = pd.DataFrame()\n",
    "    if mktweight:\n",
    "        for i in range(len(list_of_factor)):\n",
    "            x = reg_mktweight_single(list_of_factor[i],list_of_factor_name[i],rt,mkt,ffc_factor)\n",
    "            X = pd.concat([X,x],axis=0) \n",
    "    else:\n",
    "        for i in range(len(list_of_factor)):\n",
    "            x = reg_equal_single(list_of_factor[i],list_of_factor_name[i],rt,ffc_factor)\n",
    "            X = pd.concat([X,x],axis=0)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mktcap = pd.pivot_table(monthly,index='code',columns='month_num',values='mktcap')\n",
    "mktcap = cut2000(mktcap)\n",
    "mktcap = mktcap[codelist]\n",
    "monthly_rt = pd.pivot_table(monthly,index='code',columns='month_num',values='rt')\n",
    "monthly_rt = cut2000(monthly_rt)\n",
    "monthly_rt = monthly_rt[codelist]\n",
    "monthly_rt = monthly_rt.shift(-1,axis=1)\n",
    "\n",
    "skew_name = ['Skew1M','Skew3M','Skew6M','Skew12M','Skew1Y','Skew2Y','Skew3Y','Skew5Y']\n",
    "table10A =  reg_list(skew_list,skew_name,monthly_rt,mktcap,FFCPSfactor_monthly)\n",
    "table10A[table10A.isna()] = ' '\n",
    "table10B =  reg_list(skew_list,skew_name,monthly_rt,mktcap,FFCPSfactor_monthly,mktweight=True)\n",
    "table10B[table10B.isna()] = ' '\n",
    "\n",
    "coskew_name = ['CoSkew1M','CoSkew3M','CoSkew6M','CoSkew12M','CoSkew1Y','CoSkew2Y','CoSkew3Y','CoSkew5Y'] \n",
    "table11A =  reg_list(coskew_list,coskew_name,monthly_rt,mktcap,FFCPSfactor_monthly)\n",
    "table11A[table11A.isna()] = ' '\n",
    "table11B =  reg_list(coskew_list,coskew_name,monthly_rt,mktcap,FFCPSfactor_monthly,mktweight=True)\n",
    "table11B[table11B.isna()] = ' '\n",
    "\n",
    "idioskew_name = ['IdioSkew1M','IdioSkew3M','IdioSkew6M','IdioSkew12M','IdioSkew1Y','IdioSkew2Y','IdioSkew3Y','IdioSkew5Y']         \n",
    "table12A =  reg_list(idioskew_list,idioskew_name,monthly_rt,mktcap,FFCPSfactor_monthly)\n",
    "table12A[table12A.isna()] = ' '\n",
    "table12B =  reg_list(idioskew_list,idioskew_name,monthly_rt,mktcap,FFCPSfactor_monthly,mktweight=True)\n",
    "table12B[table12B.isna()] = ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Table10.png](https://i.loli.net/2020/05/01/NEpneKlxskrZ5dF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Table11.png](https://i.loli.net/2020/05/01/2nJXxybKVDmRhSE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Table12.png](https://i.loli.net/2020/05/01/JWZV8Iq6sGoaRwb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the relation between expected stock returns and total skewness: EW(negative and highly statistically significant), VW(negative and statistically insignificant except Skew1M)\n",
    "\n",
    "* the relation between expected stock returns and co-skewness: both statistically significant\n",
    "\n",
    "* the relation between expected stock returns and idiosyncratic skewness: EW(negative and statistically insignificant except IdioSkew1M), VW(negative and statistically insignificant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* consistent with conclusions from Replicating Anomalies in China\n",
    "![re.png](https://i.loli.net/2020/05/02/oK1daONA7PHY4f6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################### FM回归13.14.15\n",
    "final = pd.DataFrame()\n",
    "for temp in [monthly_rt,rev,beta,size,bm,mom,illiq,skew_1m,skew_3m,skew_6m,skew_12m,skew_1y,skew_2y,skew_3y,skew_5y,\\\n",
    "          coskew_1m,coskew_3m,coskew_6m,coskew_12m,coskew_1y,coskew_2y,coskew_3y,coskew_5y,\\\n",
    "          idioskew_1m,idioskew_3m,idioskew_6m,idioskew_12m,idioskew_1y,idioskew_2y,idioskew_3y,idioskew_5y]:\n",
    "    temp=temp.stack()\n",
    "    final = pd.concat([final,temp],axis=1, join='outer')\n",
    "a = final.reset_index()\n",
    "a.columns = ['code','month_num','rt_rf','rev','beta','size','bm','mom','illiq','Skew1M','Skew3M','Skew6M','Skew12M','Skew1Y','Skew2Y','Skew3Y','Skew5Y',\\\n",
    "             'CoSkew1M','CoSkew3M','CoSkew6M','CoSkew12M','CoSkew1Y','CoSkew2Y','CoSkew3Y','CoSkew5Y','IdioSkew1M','IdioSkew3M','IdioSkew6M','IdioSkew12M','IdioSkew1Y','IdioSkew2Y','IdioSkew3Y','IdioSkew5Y']\n",
    "\n",
    "def FM_regression1(independent):\n",
    "    coefs = []\n",
    "    adj_R = []\n",
    "    number = []\n",
    "    # 筛选出所需指标数据\n",
    "    df = a.copy()\n",
    "    FM_df = df[(['month_num','rt_rf'] + independent)].copy()\n",
    "    month = FM_df[['month_num']].drop_duplicates()\n",
    "    month = month.sort_values(by = 'month_num')\n",
    "    month.index = range(1,241)\n",
    "    for i in month['month_num'][:239]: # 最后一列全nan\n",
    "        temp = FM_df[FM_df['month_num'] == i].copy()        \n",
    "        temp = temp.dropna()\n",
    "        number.append(len(temp)) #样本量\n",
    "        temp = temp.drop(columns = 'month_num')\n",
    "        temp[independent] = winsorize(temp[independent], limits=(0.005, 0.005))\n",
    "        Y = temp['rt_rf']\n",
    "        X = temp[independent]\n",
    "        model = sm.OLS(Y.values,sm.add_constant(X).values).fit()\n",
    "        coefs.append(model.params)\n",
    "        adj_R.append(model.rsquared_adj)\n",
    "    col = ['Intercept']+independent    \n",
    "    result = pd.DataFrame(\n",
    "            coefs, \n",
    "            index = month['month_num'][:239],\n",
    "            columns = col\n",
    "            )\n",
    "    result['adj_R'] = adj_R\n",
    "    result['n'] = number\n",
    "    return result\n",
    "\n",
    "def NWtest_1sample(a, lags=6):\n",
    "    adj_a = np.array(a)\n",
    "    # 对常数回归\n",
    "    model = sm.OLS(adj_a, [1] * len(adj_a)).fit(cov_type='HAC', cov_kwds={'maxlags': lags})\n",
    "    return adj_a.mean(), float(model.tvalues)\n",
    "\n",
    "def Table131415fun(table,name,index,colname):\n",
    "    temp = pd.DataFrame()    \n",
    "    for i in range(len(data_list)):\n",
    "        data = data_list[i]\n",
    "        value1 = data.iloc[:, :-2].apply(NWtest_1sample)\n",
    "        value1 = np.array([list(x) for x in value1.values]).reshape(-1)\n",
    "        value1[0:len(value1)-1:2] = [round(x,3) for x in value1[0:len(value1)-1:2]]\n",
    "        value1 = list(value1)\n",
    "        value1[1:len(value1):2] = ['('+str(round(x,2))+')' for x in value1[1:len(value1):2]]\n",
    "        value2 = [round(x,3) for x in data.iloc[:, -2:].mean().values]\n",
    "        value = pd.DataFrame(value1 + value2)\n",
    "        inx = ['Intercept','t']+index[i]+['Adj_R2','n']\n",
    "        value.index = inx\n",
    "        temp = pd.concat([temp,value],axis = 1,join = 'outer')\n",
    "    temp.columns = name\n",
    "    df = temp.T\n",
    "    df = df[colname]\n",
    "    df = df.T\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 13\n",
    "A1  = FM_regression1(['Skew1M'])\n",
    "A2  = FM_regression1(['Skew3M'])\n",
    "A3  = FM_regression1(['Skew6M'])\n",
    "A4  = FM_regression1(['Skew12M'])\n",
    "A5  = FM_regression1(['Skew1Y'])\n",
    "A6  = FM_regression1(['Skew2Y'])\n",
    "A7  = FM_regression1(['Skew3Y'])\n",
    "A8  = FM_regression1(['Skew5Y'])\n",
    "\n",
    "data_list = [A1,A2,A3,A4,A5,A6,A7,A8]\n",
    "colname=['Skew1M','Skew1M_t','Skew3M','Skew3M_t','Skew6M','Skew6M_t','Skew12M','Skew12M_t','Skew1Y','Skew1Y_t','Skew2Y','Skew2Y_t','Skew3Y','Skew3Y_t','Skew5Y','Skew5Y_t','Intercept','t','Adj_R2','n']\n",
    "data_name = ['(1)','(2)','(3)','(4)','(5)','(6)','(7)','(8)']\n",
    "index_name = [['Skew1M','Skew1M_t'],['Skew3M','Skew3M_t'],['Skew6M','Skew6M_t'],['Skew12M','Skew12M_t'],['Skew1Y','Skew1Y_t'],['Skew2Y','Skew2Y_t'],['Skew3Y','Skew3Y_t'],['Skew5Y','Skew5Y_t']]\n",
    "Table13A = Table131415fun(data_list,data_name,index_name,colname)\n",
    "#Table13A = Table13A.applymap(lambda x:round(x, 3))\n",
    "Table13A.loc['n',:] = Table13A.loc['n',:].astype('int')\n",
    "Table13A[Table13A.isna()] = ' '\n",
    "\n",
    "A1  = FM_regression1(['Skew1M','beta','size','bm','mom','rev','illiq'])\n",
    "A2  = FM_regression1(['Skew3M','beta','size','bm','mom','rev','illiq'])\n",
    "A3  = FM_regression1(['Skew6M','beta','size','bm','mom','rev','illiq'])\n",
    "A4  = FM_regression1(['Skew12M','beta','size','bm','mom','rev','illiq'])\n",
    "A5  = FM_regression1(['Skew1Y','beta','size','bm','mom','rev','illiq'])\n",
    "A6  = FM_regression1(['Skew2Y','beta','size','bm','mom','rev','illiq'])\n",
    "A7  = FM_regression1(['Skew3Y','beta','size','bm','mom','rev','illiq'])\n",
    "A8  = FM_regression1(['Skew5Y','beta','size','bm','mom','rev','illiq'])\n",
    "\n",
    "data_list = [A1,A2,A3,A4,A5,A6,A7,A8]\n",
    "colname=['Skew1M','Skew1M_t','Skew3M','Skew3M_t','Skew6M','Skew6M_t','Skew12M','Skew12M_t','Skew1Y','Skew1Y_t','Skew2Y','Skew2Y_t','Skew3Y','Skew3Y_t','Skew5Y','Skew5Y_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t','Intercept','t','Adj_R2','n']\n",
    "data_name = ['(1)','(2)','(3)','(4)','(5)','(6)','(7)','(8)']\n",
    "index_name = [['Skew1M','Skew1M_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['Skew3M','Skew3M_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['Skew6M','Skew6M_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['Skew12M','Skew12M_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['Skew1Y','Skew1Y_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['Skew2Y','Skew2Y_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['Skew3Y','Skew3Y_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['Skew5Y','Skew5Y_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t']]\n",
    "Table13B = Table131415fun(data_list,data_name,index_name,colname)\n",
    "# Table13B = Table13B.applymap(lambda x:round(x, 3))\n",
    "Table13B.loc['n',:] = Table13B.loc['n',:].astype('int')\n",
    "Table13B[Table13B.isna()] = ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Table13.png](https://i.loli.net/2020/05/01/sxdWNfzkruGc86I.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table14\n",
    "A1  = FM_regression1(['CoSkew1M'])\n",
    "A2  = FM_regression1(['CoSkew3M'])\n",
    "A3  = FM_regression1(['CoSkew6M'])\n",
    "A4  = FM_regression1(['CoSkew12M'])\n",
    "A5  = FM_regression1(['CoSkew1Y'])\n",
    "A6  = FM_regression1(['CoSkew2Y'])\n",
    "A7  = FM_regression1(['CoSkew3Y'])\n",
    "A8  = FM_regression1(['CoSkew5Y'])\n",
    "\n",
    "data_list = [A1,A2,A3,A4,A5,A6,A7,A8]\n",
    "colname=['CoSkew1M','CoSkew1M_t','CoSkew3M','CoSkew3M_t','CoSkew6M','CoSkew6M_t','CoSkew12M','CoSkew12M_t','CoSkew1Y','CoSkew1Y_t','CoSkew2Y','CoSkew2Y_t','CoSkew3Y','CoSkew3Y_t','CoSkew5Y','CoSkew5Y_t','Intercept','t','Adj_R2','n']\n",
    "data_name = ['(1)','(2)','(3)','(4)','(5)','(6)','(7)','(8)']\n",
    "index_name = [['CoSkew1M','CoSkew1M_t'],['CoSkew3M','CoSkew3M_t'],['CoSkew6M','CoSkew6M_t'],['CoSkew12M','CoSkew12M_t'],['CoSkew1Y','CoSkew1Y_t'],['CoSkew2Y','CoSkew2Y_t'],['CoSkew3Y','CoSkew3Y_t'],['CoSkew5Y','CoSkew5Y_t']]   \n",
    "Table14A = Table131415fun(data_list,data_name,index_name,colname)\n",
    "# Table14A = Table14A.applymap(lambda x:round(x, 3))\n",
    "Table14A.loc['n',:] = Table14A.loc['n',:].astype('int')\n",
    "Table14A[Table14A.isna()] = ' '\n",
    "\n",
    "A1  = FM_regression1(['CoSkew1M','beta','size','bm','mom','rev','illiq'])\n",
    "A2  = FM_regression1(['CoSkew3M','beta','size','bm','mom','rev','illiq'])\n",
    "A3  = FM_regression1(['CoSkew6M','beta','size','bm','mom','rev','illiq'])\n",
    "A4  = FM_regression1(['CoSkew12M','beta','size','bm','mom','rev','illiq'])\n",
    "A5  = FM_regression1(['CoSkew1Y','beta','size','bm','mom','rev','illiq'])\n",
    "A6  = FM_regression1(['CoSkew2Y','beta','size','bm','mom','rev','illiq'])\n",
    "A7  = FM_regression1(['CoSkew3Y','beta','size','bm','mom','rev','illiq'])\n",
    "A8  = FM_regression1(['CoSkew5Y','beta','size','bm','mom','rev','illiq'])\n",
    "\n",
    "data_list = [A1,A2,A3,A4,A5,A6,A7,A8]\n",
    "colname=['CoSkew1M','CoSkew1M_t','CoSkew3M','CoSkew3M_t','CoSkew6M','CoSkew6M_t','CoSkew12M','CoSkew12M_t','CoSkew1Y','CoSkew1Y_t','CoSkew2Y','CoSkew2Y_t','CoSkew3Y','CoSkew3Y_t','CoSkew5Y','CoSkew5Y_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t','Intercept','t','Adj_R2','n']\n",
    "data_name = ['(1)','(2)','(3)','(4)','(5)','(6)','(7)','(8)']\n",
    "index_name = [['CoSkew1M','CoSkew1M_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['CoSkew3M','CoSkew3M_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['CoSkew6M','CoSkew6M_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['CoSkew12M','CoSkew12M_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['CoSkew1Y','CoSkew1Y_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['CoSkew2Y','CoSkew2Y_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['CoSkew3Y','CoSkew3Y_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['CoSkew5Y','CoSkew5Y_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t']]   \n",
    "Table14B = Table131415fun(data_list,data_name,index_name,colname)\n",
    "# Table14B = Table14B.applymap(lambda x:round(x, 3))\n",
    "Table14B.loc['n',:] = Table14B.loc['n',:].astype('int')\n",
    "Table14B[Table14B.isna()] = ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Table14.png](https://i.loli.net/2020/05/01/dt8Olf5jNF9RcwL.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table15\n",
    "A1  = FM_regression1(['IdioSkew1M'])\n",
    "A2  = FM_regression1(['IdioSkew3M'])\n",
    "A3  = FM_regression1(['IdioSkew6M'])\n",
    "A4  = FM_regression1(['IdioSkew12M'])\n",
    "A5  = FM_regression1(['IdioSkew1Y'])\n",
    "A6  = FM_regression1(['IdioSkew2Y'])\n",
    "A7  = FM_regression1(['IdioSkew3Y'])\n",
    "A8  = FM_regression1(['IdioSkew5Y'])\n",
    "\n",
    "data_list = [A1,A2,A3,A4,A5,A6,A7,A8]\n",
    "colname=['IdioSkew1M','IdioSkew1M_t','IdioSkew3M','IdioSkew3M_t','IdioSkew6M','IdioSkew6M_t','IdioSkew12M','IdioSkew12M_t','IdioSkew1Y','IdioSkew1Y_t','IdioSkew2Y','IdioSkew2Y_t','IdioSkew3Y','IdioSkew3Y_t','IdioSkew5Y','IdioSkew5Y_t','Intercept','t','Adj_R2','n']\n",
    "data_name = ['(1)','(2)','(3)','(4)','(5)','(6)','(7)','(8)']\n",
    "index_name = [['IdioSkew1M','IdioSkew1M_t'],['IdioSkew3M','IdioSkew3M_t'],['IdioSkew6M','IdioSkew6M_t'],['IdioSkew12M','IdioSkew12M_t'],['IdioSkew1Y','IdioSkew1Y_t'],['IdioSkew2Y','IdioSkew2Y_t'],['IdioSkew3Y','IdioSkew3Y_t'],['IdioSkew5Y','IdioSkew5Y_t']]\n",
    "Table15A = Table131415fun(data_list,data_name,index_name,colname)\n",
    "# Table15A = Table15A.applymap(lambda x:round(x, 3))\n",
    "Table15A.loc['n',:] = Table15A.loc['n',:].astype('int')\n",
    "Table15A[Table15A.isna()] = ' '\n",
    "\n",
    "A1  = FM_regression1(['IdioSkew1M','beta','size','bm','mom','rev','illiq'])\n",
    "A2  = FM_regression1(['IdioSkew3M','beta','size','bm','mom','rev','illiq'])\n",
    "A3  = FM_regression1(['IdioSkew6M','beta','size','bm','mom','rev','illiq'])\n",
    "A4  = FM_regression1(['IdioSkew12M','beta','size','bm','mom','rev','illiq'])\n",
    "A5  = FM_regression1(['IdioSkew1Y','beta','size','bm','mom','rev','illiq'])\n",
    "A6  = FM_regression1(['IdioSkew2Y','beta','size','bm','mom','rev','illiq'])\n",
    "A7  = FM_regression1(['IdioSkew3Y','beta','size','bm','mom','rev','illiq'])\n",
    "A8  = FM_regression1(['IdioSkew5Y','beta','size','bm','mom','rev','illiq'])\n",
    "\n",
    "data_list = [A1,A2,A3,A4,A5,A6,A7,A8]\n",
    "colname=['IdioSkew1M','IdioSkew1M_t','IdioSkew3M','IdioSkew3M_t','IdioSkew6M','IdioSkew6M_t','IdioSkew12M','IdioSkew12M_t','IdioSkew1Y','IdioSkew1Y_t','IdioSkew2Y','IdioSkew2Y_t','IdioSkew3Y','IdioSkew3Y_t','IdioSkew5Y','IdioSkew5Y_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t','Intercept','t','Adj_R2','n']\n",
    "data_name = ['(1)','(2)','(3)','(4)','(5)','(6)','(7)','(8)']\n",
    "index_name = [['IdioSkew1M','IdioSkew1M_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['IdioSkew3M','IdioSkew3M_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['IdioSkew6M','IdioSkew6M_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['IdioSkew12M','IdioSkew12M_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['IdioSkew1Y','IdioSkew1Y_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['IdioSkew2Y','IdioSkew2Y_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['IdioSkew3Y','IdioSkew3Y_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t'],['IdioSkew5Y','IdioSkew5Y_t','beta','beta_t','Size','Size_t','BM','BM_t','Mom','Mom_t','Rev','Rev_t','Illiq','Illiq_t']]\n",
    "Table15B = Table131415fun(data_list,data_name,index_name,colname)\n",
    "# Table15B = Table15B.applymap(lambda x:round(x, 3))\n",
    "Table15B.loc['n',:] = Table15B.loc['n',:].astype('int')\n",
    "Table15B[Table15B.isna()] = ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Table15.png](https://i.loli.net/2020/05/01/rRouEzgWYKd759m.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
