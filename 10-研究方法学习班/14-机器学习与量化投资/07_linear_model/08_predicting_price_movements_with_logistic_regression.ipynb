{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting stock price moves with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:14:26.572365Z",
     "start_time": "2022-11-08T12:14:26.556894Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:14:36.854654Z",
     "start_time": "2022-11-08T12:14:27.231287Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys, os\n",
    "from time import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:14:43.969472Z",
     "start_time": "2022-11-08T12:14:36.890455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: utils in c:\\users\\86152\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:14:44.015439Z",
     "start_time": "2022-11-08T12:14:44.002352Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:14:44.077416Z",
     "start_time": "2022-11-08T12:14:44.050461Z"
    }
   },
   "outputs": [],
   "source": [
    "# sequential data like time series requires careful cross-validation to be set up so that we do not inadvertently introduce look-ahead bias or leakage\n",
    "class MultipleTimeSeriesCV: #多重时间序列交叉验证(Cross-validating)\n",
    "    \"\"\"Generates tuples of train_idx, test_idx pairs\n",
    "    Assumes the MultiIndex contains levels 'symbol' and 'date'\n",
    "    purges overlapping outcomes\"\"\"\n",
    "\n",
    "    def __init__(self, #实例\n",
    "                 n_splits=3, #实例属性\n",
    "                 train_period_length=126, \n",
    "                 test_period_length=21,\n",
    "                 lookahead=None, #提前量\n",
    "                 shuffle=False):\n",
    "        self.n_splits = n_splits\n",
    "        self.lookahead = lookahead\n",
    "        self.test_length = test_period_length\n",
    "        self.train_length = train_period_length\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    #The split() method returns a generator yielding pairs of train and test indices,\n",
    "    #which we can then use to select outcomes and features.\n",
    "    #The number of pairs depends on the parameter n_splits\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        unique_dates = X.index.get_level_values('date').unique() #获取唯一的日期\n",
    "        days = sorted(unique_dates, reverse=True) #!!!倒序排列日期，这与后面倒着定义训练集，测试集的坐标相关\n",
    "\n",
    "        split_idx = []\n",
    "        for i in range(self.n_splits): #self.n_splits默认为3，即应循环3次\n",
    "            test_end_idx = i * self.test_length #self.test_length默认为21，test_end_idx为21*i (i = 0,1,2)\n",
    "            test_start_idx = test_end_idx + self.test_length #test_start_idx = test_end_idx + 21\n",
    "            train_end_idx = test_start_idx + + self.lookahead - 1 #train_end_idx = test_start_idx + self.lookahead - 1\n",
    "            train_start_idx = train_end_idx + self.train_length + self.lookahead - 1 #train_start_idx = train_end_idx + 125 + self.lookahead\n",
    "            split_idx.append([train_start_idx, train_end_idx,\n",
    "                              test_start_idx, test_end_idx]) #将三次train_test对应的训练集，测试集的坐标保存到split_idx中\n",
    "\n",
    "        dates = X.reset_index()[['date']] #给X重设index并提取其中的日期项,dates的日期项的顺序是正的，包含了所有股票在所选时间的序列。而days则只包含了不重复的时间数据。\n",
    "        for train_start, train_end, test_start, test_end in split_idx: #依次读取每次训练的days的数据坐标，注意这些坐标数据是由“远”及“近”的\n",
    "            train_idx = dates[(dates.date > days[train_start])\n",
    "                              & (dates.date <= days[train_end])].index #获取train_set的index，其由dates的index而来，因此是正序的，而且这一index的范围囊括了所有对象股\n",
    "            test_idx = dates[(dates.date > days[test_start])\n",
    "                             & (dates.date <= days[test_end])].index\n",
    "            if self.shuffle: #默认为False\n",
    "                np.random.shuffle(list(train_idx)) #对train_idx中的项(index)进行洗牌\n",
    "                \n",
    "            yield train_idx, test_idx\n",
    "            #yield的作用：返回一个可以用来迭代(for循环)的生成器，它的应用场景通常为一个需要返回一系列值的，含有循环的函数中\n",
    "\n",
    "    def get_n_splits(self, X, y, groups=None): #返回n_split这个参数，即滚动窗口的次数\n",
    "        return self.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:14:44.124530Z",
     "start_time": "2022-11-08T12:14:44.113462Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:14:44.171501Z",
     "start_time": "2022-11-08T12:14:44.158890Z"
    }
   },
   "outputs": [],
   "source": [
    "YEAR = 252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:14:55.012642Z",
     "start_time": "2022-11-08T12:14:44.207385Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore('data.h5') as store:\n",
    "    data = (store['model_data']\n",
    "            .dropna()\n",
    "            .drop(['open', 'close', 'low', 'high'], axis=1))\n",
    "data = data.drop([c for c in data.columns if 'year' in c or 'lag' in c], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Investment Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:14:58.045115Z",
     "start_time": "2022-11-08T12:14:57.925756Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data[data.dollar_vol_rank<100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:14:58.320877Z",
     "start_time": "2022-11-08T12:14:58.277534Z"
    }
   },
   "outputs": [],
   "source": [
    "y = data.filter(like='target')\n",
    "X = data.drop(y.columns, axis=1)\n",
    "X = X.drop(['dollar_vol', 'dollar_vol_rank', 'volume', 'consumer_durables'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define cross-validation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:14:58.707488Z",
     "start_time": "2022-11-08T12:14:58.695316Z"
    }
   },
   "outputs": [],
   "source": [
    "train_period_length = 63\n",
    "test_period_length = 10\n",
    "lookahead =1\n",
    "n_splits = int(3 * YEAR/test_period_length)\n",
    "\n",
    "cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                          test_period_length=test_period_length,\n",
    "                          lookahead=lookahead,\n",
    "                          train_period_length=train_period_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:14:59.155123Z",
     "start_time": "2022-11-08T12:14:59.144318Z"
    }
   },
   "outputs": [],
   "source": [
    "target = f'target_{lookahead}d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:15:02.170116Z",
     "start_time": "2022-11-08T12:14:59.622171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    56486\n",
       "0    53189\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.loc[:, 'label'] = (y[target] > 0).astype(int)\n",
    "y.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:15:02.729468Z",
     "start_time": "2022-11-08T12:15:02.713447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02,\n",
       "       1.e+03, 1.e+04, 1.e+05])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cs = np.logspace(-5, 5, 11)\n",
    "Cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:15:03.146020Z",
     "start_time": "2022-11-08T12:15:03.136054Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['C', 'date', 'auc', 'ic', 'pval']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-08T12:14:30.641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n",
      "\t 52.0 | 010 |  -0.31% |  50.42%\n",
      "\t 58.7 | 020 |   1.89% |  51.83%\n",
      "\t 65.5 | 030 |   2.84% |  52.01%\n",
      "\t 72.6 | 040 |   3.29% |  51.98%\n",
      "\t 79.7 | 050 |   3.97% |  52.44%\n",
      "\t 86.6 | 060 |   3.96% |  52.27%\n",
      "\t 94.4 | 070 |   4.73% |  52.59%\n",
      "0.0001\n",
      "\t  8.1 | 010 |  -0.06% |  50.62%\n",
      "\t 17.6 | 020 |   2.23% |  52.01%\n",
      "\t 26.1 | 030 |   3.20% |  52.26%\n",
      "\t 33.4 | 040 |   3.34% |  52.08%\n",
      "\t 40.7 | 050 |   4.02% |  52.53%\n",
      "\t 47.9 | 060 |   4.02% |  52.33%\n",
      "\t 55.5 | 070 |   4.83% |  52.67%\n",
      "0.001\n",
      "\t 10.4 | 010 |   0.42% |  50.96%\n",
      "\t 18.0 | 020 |   2.53% |  52.14%\n",
      "\t 26.0 | 030 |   3.58% |  52.48%\n",
      "\t 33.9 | 040 |   3.17% |  52.07%\n",
      "\t 41.4 | 050 |   3.83% |  52.49%\n",
      "\t 49.1 | 060 |   4.03% |  52.33%\n",
      "\t 56.6 | 070 |   4.88% |  52.70%\n",
      "0.01\n",
      "\t  8.7 | 010 |   0.68% |  51.13%\n",
      "\t 16.5 | 020 |   2.39% |  51.97%\n",
      "\t 24.4 | 030 |   3.64% |  52.41%\n",
      "\t 32.2 | 040 |   3.12% |  51.94%\n",
      "\t 40.3 | 050 |   3.92% |  52.46%\n",
      "\t 48.8 | 060 |   4.16% |  52.30%\n",
      "\t 56.2 | 070 |   4.91% |  52.64%\n",
      "0.1\n",
      "\t 20.0 | 010 |   0.65% |  51.11%\n",
      "\t 33.4 | 020 |   2.17% |  51.80%\n",
      "\t 41.9 | 030 |   3.49% |  52.28%\n",
      "\t 50.7 | 040 |   2.94% |  51.80%\n",
      "\t 59.6 | 050 |   3.74% |  52.31%\n",
      "\t 68.8 | 060 |   3.93% |  52.15%\n",
      "\t 77.4 | 070 |   4.59% |  52.46%\n",
      "1.0\n",
      "\t  9.0 | 010 |   0.60% |  51.07%\n",
      "\t 18.7 | 020 |   2.13% |  51.77%\n",
      "\t 28.5 | 030 |   3.45% |  52.26%\n",
      "\t 38.0 | 040 |   2.90% |  51.77%\n",
      "\t 47.9 | 050 |   3.68% |  52.28%\n",
      "\t 56.9 | 060 |   3.86% |  52.11%\n",
      "\t 66.0 | 070 |   4.50% |  52.41%\n",
      "10.0\n",
      "\t  8.5 | 010 |   0.59% |  51.07%\n",
      "\t 17.1 | 020 |   2.12% |  51.76%\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_coeffs, log_scores, log_predictions = {}, [], []\n",
    "for C in Cs:\n",
    "    print(C)\n",
    "    model = LogisticRegression(C=C, #C：正则化强度的倒数，必须是一个大于0的浮点数，不填写默认1.0，即默认正则项与损失函数的比值是1：1。\n",
    "                               #C越小，损失函数会越小，模型对损失函数的惩罚越重，正则化的效力越强，参数会逐渐被压缩得越来越小。\n",
    "                               fit_intercept=True,\n",
    "                               random_state=42,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()), #加入了正则化项来提高模型的泛化性，而使用正则化必须要进行标准化操作，从而使参数的数量级一致\n",
    "        ('model', model)])\n",
    "    ics = aucs = 0\n",
    "    start = time()\n",
    "    coeffs = []\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(X), 1):\n",
    "        X_train, y_train, = X.iloc[train_idx], y.label.iloc[train_idx]\n",
    "        pipe.fit(X=X_train, y=y_train)\n",
    "        X_test, y_test = X.iloc[test_idx], y.label.iloc[test_idx]\n",
    "        actuals = y[target].iloc[test_idx]\n",
    "        if len(y_test) < 10 or len(np.unique(y_test)) < 2:\n",
    "            continue\n",
    "        y_score = pipe.predict_proba(X_test)[:, 1]\n",
    "       \n",
    "        auc = roc_auc_score(y_score=y_score, y_true=y_test)\n",
    "        actuals = y[target].iloc[test_idx]\n",
    "        ic, pval = spearmanr(y_score, actuals)\n",
    "\n",
    "        log_predictions.append(y_test.to_frame('labels').assign(\n",
    "            predicted=y_score, C=C, actuals=actuals))\n",
    "        date = y_test.index.get_level_values('date').min()\n",
    "        log_scores.append([C, date, auc, ic * 100, pval])\n",
    "        coeffs.append(pipe.named_steps['model'].coef_)\n",
    "        ics += ic\n",
    "        aucs += auc\n",
    "        if i % 10 == 0:\n",
    "            print(f'\\t{time()-start:5.1f} | {i:03} | {ics/i:>7.2%} | {aucs/i:>7.2%}')\n",
    "\n",
    "    log_coeffs[C] = np.mean(coeffs, axis=0).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-08T12:14:30.965Z"
    }
   },
   "outputs": [],
   "source": [
    "log_scores = pd.DataFrame(log_scores, columns=cols)\n",
    "log_scores.to_hdf('data.h5', 'logistic/scores')\n",
    "\n",
    "log_coeffs = pd.DataFrame(log_coeffs, index=X.columns).T\n",
    "log_coeffs.to_hdf('data.h5', 'logistic/coeffs')\n",
    "\n",
    "log_predictions = pd.concat(log_predictions)\n",
    "log_predictions.to_hdf('data.h5', 'logistic/predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-08T12:14:31.139Z"
    }
   },
   "outputs": [],
   "source": [
    "log_scores = pd.read_hdf('data.h5', 'logistic/scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-08T12:14:31.284Z"
    }
   },
   "outputs": [],
   "source": [
    "log_scores.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-08T12:14:31.525Z"
    }
   },
   "outputs": [],
   "source": [
    "log_scores.groupby('C').auc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Validation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-08T12:14:32.960Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_ic_distribution(df, ax=None):\n",
    "    if ax is not None:\n",
    "        sns.distplot(df.ic, ax=ax)    \n",
    "    else:\n",
    "        ax = sns.distplot(df.ic)\n",
    "    mean, median = df.ic.mean(), df.ic.median()\n",
    "    ax.axvline(0, lw=1, ls='--', c='k')\n",
    "    ax.text(x=.05, y=.9, s=f'Mean: {mean:8.2f}\\nMedian: {median:5.2f}',\n",
    "            horizontalalignment='left',\n",
    "            verticalalignment='center',\n",
    "            transform=ax.transAxes)\n",
    "    ax.set_xlabel('Information Coefficient')\n",
    "    sns.despine()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-08T12:14:33.122Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes= plt.subplots(ncols=2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(x='C', y='auc', data=log_scores, estimator=np.mean, label='Mean', ax=axes[0])\n",
    "by_alpha = log_scores.groupby('C').auc.agg(['mean', 'median'])\n",
    "best_auc = by_alpha['mean'].idxmax()\n",
    "by_alpha['median'].plot(logx=True, ax=axes[0], label='Median', xlim=(10e-6, 10e5))\n",
    "axes[0].axvline(best_auc, ls='--', c='k', lw=1, label='Max. Mean')\n",
    "axes[0].axvline(by_alpha['median'].idxmax(), ls='-.', c='k', lw=1, label='Max. Median')\n",
    "axes[0].legend()\n",
    "axes[0].set_ylabel('AUC')\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_title('Area Under the Curve')\n",
    "\n",
    "plot_ic_distribution(log_scores[log_scores.C==best_auc], ax=axes[1])\n",
    "axes[1].set_title('Information Coefficient')\n",
    "\n",
    "fig.suptitle('Logistic Regression', fontsize=14)\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=.9);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
