{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to implement cross-validation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will illustrate various options for splitting data into training and test sets. We'll do this \n",
    "by showing how the indices of a mock dataset with 10 observations are assigned to the train \n",
    "and test set, as shown in following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (train_test_split,\n",
    "                                     KFold,\n",
    "                                     LeaveOneOut,\n",
    "                                     LeavePOut,\n",
    "                                     ShuffleSplit,\n",
    "                                     TimeSeriesSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "data = list(range(1, 11)) #the mock dataset\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single split of your data into a training and a test set, use ```train_test_split```, where \n",
    "the ```shuffle``` parameter, by default, ensures the randomized selection of observations. You \n",
    "can ensure replicability by seeding the random number generator by setting ```random_state```. \n",
    "There is also a stratify parameter, which ensures for a classifjcation problem that the train \n",
    "and test sets will contain approximately the same proportion of each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9, 6, 8, 10, 2, 3, 5, 4], [7, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(train_test_split(data, train_size=.8)) #训练集：验证集=4:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we train a model using all data except row numbers **6** and **9**, which will be \n",
    "used to generate predictions and measure the errors given on the known labels. This \n",
    "method is useful for quick evaluation but is sensitive to the split, and the standard error of \n",
    "the performance measure estimate will be higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFold iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KFold iterator produces several disjunct splits and assigns each of these splits once to \n",
    "the validation set, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 3 4 5 6 7 9] [1 8]\n",
      "[1 2 3 4 6 7 8 9] [0 5]\n",
      "[0 1 3 4 5 6 8 9] [2 7]\n",
      "[0 1 2 3 5 6 7 8] [4 9]\n",
      "[0 1 2 4 5 7 8 9] [3 6]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42) #分k次，互斥集\n",
    "for train, validate in kf.split(data):\n",
    "    print(train, validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-one-out CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original CV implementation used a leave-one-out method that **used each observation \n",
    "once as the validation set**, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9] [0]\n",
      "[0 2 3 4 5 6 7 8 9] [1]\n",
      "[0 1 3 4 5 6 7 8 9] [2]\n",
      "[0 1 2 4 5 6 7 8 9] [3]\n",
      "[0 1 2 3 5 6 7 8 9] [4]\n",
      "[0 1 2 3 4 6 7 8 9] [5]\n",
      "[0 1 2 3 4 5 7 8 9] [6]\n",
      "[0 1 2 3 4 5 6 8 9] [7]\n",
      "[0 1 2 3 4 5 6 7 9] [8]\n",
      "[0 1 2 3 4 5 6 7 8] [9]\n"
     ]
    }
   ],
   "source": [
    "loo = LeaveOneOut()  #每次取一个值作为验证集，验证集互斥\n",
    "for train, validate in loo.split(data):\n",
    "    print(train, validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This maximizes the number of models that are trained, which **increases computational \n",
    "costs**. While the validation sets do not overlap, the overlap of training sets is maximized, \n",
    "driving up the correlation of models and their prediction errors. As a result, the variance of \n",
    "the prediction error is higher for a model with a larger number of folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-P-Out CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar version to leave-one-out CV is leave-P-out CV, which generates all possible \n",
    "combinations of p data rows, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5 6 7 8 9] [0 1]\n",
      "[1 3 4 5 6 7 8 9] [0 2]\n",
      "[1 2 4 5 6 7 8 9] [0 3]\n",
      "[1 2 3 5 6 7 8 9] [0 4]\n",
      "[1 2 3 4 6 7 8 9] [0 5]\n",
      "[1 2 3 4 5 7 8 9] [0 6]\n",
      "[1 2 3 4 5 6 8 9] [0 7]\n",
      "[1 2 3 4 5 6 7 9] [0 8]\n",
      "[1 2 3 4 5 6 7 8] [0 9]\n",
      "[0 3 4 5 6 7 8 9] [1 2]\n",
      "[0 2 4 5 6 7 8 9] [1 3]\n",
      "[0 2 3 5 6 7 8 9] [1 4]\n",
      "[0 2 3 4 6 7 8 9] [1 5]\n",
      "[0 2 3 4 5 7 8 9] [1 6]\n",
      "[0 2 3 4 5 6 8 9] [1 7]\n",
      "[0 2 3 4 5 6 7 9] [1 8]\n",
      "[0 2 3 4 5 6 7 8] [1 9]\n",
      "[0 1 4 5 6 7 8 9] [2 3]\n",
      "[0 1 3 5 6 7 8 9] [2 4]\n",
      "[0 1 3 4 6 7 8 9] [2 5]\n",
      "[0 1 3 4 5 7 8 9] [2 6]\n",
      "[0 1 3 4 5 6 8 9] [2 7]\n",
      "[0 1 3 4 5 6 7 9] [2 8]\n",
      "[0 1 3 4 5 6 7 8] [2 9]\n",
      "[0 1 2 5 6 7 8 9] [3 4]\n",
      "[0 1 2 4 6 7 8 9] [3 5]\n",
      "[0 1 2 4 5 7 8 9] [3 6]\n",
      "[0 1 2 4 5 6 8 9] [3 7]\n",
      "[0 1 2 4 5 6 7 9] [3 8]\n",
      "[0 1 2 4 5 6 7 8] [3 9]\n",
      "[0 1 2 3 6 7 8 9] [4 5]\n",
      "[0 1 2 3 5 7 8 9] [4 6]\n",
      "[0 1 2 3 5 6 8 9] [4 7]\n",
      "[0 1 2 3 5 6 7 9] [4 8]\n",
      "[0 1 2 3 5 6 7 8] [4 9]\n",
      "[0 1 2 3 4 7 8 9] [5 6]\n",
      "[0 1 2 3 4 6 8 9] [5 7]\n",
      "[0 1 2 3 4 6 7 9] [5 8]\n",
      "[0 1 2 3 4 6 7 8] [5 9]\n",
      "[0 1 2 3 4 5 8 9] [6 7]\n",
      "[0 1 2 3 4 5 7 9] [6 8]\n",
      "[0 1 2 3 4 5 7 8] [6 9]\n",
      "[0 1 2 3 4 5 6 9] [7 8]\n",
      "[0 1 2 3 4 5 6 8] [7 9]\n",
      "[0 1 2 3 4 5 6 7] [8 9]\n"
     ]
    }
   ],
   "source": [
    "lpo = LeavePOut(p=2)\n",
    "for train, validate in lpo.split(data):\n",
    "    print(train, validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```ShuffleSplit```class creates independent splits with **potentially overlapping validation \n",
    "sets**, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 9 1 6 7 3 0 5] [2 8]\n",
      "[1 2 9 8 0 6 7 4] [3 5]\n",
      "[8 4 5 1 0 6 9 7] [2 3]\n"
     ]
    }
   ],
   "source": [
    "ss = ShuffleSplit(n_splits=3, test_size=2, random_state=0) #验证集数据可能重合\n",
    "for train, validate in ss.split(data):\n",
    "    print(train, validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series cross-validation with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time-series nature of the data implies that cross-validation produces a situation where \n",
    "data from the future will be used to predict data from the past. This is unrealistic at best \n",
    "and data snooping at worst, to the extent that future data refmects past events.\n",
    "To address time dependency, the TimeSeriesSplit object implements a walk-forward \n",
    "test with an expanding training set, where subsequent training sets are supersets of past \n",
    "training sets, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] [5]\n",
      "[0 1 2 3 4 5] [6]\n",
      "[0 1 2 3 4 5 6] [7]\n",
      "[0 1 2 3 4 5 6 7] [8]\n",
      "[0 1 2 3 4 5 6 7 8] [9]\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)  #test集里的数据都在train之后\n",
    "for train, validate in tscv.split(data):\n",
    "    print(train, validate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b82764f8568d3e731c1a8fca5041e2084a073129ef40aeb754987146397fb09b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
